#!/usr/bin/env python3

# TODO:  # noqa: TD005, RUF100
# add  $schema: 'https://docs.renovatebot.com/renovate-schema.json', in renovate configuration
# https://github.com/tox-dev/pyproject-fmt
#
# Warning: [tool.poetry.name] is deprecated. Use [project.name] instead.
# Warning: [tool.poetry.version] is set but 'version' is not in [project.dynamic]. If it is static use [project.version]. If it is dynamic, add 'version' to [project.dynamic].
# If you want to set the version dynamically via `poetry build --local-version` or you are using a plugin, which sets the version dynamically, you should define the version in [tool.poetry] and add 'version' to [project.dynamic].
# Warning: [tool.poetry.description] is deprecated. Use [project.description] instead.
# Warning: [tool.poetry.readme] is set but 'readme' is not in [project.dynamic]. If it is static use [project.readme]. If it is dynamic, add 'readme' to [project.dynamic].
# If you want to define multiple readmes, you should define them in [tool.poetry] and add 'readme' to [project.dynamic].
# Warning: [tool.poetry.license] is deprecated. Use [project.license] instead.
# Warning: [tool.poetry.authors] is deprecated. Use [project.authors] instead.
# Warning: [tool.poetry.keywords] is deprecated. Use [project.keywords] instead.
# Warning: [tool.poetry.classifiers] is set but 'classifiers' is not in [project.dynamic]. If it is static use [project.classifiers]. If it is dynamic, add 'classifiers' to [project.dynamic].
# ATTENTION: Per default Poetry determines classifiers for supported Python versions and license automatically. If you define classifiers in [project], you disable the automatic enrichment. In other words, you have to define all classifiers manually. If you want to use Poetry's automatic enrichment of classifiers, you should define them in [tool.poetry] and add 'classifiers' to [project.dynamic].
# Warning: [tool.poetry.homepage] is deprecated. Use [project.urls] instead.
# Warning: [tool.poetry.repository] is deprecated. Use [project.urls] instead.
# Warning: [tool.poetry.extras] is deprecated. Use [project.optional-dependencies] instead.
# Warning: Defining console scripts in [tool.poetry.scripts] is deprecated. Use [project.scripts] instead. ([tool.poetry.scripts] should only be used for scripts of type 'file').

import functools
import os
import re
import subprocess
from pathlib import Path
from typing import Any, NamedTuple, Optional

import multi_repo_automation as mra
import ruamel.yaml.comments
import ruamel.yaml.scalarstring
import tomlkit.items
import yaml as py_yaml
from githubkit import GitHub
from packaging import version

# if os.path.exists(".github/renovate.json5"):
# if mra.run(["grep", "text", ".github/renovate.json5"], exit_on_error=False).returncode != 0: # not found
# if mra.git_grep(r"\<text\>"]): # found
# if mra.run(["git", "ls-files", "**/*.txt"], stdout=subprocess.PIPE).stdout.strip() != b"": # found
# mra.edit("file")
# input()

_VERSIONS = {}
with (Path(__file__).parent / "versions.yaml").open(encoding="utf-8") as f:
    _VERSIONS = py_yaml.load(f, Loader=py_yaml.SafeLoader)


def gopass(key: str, default: Optional[str] = None) -> Optional[str]:
    """
    Get a value from gopass.

    Arguments:
        key: The key to get
        default: the value to return if gopass is not found

    Return the value

    """
    try:
        return subprocess.check_output(["gopass", "show", key]).strip().decode()
    except FileNotFoundError:
        if default is not None:
            return default
        raise


_TOKEN = (
    os.environ["GITHUB_TOKEN"].strip()
    if "GITHUB_TOKEN" in os.environ
    else gopass("gs/ci/github/token/gopass")
)


class _Config:
    _values: dict[str, Any]
    _enabled: list[str]
    _disabled: list[str]

    def __init__(self) -> None:
        self._values = {}
        self._enabled = []
        self._disabled = []
        self.repo = mra.get_repo_config()
        self.arguments = mra.get_arguments()

        if Path(".github/ci-upgrade.yaml").exists():
            with Path(".github/ci-upgrade.yaml").open(encoding="utf-8") as ci_update_file:
                upgrade_config = py_yaml.load(ci_update_file.read(), Loader=py_yaml.SafeLoader)
                self._values = upgrade_config.get("values", {})
                self._enabled = upgrade_config.get("enabled", [])
                self._disabled = upgrade_config.get("disabled", [])

    def value(self, name: str, default: Any = None) -> Any:
        """Get a value from the configuration."""
        return self._values.get(name, default)

    def enabled(self, name: str, default: bool) -> bool:
        """Check if a feature is enabled."""
        if name in self._enabled:
            return True
        if name in self._disabled:
            return False
        return default


class _TaskEnv(NamedTuple):
    github: GitHub
    c2cciutils_version: version.Version
    set_c2cciutils_version: bool
    use_python: bool
    # min_python_version: str
    # max_python_version: str
    pyproject_path: str
    prospector_path: str
    use_pypi: bool
    use_docker: bool
    use_helm: bool
    has_stabilization_branches: bool
    on_stabilization_branches: bool
    stabilization_branches: list[str]
    gopass: bool
    token: str
    config: _Config


def _create_labels(task_env: _TaskEnv) -> None:
    mra.gh(
        "label",
        "create",
        "--force",
        "dependencies",
        "--color=0075ca",
        "--description=Update the dependencies",
    )
    if task_env.config.enabled("pullRequestWelcome", default=False):
        mra.gh(
            "label",
            "create",
            "--force",
            "pull request welcome",
            "--color=6622BB",
            "--description=A pull request is welcome to fix this issue",
        )


def _merge(default_config: Any, config: Any) -> Any:
    """
    Deep merge the dictionaries (on dictionaries only, not on arrays).

    Arguments:
        default_config: The default config that will be applied
        config: The base config, will be modified
    """
    if not isinstance(default_config, dict) or not isinstance(config, dict):
        return config

    for key in default_config:
        if key not in config:
            config[key] = default_config[key]
        else:
            _merge(default_config[key], config[key])
    return config


def _get_repository() -> str:
    """
    Get the current GitHub repository like `organization/project`.
    """
    if "GITHUB_REPOSITORY" in os.environ:
        return os.environ["GITHUB_REPOSITORY"]

    remote_lines = subprocess.check_output(["git", "remote", "--verbose"]).decode().split("\n")
    remote_match = (
        re.match(r".*git@github.com:(.*).git .*", remote_lines[0]) if len(remote_lines) >= 1 else None
    )

    if remote_match:
        return remote_match.group(1)

    print("::warning::The GitHub repository isn't found, using 'camptocamp/project'")

    return "camptocamp/project"


def _get_master_branch(task_env: _TaskEnv, repo: list[str]) -> tuple[str, bool]:
    """Get the name of the master branch."""
    master_branch = "master"
    success = False
    try:
        repo = task_env.github.get_repo(repo[0], repo[1])
    except Exception as runtime_error:  # pylint: disable=broad-except  # noqa: BLE001
        print(runtime_error)
        print("::warning::Fallback to get default branch name")
    else:
        return repo.default_branch, True
    return master_branch, success


def _get_c2cciutils_1_8_config(config: dict[str, Any]) -> dict[str, Any]:
    """
    Get the configuration, with project and auto detections.
    """

    # repository = _get_repository()
    # repo = repository.split("/")

    # _merge(
    #    {
    #        "version": {
    #            "tag_to_version_re": [
    #                {"from": r"([0-9]+.[0-9]+.[0-9]+)", "to": r"\1"},
    #            ],
    #            "branch_to_version_re": [
    #                {"from": r"([0-9]+.[0-9]+)", "to": r"\1"},
    #                {"from": master_branch, "to": master_branch},
    #            ],
    #        }
    #    },
    #    config,
    # )

    has_docker_files = bool(
        subprocess.run(
            ["git", "ls-files", "*/Dockerfile*", "Dockerfile*"],
            stdout=subprocess.PIPE,
            check=True,
        ).stdout,
    )
    has_python_package = bool(
        subprocess.run(
            ["git", "ls-files", "setup.py", "*/setup.py"],
            stdout=subprocess.PIPE,
            check=True,
        ).stdout,
    ) or bool(
        subprocess.run(
            ["git", "ls-files", "pyproject.toml", "*/pyproject.toml"],
            stdout=subprocess.PIPE,
            check=True,
        ).stdout,
    )

    publish_config = _merge(
        {
            "pypi": {"versions": ["version_tag"], "packages": "<auto-detected>"},
            "docker": {"images": "<auto-detected>"},
            "helm": {"versions": ["version_tag"], "folders": "<auto-detected>"},
        },
        {},
    )
    publish_config["pypi"]["packages"] = [{"path": "."}] if has_python_package else []
    publish_config["docker"]["images"] = [{"name": _get_repository()}] if has_docker_files else []
    publish_config["helm"]["folders"] = [f.parent for f in Path().rglob("Chart.yaml")]

    default_config = {
        "publish": publish_config,
    }
    _merge(default_config, config)

    return config


def _tag_publish_config(task_env: _TaskEnv) -> None:
    del task_env  # unused
    if not mra.git_grep("tag-publish") and not mra.git_grep("c2cciutils-publish"):
        if Path(".github/publish.yaml").exists():
            Path(".github/publish.yaml").unlink()
        return

    if Path(".github/publish.yaml").exists():
        return

    ci_config = Path("ci/config.yaml")
    if not ci_config.exists():
        filled_config = _get_c2cciutils_1_8_config({})
    else:
        with mra.EditYAML(ci_config) as config:
            filled_config = _get_c2cciutils_1_8_config(config)

    if "publish" not in filled_config:
        return

    if Path("ci/dpkg-versions.yaml").exists():
        mra.run(["git", "mv", "ci/dpkg-versions.yaml", ".github/"])

    to_remove = False
    with mra.EditYAML(Path(".github/publish.yaml")) as publish:
        publish.data = filled_config["publish"]
        if "helm" in publish and "folders" in publish["helm"]:
            publish["helm"]["packages"] = [{"folder": f} for f in publish["helm"]["folders"]]
            del publish["helm"]["folders"]
        if "dispatch" not in publish:
            publish["dispatch"] = [{}]
        if "version" in filled_config:
            publish["version"] = filled_config["version"]

        if publish.get("pypi", False) is not False:
            for package in publish.get("pypi", {}).get("packages", []):
                if package["path"] == ".":
                    del package["path"]
            if publish.get("pypi", {}).get("versions", []) == ["version_tag"]:
                del publish["pypi"]["versions"]
        if publish.get("helm", False) is not False and publish.get("helm", {}).get("versions", []) == [
            "version_tag",
        ]:
            del publish["helm"]["versions"]
        if publish.get("docker", False) is not False and "repository" in publish.get("docker", {}):
            del publish["docker"]["repository"]
        if "print_versions" in publish:
            del publish["print_versions"]

        if "pypi" in publish and (publish["pypi"] is False or not publish["pypi"].get("packages", [])):
            del publish["pypi"]
        if "docker" in publish and (publish["docker"] is False or not publish["docker"].get("images", [])):
            del publish["docker"]
        if publish.get("docker", False) is not False and "dispatch" in publish["docker"]:
            del publish["docker"]["dispatch"]
        if "helm" in publish and (publish["helm"] is False or not publish["helm"].get("packages", [])):
            del publish["helm"]

        def migrate_versions(versions: list[str]) -> list[str]:
            new_versions = []
            for version_ in versions:
                if version_ == "version_tag":
                    new_versions.append("tag")
                if version_ == "version_branch":
                    new_versions.append("stabilization_branch")
                    new_versions.append("default_branch")
                if version_ == "feature_tag":
                    pass  # no more supported
                if version_ == "feature_branch":
                    new_versions.append("feature_branch")
                    new_versions.append("pull_request")
                else:
                    new_versions.append(version_)
            return new_versions

        if publish.get("docker", False) is not False:
            for image in publish["docker"].get("images", []):
                if image.get("tags", []) == ["{version}"]:
                    del image["tags"]

        if publish.get("docker", False) is not False and "versions" in publish.get("docker", {}):
            publish["docker"]["versions_type"] = migrate_versions(publish["docker"]["versions"])
            del publish["docker"]["versions"]
        if publish.get("helm", False) is not False and "versions" in publish.get("helm", {}):
            publish["helm"]["versions_type"] = migrate_versions(publish["helm"]["versions"])
            del publish["helm"]["versions"]
        if publish.get("pypi", False) is not False and "versions" in publish.get("pypi", {}):
            publish["pypi"]["versions_type"] = migrate_versions(publish["pypi"]["versions"])
            del publish["pypi"]["versions"]

        if "branch_to_version_re" in publish.get("version", {}):
            branch_to_version_re = publish["version"]["branch_to_version_re"]
            if (
                len(branch_to_version_re) == 2
                and branch_to_version_re[0].get("from") == r"([0-9]+.[0-9]+)"
                and branch_to_version_re[0].get("to") == r"\1"
                and branch_to_version_re[1].get("from") == branch_to_version_re[1].get("to")
            ):
                del publish["version"]["branch_to_version_re"]
            else:
                publish["version"]["branch_to_version"] = publish["version"]["branch_to_version_re"]
                del publish["version"]["branch_to_version_re"]
        for branch_to_version in publish.get("version", {}).get("branch_to_version", []):
            if "from" in branch_to_version:
                branch_to_version["from_re"] = branch_to_version["from"]
                del branch_to_version["from"]

        if "tag_to_version_re" in publish.get("version", {}):
            if publish["version"]["tag_to_version_re"] == [
                {"from": r"([0-9]+.[0-9]+.[0-9]+)", "to": r"\1"},
            ]:
                del publish["version"]["tag_to_version_re"]
            else:
                publish["version"]["tag_to_version"] = publish["version"]["tag_to_version_re"]
                del publish["version"]["tag_to_version_re"]
        for tag_to_version in publish.get("version", {}).get("tag_to_version", []):
            if "from" in tag_to_version:
                tag_to_version["from_re"] = tag_to_version["from"]
                del tag_to_version["from"]

        index_to_remove = []
        for nb, branch_to_version in enumerate(publish.get("version", {}).get("branch_to_version", [])):
            if branch_to_version.get("to") == "\\1":
                index_to_remove.append(nb)
        for nb in reversed(index_to_remove):
            del publish["version"]["branch_to_version"][nb]
        if "branch_to_version" in publish.get("version", {}) and not publish["version"]["branch_to_version"]:
            del publish["version"]["branch_to_version"]
        if "version" in publish and not publish["version"]:
            del publish["version"]

        if "version" in publish:
            publish["transformers"] = publish["version"]
            del publish["version"]

        if "repository" in publish.get("docker", {}):
            for repository in publish["docker"]["repository"].values():
                if "server" in repository:
                    repository["host"] = repository["server"]
                    del repository["host"]
                if "versions" in repository:
                    repository["versions_type"] = migrate_versions(repository["versions"])
                    del repository["versions"]

        to_remove = list(publish.keys()) == ["dispatch"]
    if to_remove:
        Path(".github/publish.yaml").unlink()

    rm_config = False
    if ci_config.exists():
        with mra.EditYAML(ci_config) as config:
            if "publish" in config:
                del config["publish"]
            if "version" in config:
                del config["version"]

            rm_config = not config.data

    if rm_config:
        ci_config.unlink()


def _set_schema_config(task_env: _TaskEnv) -> None:
    for config_filename, schema_url in (
        (
            Path("ci/config.yaml"),
            f"https://raw.githubusercontent.com/camptocamp/c2cciutils/{task_env.c2cciutils_version}/c2cciutils/schema.json",
        ),
        (
            Path(".github/publish.yaml"),
            f"https://raw.githubusercontent.com/camptocamp/tag-publish/{_VERSIONS['tag-publish']}/tag_publish/schema.json",
        ),
        (
            Path(".github/ghci.yaml"),
            "https://geoservices-int.camptocamp.com/github/schema.json",
        ),
        (
            Path("jsonschema-gentypes.yaml"),
            f"https://raw.githubusercontent.com/sbrunner/jsonschema-gentypes/{_VERSIONS['sbrunner/jsonschema-gentypes']}/jsonschema_gentypes/schema.json",
        ),
    ):
        if config_filename.exists():
            with mra.Edit(config_filename) as config:
                data = config.data.split("\n")
                if data[0].startswith("# yaml-language-server: $schema="):
                    continue

                data = [
                    f"# yaml-language-server: $schema={schema_url}",
                    "",
                    *data,
                ]

                config.data = "\n".join(data)


def _upgrade_ubuntu(task_env: _TaskEnv) -> None:
    del task_env

    for workflow_file in mra.run(
        ["git", "ls-files", ".github/workflows/*.yaml"],
        stdout=subprocess.PIPE,
    ).stdout.split("\n"):
        if workflow_file:
            try:
                with mra.EditYAML(workflow_file) as yaml:
                    for job in yaml.get("jobs", {}).values():
                        if job.get("runs-on", "").startswith("ubuntu-"):
                            job["runs-on"] = "ubuntu-22.04"
            except Exception as e:  # pylint: disable=broad-except  # noqa: BLE001
                print(f"Error in {workflow_file}: {e}")


def _update_dockerfile(task_env: _TaskEnv) -> None:
    if not task_env.use_docker:
        return

    for dockerfile in mra.run(
        ["git", "ls-files", "*/Dockerfile*", "Dockerfile*"],
        stdout=subprocess.PIPE,
    ).stdout.split("\n"):
        if dockerfile:
            with mra.Edit(Path(dockerfile)) as docker:
                from_as_re = re.compile(r"FROM\s+(.*)\s+as\s+")
                from_as_match = from_as_re.search(docker.data)
                while from_as_match:
                    docker.data = from_as_re.sub("FROM \\1 AS ", docker.data)
                    from_as_match = from_as_re.search(docker.data)

                if 'LABEL maintainer Camptocamp "info@camptocamp.com"' in docker.data:
                    docker.data = docker.data.replace(
                        'LABEL maintainer Camptocamp "info@camptocamp.com"',
                        'LABEL org.opencontainers.image.authors="Camptocamp <info@camptocamp.com>"',
                    )


def _update_workflow_venv(task_env: _TaskEnv, yaml: mra.EditYAML) -> None:
    if task_env.on_stabilization_branches:
        return

    # Update for Python 3.12
    # pip install match
    pip_install_re = re.compile(r"\bpip install\b")
    for job in yaml["jobs"].values():
        setup_index = -1
        install_index = -1
        echo_index = -1
        for index, step in enumerate(job["steps"]):
            if "pip install " in step.get("run", "") and " --user " in step.get("run", ""):
                step["run"] = step["run"].replace(" --user ", " ")
            if install_index < 0 and pip_install_re.search(step.get("run", "")):
                install_index = index
            if setup_index < 0 and step.get("uses", "").startswith("actions/setup-python@"):
                setup_index = index
            if echo_index < 0 and step.get("run", "") == 'echo "${HOME}/.local/bin" >> ${GITHUB_PATH}':
                echo_index = index
        if 0 <= install_index < setup_index:
            job["steps"].insert(
                install_index,
                {
                    "uses": "actions/setup-python@" + _VERSIONS["actions/setup-python"],
                    "with": {
                        "python-version": _VERSIONS["python"],
                    },
                },
            )
        if echo_index >= 0:
            del job["steps"][echo_index]


def _update_main_workflow(task_env: _TaskEnv) -> None:
    if Path(".github/workflows/codeql.yaml").exists():
        Path(".github/workflows/codeql.yaml").unlink()
    if not Path(".github/workflows/main.yaml").exists() and Path(".github/workflows/ci.yaml").exists():
        Path(".github/workflows/ci.yaml").rename(Path(".github/workflows/main.yaml"))
    if Path(".github/workflows/main.yaml").exists():
        with mra.EditYAML(Path(".github/workflows/main.yaml")) as yaml:
            _update_workflow_venv(task_env, yaml)

            if mra.git_grep("tag-publish") or mra.git_grep("c2cciutils-publish"):
                permissions = yaml.setdefault("permissions", {})
                permissions["contents"] = "write"
                if task_env.use_docker:
                    permissions["packages"] = "write"
                if task_env.use_pypi:
                    permissions["id-token"] = "write"

            for job in yaml["jobs"].values():
                pre_commit_index = -1
                has_pre_commit_artifacts = False
                publish_index = -1
                tag_publish_index = -1
                has_publish_artifacts = False
                for index, step in enumerate(job["steps"]):
                    if step.get("run", "").startswith("pre-commit run"):
                        if step["run"] == "pre-commit run --all-files":
                            step["run"] = "pre-commit run --all-files --color=always"
                        pre_commit_index = index
                    if step.get("run", "").startswith("c2cciutils-publish"):
                        publish_index = index
                    if step.get("run", "").startswith("tag-publish"):
                        tag_publish_index = index
                    if (
                        step.get("uses", "").startswith("actions/upload-artifact@")
                        and step.get("with", {}).get("name", "") == "Apply pre-commit fix.patch"
                    ):
                        has_pre_commit_artifacts = True
                    if (
                        step.get("uses", "").startswith("actions/upload-artifact@")
                        and step.get("with", {}).get("name", "") == "Update dpkg versions list.patch"
                    ):
                        has_publish_artifacts = True
                    if (
                        step.get("uses", "").startswith("actions/checkout@")
                        and step.get("restore-keys", "")
                        == "pre-commit-${{ hashFiles('.pre-commit-config.yaml') }}"
                    ):
                        step["key"] = (
                            "pre-commit-${{ github.event_name == 'pull_request' && github.base_ref || github.ref_name }}-${{ hashFiles('.pre-commit-config.yaml') }}"
                        )
                        step["restore-keys"] = ruamel.yaml.scalarstring.LiteralScalarString(
                            "\n".join(  # noqa: FLY002
                                [
                                    "pre-commit-${{ github.event_name == 'pull_request' && github.base_ref || github.ref_name }}-${{ hashFiles('.pre-commit-config.yaml') }}",
                                    "pre-commit-${{ github.event_name == 'pull_request' && github.base_ref || github.ref_name }}-",
                                    "pre-commit-",
                                ],
                            ),
                        )

                index_add = 0
                for index, filename, has_artifact, artifact_name in (
                    (
                        pre_commit_index,
                        "pre-commit",
                        has_pre_commit_artifacts,
                        "Apply pre-commit fix",
                    ),
                    (
                        publish_index,
                        "dpkg-versions",
                        has_publish_artifacts,
                        "Update dpkg versions list",
                    ),
                    (
                        tag_publish_index,
                        "dpkg-versions",
                        has_publish_artifacts,
                        "Update dpkg versions list",
                    ),
                ):
                    if index >= 0:
                        if not task_env.on_stabilization_branches and (
                            job["steps"][index + index_add].get("env", {}).get("SKIP", "").strip(",")
                            == "poetry-lock"
                        ):
                            del job["steps"][index + index_add]["env"]["SKIP"]
                            if not job["steps"][index + index_add]["env"]:
                                del job["steps"][index + index_add]["env"]
                        if len(job["steps"]) > index + index_add + 1 and job["steps"][
                            index + index_add + 1
                        ].get("run", "").startswith("git diff"):
                            job["steps"][index + index_add + 1]["run"] = (
                                f"git diff --exit-code --patch > /tmp/{filename}.patch; git diff --color; git reset --hard || true"
                            )
                            job["steps"][index + index_add + 1]["if"] = "failure()"
                        else:
                            job["steps"].insert(
                                index + index_add + 1,
                                {
                                    "run": f"git diff --exit-code --patch > /tmp/{filename}.patch || true",
                                    "if": "failure()",
                                },
                            )
                            index_add += 1
                        if not has_artifact and index >= 0:
                            job["steps"].insert(
                                index + index_add + 1,
                                {
                                    "uses": "actions/upload-artifact@" + _VERSIONS["actions/upload-artifact"],
                                    "with": {
                                        "name": f"{artifact_name}.patch",
                                        "path": f"/tmp/{filename}.patch",  # noqa: S108
                                        "retention-days": 1,
                                    },
                                    "if": "failure()",
                                },
                            )
                            index_add += 1

                publish_index = -1

                for index, step in enumerate(job["steps"]):
                    if not task_env.on_stabilization_branches:
                        if task_env.c2cciutils_version >= version.parse("1.6.0"):
                            if step.get("run", "") == "c2cciutils-checks":
                                step["name"] = "Print environment information"
                                step["run"] = "c2cciutils-env"
                                value = None
                                if "env" in step:
                                    if step["env"].ca.items:
                                        value = list(step["env"].ca.items.values())[-1][2].value
                                    del step["env"]
                                step["env"] = {"GITHUB_EVENT": "${{ toJson(github) }}"}
                                job["steps"].ca.items[index] = [
                                    None,
                                    None,
                                    [
                                        ruamel.yaml.CommentToken(
                                            value or "\n\n",
                                            ruamel.yaml.error.CommentMark(0),
                                            None,
                                        ),
                                    ],
                                    None,
                                ]
                        elif step.get("run", "") == "c2cciutils-checks" and not task_env.gopass:
                            env = step.setdefault("env", {})
                            env["SNYK_TOKEN"] = "${{ secrets.SNYK_TOKEN }}"  # noqa: S105

            # if len(yaml["jobs"]) > 1:
            #     candidate_jobs = set()
            #     needed_jobs = set()
            #     success_job = False
            #     for name, job in yaml["jobs"].items():
            #         if name == "success":
            #             success_job = True
            #         if "needs" in job:
            #             candidate_jobs.add(name)
            #             if isinstance(job["needs"], list):
            #                 needed_jobs += job["needs"]
            #             else:
            #                 needed_jobs.add(job["needs"])
            #     for needed_job in needed_jobs:
            #         if needed_job in candidate_jobs:
            #             candidate_jobs.remove(needed_job)
            #     if len(candidate_jobs) == 1 and not success_job:
            #         candidate_job = list(candidate_jobs)[0]
            #
            #         yaml["jobs"]["success"] = {
            #             "name": "Success",
            #             "runs-on": "ubuntu-22.04",
            #             "timeout-minutes": 5,
            #             "needs": yaml["jobs"][candidate_job]["needs"],
            #             "steps": [
            #                 {
            #                     "run": "touch SUCCESS",
            #                 },
            #                 {
            #                     "uses": "actions/upload-artifact@v4",
            #                     "with": {
            #                         "name": "Success",
            #                         "path": "SUCCESS",
            #                         "retention-days": 1,
            #                     },
            #                 },
            #             ],
            #         }
            #
            #         yaml["jobs"][candidate_job]["needs"] = "success"
            #         if "if" in yaml["jobs"][candidate_job]:
            #             yaml["jobs"]["success"][
            #                 "if"
            #             ] = f"always() && {yaml['jobs'][candidate_job]['if']}"
            #         else:
            #             yaml["jobs"]["success"]["if"] = "always()"
            #
            #         step = {
            #             "name": "Check if related check run failed",
            #             "uses": "actions/download-artifact@v4",
            #             "with": {
            #                 "name": "Success",
            #             },
            #         }
            #         if job_name == "publish":
            #             job["steps"].insert(0, step)
            #         else:
            #             job["steps"].append(step)


def _update_audit_workflow(task_env: _TaskEnv) -> None:
    del task_env  # unused
    if Path(".github/workflows/audit.yaml").exists():
        Path(".github/workflows/audit.yaml").unlink()


def _update_clean_workflow(task_env: _TaskEnv) -> None:
    if Path(".github/workflows/clean.yaml").exists():
        with mra.EditYAML(Path(".github/workflows/clean.yaml")) as yaml:
            _update_workflow_venv(task_env, yaml)


def _clean_update_workflow(task_env: _TaskEnv) -> None:
    if Path(".whitesource").exists():
        Path(".whitesource").unlink()
    if Path(".pylintrc").exists():
        Path(".pylintrc").unlink()
    if Path(".github/changelog-config.yaml").exists():
        Path(".github/changelog-config.yaml").unlink()
    if Path(".github/workflows/changelog.yaml").exists():
        Path(".github/workflows/changelog.yaml").unlink()
    if Path(".github/run-changelog.mjs").exists():
        Path(".github/run-changelog.mjs").unlink()
    if Path(".github/workflows/pr-checks.yaml").exists():
        Path(".github/workflows/pr-checks.yaml").unlink()
    if Path(".github/workflows/test_url.yaml").exists():
        Path(".github/workflows/test_url.yaml").unlink()

    if not task_env.use_docker:
        if Path(".github/workflows/clean.yaml").exists():
            Path(".github/workflows/clean.yaml").unlink()
        return

    if not task_env.has_stabilization_branches:
        if Path(".github/workflows/backport.yaml").exists():
            Path(".github/workflows/backport.yaml").unlink()
        return

    # Upgrade deprecated workflows
    for workflow_filename in Path(".github/workflows").glob("*.yaml"):
        with mra.EditYAML(workflow_filename) as yaml:
            for job in yaml["jobs"].values():
                for step in job["steps"]:
                    for action, version_ in [
                        ("actions/cache", "v1"),
                        ("actions/cache", "v2"),
                        ("actions/upload-artifact", "v3"),
                        ("actions/download-artifact", "v3"),
                    ]:
                        if step.get("uses", "").startswith(f"{action}@{version_}"):
                            step["uses"] = f"{action}@{_VERSIONS[action]}"
                            break


def _update_delete_old_workflows_run_workflow(task_env: _TaskEnv) -> None:
    del task_env  # unused
    if Path(".github/workflows/delete-old-workflow-run.yaml").exists():
        Path(".github/workflows/delete-old-workflow-run.yaml").unlink()
    if Path(".github/workflows/delete-old-workflows-run.yaml").exists():
        Path(".github/workflows/delete-old-workflows-run.yaml").unlink()


def _safe_or(elements: list[str], prefix: str = "") -> str:
    """Create an or condition with a safe check."""
    if len(elements) == 0:
        return ""
    if len(elements) == 1:
        return elements[0]
    return "(" + f"\n{prefix}|| ".join(elements) + ")"


def _and(elements: list[str], prefix: str = "") -> str:
    elements = [e for e in elements if e]
    if len(elements) == 0:
        return ""
    return f"\n{prefix}&& ".join(elements)


def _update_pull_request_automation_workflow(task_env: _TaskEnv) -> None:
    for file_ in (
        Path(".github/workflows/dependabot-auto-merge.yaml"),
        Path(".github/workflows/auto-review.yaml"),
        Path(".github/workflows/auto-merge.yaml"),
        Path(".github/workflows/dependency-update-review.yaml"),
        Path(".github/workflows/dependency-auto-review.yaml"),
    ):
        if file_.exists():
            if Path(".github/workflows/pull-request-automation.yaml").exists():
                file_.unlink()
            else:
                mra.run(
                    [
                        "git",
                        "mv",
                        file_,
                        ".github/workflows/pull-request-automation.yaml",
                    ],
                )
    if not Path(".github/workflows/pull-request-automation.yaml").exists():
        with mra.Edit(Path(".github/workflows/pull-request-automation.yaml")) as text:
            text.data = "\n".join(  # noqa: FLY002
                [
                    "name: Auto reviews updates",
                    "",
                    "on:",
                    "  pull_request:",
                    "    types:",
                    "      - opened",
                    "      - reopened",
                    "",
                    "jobs:",
                    "  auto-merge:",
                    "    name: Auto reviews updates",
                    "    runs-on: ubuntu-22.04",
                    "    timeout-minutes: 5",
                    "",
                    "    steps:",
                    "      - uses: actions/github-script@v7",
                    "        with:",
                    "          script: |-",
                    "            github.rest.pulls.createReview({",
                    "              owner: context.repo.owner,",
                    "              repo: context.repo.repo,",
                    "              pull_number: context.payload.pull_request.number,",
                    "              event: 'APPROVE',",
                    "            })",
                    "    if: github.event.pull_request.user.login == 'renovate[bot]'",
                ],
            )
    with mra.EditYAML(Path(".github/workflows/pull-request-automation.yaml")) as yaml:
        task_env.config.value("dependencyAutoReviewUsers", ["renovate[bot]"])
        yaml["name"] = "Auto reviews pull requests from bots"
        yaml["on"] = {
            "pull_request": {"types": ["opened", "reopened"]},
        }
        yaml["name"] = "Auto reviews, merge and close pull requests"
        for job in yaml["jobs"].values():
            job["name"] = "Auto reviews pull requests from bots"

            # job["permissions"] = {
            #    "contents": "write",
            #    "pull-requests": "write",
            # }

            if "if" in job:
                del job["if"]

            print_event = "Print event"
            print_context = "Print context"
            auto_review_ghci_updates = "Auto reviews GHCI updates"
            auto_review_renovate_updates = "Auto reviews Renovate updates"
            auto_review_and_merge_dpkg_updates = "Auto review and merge dpkg updates"
            auto_review_and_merge_snyk_auto_fix = "Auto review and merge snyk auto fix"
            step_names = [
                print_event,
                print_context,
                auto_review_ghci_updates,
                auto_review_renovate_updates,
            ]

            old_step = {}
            for new_step_name in step_names:
                for step in job["steps"]:
                    if step.get("name") == new_step_name:
                        old_step[new_step_name] = step
                        break

            job["steps"] = [old_step.get(step, {"name": step}) for step in step_names]

            auto_review_and_merge_snyk_auto_fix_index = -1
            for index, step in enumerate(job["steps"]):
                if step["name"] == auto_review_and_merge_snyk_auto_fix:
                    auto_review_and_merge_snyk_auto_fix_index = index
            if auto_review_and_merge_snyk_auto_fix_index >= 0:
                del job["steps"][auto_review_and_merge_snyk_auto_fix_index]

            auto_review_and_merge_dpkg_update_index = -1
            for index, step in enumerate(job["steps"]):
                if step["name"] == auto_review_and_merge_dpkg_updates:
                    auto_review_and_merge_dpkg_update_index = index
            if auto_review_and_merge_dpkg_update_index >= 0:
                del job["steps"][auto_review_and_merge_dpkg_update_index]

            for step in job["steps"]:
                if step["name"] == print_event:
                    step["run"] = 'echo "${GITHUB}" | jq'
                    step["env"] = {
                        "GITHUB": "${{ toJson(github) }}",
                    }
                if step["name"] == print_context:
                    if not step.get("uses", "").startswith("actions/github-script@"):
                        step["uses"] = "actions/github-script@v7"
                    step["with"] = {
                        "script": ruamel.yaml.scalarstring.LiteralScalarString(
                            "console.log(context);",
                        ),
                    }
                    if "if" in step:
                        del step["if"]
                    if "env" in step:
                        del step["env"]
                if step["name"] == auto_review_ghci_updates:
                    if not step.get("uses", "").startswith("actions/github-script@"):
                        step["uses"] = "actions/github-script@v7"
                    step["if"] = ruamel.yaml.scalarstring.LiteralScalarString(
                        _and(
                            [
                                "startsWith(github.head_ref, 'ghci/audit/')",
                                _safe_or(
                                    [
                                        "github.event.pull_request.user.login == 'geo-ghci-test[bot]'",
                                        "github.event.pull_request.user.login == 'geo-ghci-int[bot]'",
                                        "github.event.pull_request.user.login == 'geo-ghci[bot]'",
                                    ],
                                    "  ",
                                ),
                            ],
                        ),
                    )
                    step["with"] = {
                        "script": ruamel.yaml.scalarstring.LiteralScalarString(
                            "\n".join(  # noqa: FLY002
                                [
                                    "github.rest.pulls.createReview({",
                                    "  owner: context.repo.owner,",
                                    "  repo: context.repo.repo,",
                                    "  pull_number: context.payload.pull_request.number,",
                                    "  event: 'APPROVE',",
                                    "})",
                                ],
                            ),
                        ),
                    }
                if step["name"] == auto_review_renovate_updates:
                    if not step.get("uses", "").startswith("actions/github-script@"):
                        step["uses"] = "actions/github-script@v7"
                    step["if"] = ruamel.yaml.scalarstring.LiteralScalarString(
                        "github.event.pull_request.user.login == 'renovate[bot]'",
                    )
                    step["with"] = {
                        "script": ruamel.yaml.scalarstring.LiteralScalarString(
                            "\n".join(  # noqa: FLY002
                                [
                                    "github.rest.pulls.createReview({",
                                    "  owner: context.repo.owner,",
                                    "  repo: context.repo.repo,",
                                    "  pull_number: context.payload.pull_request.number,",
                                    "  event: 'APPROVE',",
                                    "})",
                                ],
                            ),
                        ),
                    }


def _update_pyproject_toml(task_env: _TaskEnv) -> None:
    """
    Add or update the Poetry extensions to the pyproject.toml file.
    """
    del task_env  # unused

    poetry_version = version.parse("0.0.0")
    for requirements_path in (
        Path("requirements.txt"),
        Path(".github/requirements.txt"),
        Path("ci/requirements.txt"),
    ):
        if requirements_path.exists():
            with mra.Edit(requirements_path) as requirements_txt:
                for line in requirements_txt.data.splitlines():
                    if line.startswith("poetry=="):
                        poetry_version = version.parse(line.split("==")[1])
                        break

    if poetry_version >= version.parse("1.3.0"):
        typed = (
            len(
                mra.run(
                    ["git", "ls-files", "py.typed"],
                    exit_on_error=False,
                    stdout=subprocess.PIPE,
                    encoding="utf-8",
                ).stdout.strip(),
            )
            > 0
        )
        for pyproject_filename in (
            Path("pyproject.toml"),
            Path("app/pyproject.toml"),
            Path("api/pyproject.toml"),
        ):
            if pyproject_filename.exists():
                with mra.EditTOML(pyproject_filename) as pyproject:
                    if "requires" in pyproject.get("build-system", {}) and "python" in pyproject.get(
                        "tool",
                        {},
                    ).get("poetry", {}).get("dependencies", {}):
                        classifiers = (
                            pyproject.setdefault("tool", {})
                            .setdefault("poetry", {})
                            .setdefault("classifiers", [])
                        )
                        if typed and "Typing :: Typed" not in classifiers:
                            classifiers.append("Typing :: Typed")
                        pyproject["tool"]["poetry"]["classifiers"] = sorted(classifiers)

                        if "dev-dependencies" in pyproject["tool"]["poetry"]:
                            if "dependencies" in pyproject["tool"]["poetry"].setdefault(
                                "group",
                                {},
                            ).setdefault("dev", {}):
                                pyproject["tool"]["poetry"]["group"]["dev"]["dependencies"].update(
                                    pyproject["tool"]["poetry"]["dev-dependencies"],
                                )
                            else:
                                pyproject["tool"]["poetry"]["group"]["dev"]["dependencies"] = pyproject[
                                    "tool"
                                ]["poetry"]["dev-dependencies"]
                            del pyproject["tool"]["poetry"]["dev-dependencies"]

                        if "prospector" in pyproject["tool"]["poetry"].get("group", {}).get("dev", {}).get(
                            "dependencies",
                            {},
                        ):
                            dev_dependencies = pyproject["tool"]["poetry"]["group"]["dev"]["dependencies"]
                            if "prospector-profile-utils" not in dev_dependencies:
                                dev_dependencies["prospector-profile-utils"] = (
                                    f"{_VERSIONS['prospector-profile-utils']}"
                                )
                            if "prospector-profile-duplicated" not in dev_dependencies:
                                dev_dependencies["prospector-profile-duplicated"] = (
                                    f"{_VERSIONS['prospector-profile-duplicated']}"
                                )
                            extra = dev_dependencies["prospector"].setdefault("extras", [])
                            if "with_ruff" not in extra:
                                extra.append("with_ruff")
                            if "with_pyroma" not in extra:
                                extra.append("with_pyroma")

                        # version_splitter = re.compile("[<>=]+")
                        # [version_splitter.split(p)[0] for p in pyproject["build-system"]["requires"]]
                        for requirements_file_name_candidate in (
                            Path("requirements.txt"),
                            Path(".github/requirements.txt"),
                            Path("ci/requirements.txt"),
                        ):
                            if requirements_file_name_candidate.exists():
                                with mra.Edit(requirements_file_name_candidate) as requirements_txt:
                                    if "poetry" in requirements_txt.data:
                                        break
                        # for dependency, plugin, plugin_version in (
                        #     (True, "poetry-dynamic-versioning", _VERSIONS["poetry-dynamic-versioning"]),
                        #     (True, "poetry-plugin-tweak-dependencies-version", _VERSIONS["poetry-plugin-tweak-dependencies-version"]),
                        #     (True, "poetry-plugin-drop-python-upper-constraint", _VERSIONS["poetry-plugin-drop-python-upper-constraint"]),
                        #     (False, "poetry-plugin-export", _VERSIONS["poetry-plugin-export"]),
                        # ):
                        #     requirement = not dependency
                        #     if dependency and plugin not in build_system_requires_no_version:
                        #         pyproject.data["build-system"]["requires"].append(plugin)
                        #         requirement = True
                        #     if requirement and requirement_file_name:
                        #         with mra.Edit(requirements_file_name) as requirements_txt:
                        #                     if (
                        #                         f"{plugin}==" not in requirements_txt.data
                        #                         and f"{plugin}[" not in requirements_txt.data
                        #                     ):
                        #                         requirements_txt.data += f"{plugin}=={plugin_version}\n"

                        poetry_dynamic_versioning = pyproject.setdefault("tool", {}).setdefault(
                            "poetry-dynamic-versioning",
                            {},
                        )
                        poetry_dynamic_versioning.setdefault("enable", True)
                        poetry_dynamic_versioning.setdefault("vcs", "git")
                        poetry_dynamic_versioning.setdefault("pattern", "^(?P<base>\\d+(\\.\\d+)*)")
                        if "style" in poetry_dynamic_versioning:
                            del poetry_dynamic_versioning["style"]
                        poetry_dynamic_versioning["format-jinja"] = tomlkit.items.String.from_raw(
                            "\n".join(  # noqa: FLY002
                                [
                                    "",
                                    '{%- if env.get("VERSION_TYPE") == "version_branch" -%}',
                                    '{{serialize_pep440(bump_version(base, 1 if env.get("IS_MASTER") == "TRUE" else 2), dev=distance)}}',
                                    "{%- elif distance == 0 -%}",
                                    "{{serialize_pep440(base)}}",
                                    "{%- else -%}",
                                    "{{serialize_pep440(bump_version(base), dev=distance)}}",
                                    "{%- endif -%}",
                                    "",
                                ],
                            ),
                            tomlkit.items.StringType.MLB,
                        )
                        poetry_plugin_tweak_dependencies_version = pyproject.setdefault(
                            "tool",
                            {},
                        ).setdefault("poetry-plugin-tweak-dependencies-version", {})
                        poetry_plugin_tweak_dependencies_version.setdefault("default", "present")

                    pyproject.setdefault("tool", {}).setdefault("ruff", {})
                    pyproject["tool"]["ruff"].setdefault("target-version", "py310")
                    pyproject["tool"]["ruff"].setdefault("line-length", 110)
                    pyproject["tool"]["ruff"].setdefault("lint", {}).setdefault("pydocstyle", {}).setdefault(
                        "convention",
                        "numpy",
                    )
                    for rm_tool in ("mypy", "black", "isort"):
                        if rm_tool in pyproject["tool"]:
                            del pyproject["tool"][rm_tool]

                    if pyproject.get("tool", {}).get("poetry-dynamic-versioning", {}).get(
                        "format-jinja",
                        "",
                    ).strip() == "\n".join(  # noqa: FLY002
                        [
                            '{%- if env.get("VERSION_TYPE") == "version_branch" -%}',
                            '{{serialize_pep440(bump_version(base, 1 if env.get("IS_MASTER") == "TRUE" else 2), dev=distance)}}',
                            "{%- elif distance == 0 -%}",
                            "{{serialize_pep440(base)}}",
                            "{%- else -%}",
                            "{{serialize_pep440(bump_version(base), dev=distance)}}",
                            "{%- endif -%}",
                        ],
                    ):
                        pyproject["tool"]["poetry-dynamic-versioning"]["format-jinja"] = (
                            tomlkit.items.String.from_raw(
                                "\n".join(  # noqa: FLY002
                                    [
                                        "",
                                        '{%- if env.get("VERSION_TYPE") == "default_branch" -%}',
                                        "{{serialize_pep440(bump_version(base, 1), dev=distance)}}",
                                        '{%- elif env.get("VERSION_TYPE") == "stabilization_branch" -%}',
                                        "{{serialize_pep440(bump_version(base, 2), dev=distance)}}",
                                        "{%- elif distance == 0 -%}",
                                        "{{serialize_pep440(base)}}",
                                        "{%- else -%}",
                                        "{{serialize_pep440(bump_version(base), dev=distance)}}",
                                        "{%- endif -%}",
                                        "",
                                    ],
                                ),
                                tomlkit.items.StringType.MLB,
                            )
                        )


def _update_prospector_config(task_env: _TaskEnv) -> None:
    del task_env  # unused
    use_c2cwsgiutils = False
    proc = mra.run(
        ["git", "grep", "c2cwsgiutils"],
        exit_on_error=False,
        stdout=subprocess.DEVNULL,
    )
    for line in proc.stdout.split("\n") if proc.stdout is not None else []:
        if ".py:" in line and "/test_" not in line and "_test.py" not in line:
            use_c2cwsgiutils = True
            break
    has_bandit_file = False
    for bandit_filename in mra.run(
        ["git", "ls-files", ".bandit.yaml"],
        stdout=subprocess.PIPE,
    ).stdout.splitlines():
        has_bandit_file = Path(bandit_filename).exists()
        if has_bandit_file:
            Path(bandit_filename).unlink()
    for prospector_filename in [
        Path(p)
        for p in mra.run(["git", "ls-files", ".prospector.yaml"], stdout=subprocess.PIPE).stdout.splitlines()
    ]:
        with mra.EditYAML(prospector_filename) as prospector_config:
            if has_bandit_file and "bandit" in prospector_config:
                del prospector_config["bandit"]
            for inherit in (
                "utils:base",
                "utils:fix",
                *(["utils:c2cwsgiutils"] if use_c2cwsgiutils else []),
            ):
                if inherit not in prospector_config.get("inherits", []):
                    prospector_config["inherits"].append(inherit)

            # remove utils:unsafe from inherits
            for inherit in prospector_config.get("inherits", []):
                if inherit == "utils:unsafe":
                    prospector_config["inherits"].remove(inherit)

            for tag in ("strictness", "max-line-length", "doc-warnings"):
                if tag in prospector_config:
                    del prospector_config[tag]
            for tag in (
                "pylint",
                "pycodestyle",
                "pydocstyle",
                "bandit",
                "mypy",
                "mccabe",
            ):
                if "run" in prospector_config.get(tag, {}):
                    del prospector_config[tag]["run"]
                    if not prospector_config[tag]:
                        del prospector_config[tag]


# def _update_python_version(task_env: TaskEnv) -> None:
#    if task_env.min_python_version:
#        if os.exists("jsonschema-gentypes.yaml"):
#            with mra.Edit(Path("jsonschema-gentypes.yaml") as jsonschema_gentypes:
#                jsonschema_gentypes['python_version'] = task_env.min_python_version


def _update_renovate_config(task_env: _TaskEnv) -> None:
    if not Path(".github/renovate.json5").exists():
        return
    upgrade_required = False
    with mra.EditRenovateConfigV2() as renovate_config:
        if "regexManagers" in renovate_config:
            upgrade_required = True

    if upgrade_required:
        with mra.Edit(Path(".github/renovate.json5")) as renovate_config:
            renovate_config.data = renovate_config.data.replace("regexManagers", "customManagers")
        with mra.EditRenovateConfigV2() as renovate_config:
            for custom_manager in renovate_config["customManagers"]:
                custom_manager["customType"] = "regex"

    if task_env.c2cciutils_version >= version.parse("1.6.0") and not Path(".github/renovate.json5").exists():
        with mra.Edit(Path(".github/renovate.json5")) as renovate_config:
            renovate_config.data = "{}"

    with mra.EditRenovateConfigV2() as renovate_config:
        # Add $schema to the renovate configuration
        if "$schema" not in renovate_config:
            renovate_config["$schema"] = "https://docs.renovatebot.com/renovate-schema.json"

        # matchPackagePrefixes => matchPackageNames
        for package_rule in renovate_config.get("packageRules", []):
            if "matchPackagePrefixes" in package_rule:
                package_rule["matchPackageNames"] = [
                    f"/^{re.escape(prefix)}.*/" for prefix in package_rule["matchPackagePrefixes"]
                ]
                del package_rule["matchPackagePrefixes"]

        for extend in renovate_config["extends"]:
            if isinstance(extend, mra.JSON5RowAttribute) and extend.value.startswith(
                "github>camptocamp/gs-renovate-config-preset:preset.json5#",
            ):
                preset_version = version.parse(
                    extend.value[len("github>camptocamp/gs-renovate-config-preset:preset.json5#") :],
                )
                if preset_version < version.parse("0.8.0"):
                    extend.value = (
                        "github>camptocamp/gs-renovate-config-preset:preset.json5#"
                        + _VERSIONS["camptocamp/gs-renovate-config-preset"]
                    )

        extends = [(e, e if isinstance(e, str) else e.value) for e in renovate_config.get("extends", [])]
        extends_to_remove = [
            e
            for e, v in extends
            if v.startswith("config:")
            or v
            in (
                "group:monorepos",
                "group:recommended",
                "replacements:all",
                "workarounds:all",
                ":semanticCommitsDisabled",
            )
        ]
        for extend in extends_to_remove:
            renovate_config["extends"].remove(extend)
        extends = [
            v
            for _, v in extends
            if not v.startswith("config:")
            and v
            not in (
                "group:monorepos",
                "group:recommended",
                "replacements:all",
                "workarounds:all",
            )
        ]

        extends_base = [e.split("#")[0] for e in extends]
        for preset in (
            "base",
            "group",
            *(["stabilization-branches"] if task_env.has_stabilization_branches else []),
            "preset",
            "ci",
            "pre-commit",
            *(
                [
                    "python",
                    "security",
                ]
                if task_env.use_python
                else []
            ),
            *(
                [
                    "docker",
                ]
                if task_env.use_docker
                else []
            ),
            "own",
            "json-schema",
            "shellcheck",
        ):
            new_extend = (
                f"github>camptocamp/gs-renovate-config-preset:{preset}.json5#"
                + _VERSIONS["camptocamp/gs-renovate-config-preset"]
            )
            if new_extend.split("#")[0] not in extends_base:
                renovate_config["extends"].append(new_extend)

        # put profile base at first, group at second, and stabilization-branches as thirst.
        def cmp(extend1: mra.JSON5RowAttribute | str, extend2: mra.JSON5RowAttribute | str) -> int:
            if isinstance(extend1, mra.JSON5RowAttribute):
                extend1 = extend1.value
            if isinstance(extend2, mra.JSON5RowAttribute):
                extend2 = extend2.value
            for preset in ["base", "group", "stabilization-branches", "ci"]:
                if extend1.startswith(f"github>camptocamp/gs-renovate-config-preset:{preset}"):
                    return -1
                if extend2.startswith(f"github>camptocamp/gs-renovate-config-preset:{preset}"):
                    return 1
            return 0

        renovate_config["extends"] = mra.JSON5List(
            sorted(renovate_config["extends"], key=functools.cmp_to_key(cmp)),
        )
        for property_ in (
            "timezone",
            "schedule",
            "labels",
            "separateMajorMinor",
            "separateMinorPatch",
            "prHourlyLimit",
            "prConcurrentLimit",
            "lockFileMaintenance",
            "semanticCommits",
            "osvVulnerabilityAlerts",
            "vulnerabilityAlerts",
            "dependencyDashboard",
        ):
            if property_ in renovate_config:
                del renovate_config[property_]
        if "html" in renovate_config and (
            renovate_config["html"] == {"fileMatch": ["\\.html?$", "\\.html?.mako$"]}
            or renovate_config["html"] == {"fileMatch": ["\\.html?$"]}
            or renovate_config["html"] == {"fileMatch": ["\\.html?.mako$"]}
        ):
            del renovate_config["html"]

        renovate_config.remove_package_rule({}, ["Group and auto merge the patch updates"])
        renovate_config.remove_package_rule({}, ["Group and auto merge the minor updates"])

        # CI
        renovate_config.remove_package_rule({}, ["Group the dev dependency update"])
        renovate_config.remove_package_rule({}, ["Auto merge the dev dependency update"])
        renovate_config.remove_package_rule({}, ["Group and auto merge the CI dependencies"])

        # pre-commit
        if "pre-commit" in renovate_config:
            del renovate_config["pre-commit"]
        renovate_config.remove_regex_manager({}, ["Do updates on pre-commit additional dependencies"])

        # python
        renovate_config.remove_package_rule({}, ["Ungroup Python dependencies"])
        renovate_config.remove_regex_manager({}, ["Python version in actions/setup-python action"])
        renovate_config.remove_package_rule({}, ["In file .python-version, use the <major>.<minor> version"])
        renovate_config.remove_package_rule(
            {},
            ["In file `.python-version`, use the `<major>.<minor>` version"],
        )

        # json-schema
        renovate_config.remove_regex_manager({}, ["Do update on the schema present in the YAML files"])

        # shellcheck
        renovate_config.remove_package_rule(
            {},
            ["Support the 4 parts of shellcheck-py version with a v prefix"],
        )

        renovate_config.remove_package_rule({}, ["Update dpkg versions at any time"])
        renovate_config.remove_regex_manager({}, ["Do update on the schema present in the ci/config.yaml"])

        if not task_env.has_stabilization_branches or task_env.stabilization_branches == ["master"]:
            if "baseBranches" in renovate_config:
                del renovate_config["baseBranches"]
            renovate_config.remove_package_rule({}, ["Accept only the patch on stabilization branches"])
            renovate_config.remove_package_rule({}, ["Accept only the patch on the stabilization branches"])

        renovate_config.remove_package_rule({}, ["In file .python-version, use the <major>.<minor> version"])
        if Path(".python-version").exists():
            renovate_config.add_package_rule(
                {
                    "matchFileNames": [".python-version"],
                    "versioning": "regex:^(?<major>\\d+)\\.(?<minor>\\d+)$",
                },
                ["In file `.python-version`, use the `<major>.<minor>` version"],
            )

        renovate_config.remove_package_rule({}, ["Group Poetry packages"])
        if "packageRules" in renovate_config and not renovate_config["packageRules"]:
            del renovate_config["packageRules"]
        if "customManagers" in renovate_config and not renovate_config["customManagers"]:
            del renovate_config["customManagers"]


def _update_config(task_env: _TaskEnv) -> None:
    ci_config = Path("ci/config.yaml")
    if ci_config.exists() and task_env.c2cciutils_version >= version.parse("1.6.0"):
        with mra.EditYAML(ci_config) as config:
            if "checks" in config:
                del config["checks"]
            to_delete = len(config.keys()) == 0
        if to_delete:
            ci_config.unlink()


def _update_pre_commit_config(task_env: _TaskEnv) -> None:
    if Path(".pre-commit-config.yaml").exists():
        with mra.EditPreCommitConfig() as pre_commit_config:
            if "ci" in pre_commit_config:
                del pre_commit_config["ci"]

            if Path(".github/renovate.json5").exists():
                pre_commit_config.add_repo(
                    "https://github.com/renovatebot/pre-commit-hooks",
                    _VERSIONS["renovatebot/pre-commit-hooks"],
                )
                pre_commit_config.add_hook(
                    "https://github.com/renovatebot/pre-commit-hooks",
                    {
                        "id": "renovate-config-validator",
                    },
                )

            filenames = {
                Path(".github/publish.yaml"),
                Path(".github/ghci.yaml"),
                Path("jsonschema_gentype.yaml"),
                Path("ci/config.yaml"),
            }
            one_exists = False
            for filepath in filenames:
                if filepath.exists():
                    one_exists = True
                    break
            if one_exists:
                pre_commit_config.add_repo(
                    "https://github.com/sbrunner/jsonschema-validator",
                    _VERSIONS["sbrunner/jsonschema-validator"],
                )
                pre_commit_config.add_hook(
                    "https://github.com/sbrunner/jsonschema-validator",
                    {"id": "jsonschema-validator"},
                )
            for repo in pre_commit_config["repos"]:
                if repo["repo"] == "https://github.com/sbrunner/jsonschema-validator":
                    files = repo["hooks"][0].get("files", "").strip()
                    if files.startswith(r"(?x)^("):
                        files = files[len(r"(?x)^(") :]
                    elif files.startswith(r"^"):
                        files = files[len(r"^") :]
                    if files.endswith(r")$"):
                        files = files[: -len(r")$")]
                    elif files.endswith(r"$"):
                        files = files[: -len(r"$")]
                    files_split = files.split("\n")
                    files_split = [f.strip() for f in files_split]
                    files_split = [f.lstrip("|") for f in files_split]
                    files_split = [f for f in files_split if f]

                    filenames_proc = mra.run(
                        ["git", "grep", r"# yaml-language-server: \$schema=https://"],
                        stdout=subprocess.PIPE,
                        exit_on_error=False,
                    )
                    if filenames_proc.stdout is not None:
                        for line in filenames_proc.stdout.split("\n"):
                            if line:
                                filename = line.split(":")[0]
                                if filename.endswith(".yaml"):
                                    filenames |= {filename}
                    for filename in filenames:
                        filename_re = re.escape(str(filename))
                        if filename.exists():
                            if filename_re not in files_split:
                                files_split.append(filename_re)
                        elif filename_re in files_split:
                            files_split.remove(filename_re)

                    repo["hooks"][0]["files"] = pre_commit_config.create_files_regex(files_split)

                    break

            # Do a spell check on the found schemas
            schemas = []
            for files_ in ("*.schema.json", "schema.json", "schema-*.json"):
                schemas += [
                    f
                    for f in mra.run(["git", "ls-files", files_], stdout=subprocess.PIPE).stdout.split("\n")
                    if f
                ]
                # Get all the schemas files
                schemas += [
                    f
                    for f in mra.run(
                        ["git", "ls-files", f"**/{files_}"],
                        stdout=subprocess.PIPE,
                    ).stdout.split("\n")
                    if f
                ]

            if schemas:
                pre_commit_config.add_repo(
                    "https://github.com/mheap/json-schema-spell-checker",
                    _VERSIONS["mheap/json-schema-spell-checker"],
                )
                pre_commit_config.add_hook(
                    "https://github.com/mheap/json-schema-spell-checker",
                    {
                        "id": "json-schema-spell-checker",
                        "files": pre_commit_config.create_files_regex([re.escape(f) for f in schemas]),
                        "args": [
                            "--fields=description,title",
                            "--spelling=.github/spell-ignore-words.txt",
                            "--ignore-numbers",
                            "--ignore-acronyms",
                            "--en-us",
                        ],
                    },
                )

            pre_commit_config.add_repo(
                "https://github.com/sbrunner/hooks",
                _VERSIONS["sbrunner/hooks"],
            )
            pre_commit_config.add_hook(
                "https://github.com/sbrunner/hooks",
                {
                    "id": "canonicalize",
                },
            )

            for repo in pre_commit_config["repos"]:
                if repo["repo"] == "https://github.com/python-jsonschema/check-jsonschema":
                    for index, hook in enumerate(list(repo["hooks"])):
                        if hook["id"] == "check-renovate":
                            del repo["hooks"][index]
                            break
                if repo["repo"] == "https://github.com/sbrunner/hooks":
                    for index, hook in enumerate(list(repo["hooks"])):
                        if hook["id"] == "poetry-check":
                            del repo["hooks"][index]
                            break

            if task_env.use_python:
                rm_repos = (
                    "https://github.com/psf/black",
                    "https://github.com/PyCQA/isort",
                    "https://github.com/PyCQA/autoflake",
                    "https://github.com/asottile/pyupgrade",
                    "https://github.com/PyCQA/docformatter",
                )
                continue_ = True
                while continue_:
                    continue_ = False
                    for name, repo in enumerate(list(pre_commit_config["repos"])):
                        if repo["repo"] in rm_repos:
                            del pre_commit_config["repos"][name]
                            continue_ = True
                            break

                if task_env.prospector_path:
                    pre_commit_config.add_repo(
                        "https://github.com/PyCQA/prospector",
                        _VERSIONS["PyCQA/prospector"],
                    )
                    pre_commit_config.add_hook(
                        "https://github.com/PyCQA/prospector",
                        {
                            "id": "prospector",
                            "args": [
                                "--die-on-tool-error",
                                "--output-format=pylint",
                                f"--profile={task_env.prospector_path}",
                            ],
                        },
                    )
                    if (
                        "prospector"
                        in pre_commit_config.repos_hooks["https://github.com/PyCQA/prospector"]["hooks"]
                    ):
                        prospector_hooks = pre_commit_config.repos_hooks[
                            "https://github.com/PyCQA/prospector"
                        ]["hooks"]["prospector"]
                        prospector_hooks[0]["args"] = [
                            arg
                            for arg in prospector_hooks[0].get("args", [])
                            if not arg.startswith("--tool=")
                            and arg
                            not in (
                                "--profile=utils:autofix",
                                "--profile=utils:pre-commit",
                            )
                        ]
                        prospector_hooks[0]["args"] = [
                            "--profile=utils:pre-commit",
                            *prospector_hooks[0]["args"],
                        ]
                        if "exclude" not in prospector_hooks[0]:
                            prospector_hooks[0]["exclude"] = ruamel.yaml.scalarstring.LiteralScalarString(
                                "\n".join(  # noqa: FLY002
                                    [
                                        "(?x)(",
                                        "  ^tests?/?",
                                        "  |/tests?(/|$)",
                                        "  |.*/tests(/|$)",
                                        "  |(^|/)test_[_a-zA-Z0-9]+.py$",
                                        "  |(^|/)[_a-zA-Z0-9]+_tests?.py$",
                                        "  |(^|/)tests?.py$",
                                        ")",
                                    ],
                                ),
                            )
                        current_deps = [
                            deps.split("=")[0]
                            for deps in prospector_hooks[0].get("additional_dependencies", [])
                        ]
                        for deps in [
                            "prospector-profile-duplicated==" + _VERSIONS["prospector-profile-duplicated"],
                            "prospector-profile-utils==" + _VERSIONS["prospector-profile-utils"],
                            # "ruff==" + _VERSIONS["ruff"],
                        ]:
                            if deps.split("=")[0] not in current_deps:
                                pre_commit_config.add_commented_additional_dependencies(
                                    prospector_hooks[0],
                                    [deps],
                                    "pypi",
                                )
                        if len(prospector_hooks) == 1:
                            pre_commit_config.add_hook(
                                "https://github.com/PyCQA/prospector",
                                {
                                    "id": "prospector",
                                    "args": [
                                        "--die-on-tool-error",
                                        "--output-format=pylint",
                                        "--profile=utils:tests",
                                        "--profile=utils:pre-commit",
                                    ],
                                },
                                force=True,
                            )
                            pre_commit_config.add_commented_additional_dependencies(
                                prospector_hooks[1],
                                [
                                    "prospector-profile-utils==" + _VERSIONS["prospector-profile-utils"],
                                    # "ruff==" + _VERSIONS["ruff"],
                                ],
                                "pypi",
                            )
                        else:
                            prospector_hooks[1]["args"] = [
                                arg
                                for arg in prospector_hooks[1]["args"]
                                if not arg.startswith("--tool=") and arg != "--profile=utils:autofix"
                            ]
                            if "--profile=utils:pre-commit" not in prospector_hooks[1]["args"]:
                                prospector_hooks[1]["args"].append("--profile=utils:pre-commit")
                pre_commit_config.add_repo(
                    "https://github.com/astral-sh/ruff-pre-commit",
                    _VERSIONS["astral-sh/ruff-pre-commit"],
                )
                pre_commit_config.add_hook(
                    "https://github.com/astral-sh/ruff-pre-commit",
                    {"id": "ruff-format"},
                )

                pre_commit_config.add_repo(
                    "https://github.com/sbrunner/python-versions-hook",
                    _VERSIONS["sbrunner/python-versions-hook"],
                )
                pre_commit_config.add_hook(
                    "https://github.com/sbrunner/python-versions-hook",
                    {
                        "id": "python-versions",
                    },
                )
                pre_commit_config.add_repo(
                    "https://github.com/sbrunner/python-versions-hook",
                    _VERSIONS["sbrunner/python-versions-hook"],
                )
                pre_commit_config.add_hook(
                    "https://github.com/sbrunner/python-versions-hook",
                    {
                        "id": "python-versions",
                    },
                )


def _use_tag_publish(task_env: _TaskEnv) -> None:
    del task_env  # unused
    if not Path(".github/workflows/main.yaml").exists():
        return

    add_tag_publish = False
    with mra.EditYAML(Path(".github/workflows/main.yaml")) as yaml:
        for job in yaml["jobs"].values():
            for step in job["steps"]:
                if step.get("run", "").startswith("tag-publish"):
                    add_tag_publish = True
                elif step.get("run", "").startswith("c2cciutils-publish"):
                    add_tag_publish = True
                    step["run"] = step["run"].replace("c2cciutils-publish", "tag-publish")
                    step.setdefault("env", {})["GITHUB_TOKEN"] = (  # nosec
                        "${{ secrets.GITHUB_TOKEN }}"  # noqa: S105
                    )

    if not add_tag_publish:
        return

    for candidate_requirements_filename in (
        Path(".github/requirements.txt"),
        Path("ci/requirements.txt"),
        Path("requirements.txt"),
    ):
        if candidate_requirements_filename.exists():
            with mra.Edit(candidate_requirements_filename) as requirements_txt:
                requirements_lines = requirements_txt.data.strip().split("\n")
                for index, line in enumerate(requirements_lines):
                    if line.startswith("tag=="):
                        del requirements_lines[index]
                if "c2cciutils" in requirements_txt.data:
                    c2cciutils_index = -1
                    c2cciutils_extra = []
                    c2cciutils_version = ""
                    c2cciutils_re = re.compile(r"c2cciutils\[(.*)\]==(.*)")
                    for index, line in enumerate(requirements_lines):
                        match = c2cciutils_re.match(line)
                        if match is not None:
                            c2cciutils_index = index
                            c2cciutils_extra = match.group(1).split(",")
                            c2cciutils_version = match.group(2)
                            break

                    if c2cciutils_index >= 0:
                        for rm_extra in ("checks", "publish"):
                            if rm_extra in c2cciutils_extra:
                                c2cciutils_extra.remove(rm_extra)
                        if c2cciutils_extra:
                            requirements_lines[c2cciutils_index] = (
                                "c2cciutils["
                                + ",".join(c2cciutils_extra)
                                + ",tag-publish]=="
                                + c2cciutils_version
                            )
                        else:
                            requirements_lines[c2cciutils_index] = "c2cciutils==" + c2cciutils_version

                    if "tag-publish" not in requirements_txt.data:
                        requirements_lines.append(f"tag-publish=={_VERSIONS['tag-publish']}")
                    requirements_txt.data = "\n".join(requirements_lines) + "\n"


def _remove_docker_compose_version(task_env: _TaskEnv) -> None:
    del task_env  # unused
    for docker_compose_filename in [
        *Path().rglob("**/docker-compose.yaml"),
        *Path().rglob("**/docker-compose.*.yaml"),
        *Path().rglob("**/docker-compose-*.yaml"),
        *Path().rglob("docker-compose.yaml"),
        *Path().rglob("docker-compose.*.yaml"),
        *Path().rglob("docker-compose-*.yaml"),
    ]:
        with mra.EditYAML(docker_compose_filename) as docker_compose:
            if "version" in docker_compose:
                del docker_compose["version"]


def _get_env() -> _TaskEnv:
    config = _Config()

    use_helm = config.enabled(
        "helm",
        Path("Chart.yaml").exists() or Path("test/helmchart/Chart.yaml").exists(),
    )

    gopass_ = config.enabled(
        "gopass",
        "no-gopass" not in config.repo.get("types", [])
        and (config.repo["name"].startswith("camptocamp/") or config.repo["name"].startswith("mapfish/")),
    )
    # Get the string we used in the workflow to get the GitHub token to be used
    token = config.value(
        "github_token_secret",
        "${{ secrets.GOPASS_CI_GITHUB_TOKEN }}" if gopass_ else "${{ secrets.TOKEN }}",
    )

    # Get the version of c2cciutils
    c2cciutils_version = version.parse("1.6.0")
    set_c2cciutils_version = False
    requirements = Path(".github/requirements.txt")
    requirements = requirements if requirements.exists() else Path("ci/requirements.txt")
    if requirements.exists():
        with mra.Edit(requirements) as requirements_txt:
            requirements = [
                r for r in requirements_txt.data.split("\n") if r.startswith(("c2cciutils==", "c2cciutils["))
            ]
            if len(requirements) == 1:
                c2cciutils_version_string = requirements[0].split("==")[1]
                c2cciutils_version_string = c2cciutils_version_string.removesuffix(".*")
                c2cciutils_version = version.parse(c2cciutils_version_string)
                set_c2cciutils_version = True
    c2cciutils_version_config = config.value("c2cciutils_version")
    if c2cciutils_version_config:
        if c2cciutils_version_config == "master":
            c2cciutils_version = version.parse("1.6.0")
            set_c2cciutils_version = False
        else:
            c2cciutils_version = version.parse(c2cciutils_version_config)
            set_c2cciutils_version = True

    prospector_path = None
    prospector_candidate_path = [
        Path(".prospector.yaml"),
        Path("app/.prospector.yaml"),
        Path("api/.prospector.yaml"),
        Path("docker/.prospector.yaml"),
    ]

    use_python = False
    pyproject_path = None
    for prospector_path_candidate in prospector_candidate_path:
        if prospector_path_candidate.exists():
            prospector_path = prospector_path_candidate
            break

    # min_python_version = ''
    # max_python_version = ''
    for pyproject_filename in (
        Path("pyproject.toml"),
        Path("app/pyproject.toml"),
        Path("api/pyproject.toml"),
        Path("docker/pyproject.toml"),
    ):
        if pyproject_filename.exists():
            pyproject_path = pyproject_filename
            with mra.EditTOML(pyproject_filename) as pyproject:
                use_python = "project" in pyproject or "build-system" in pyproject
                # min_python_version = pyproject.get("tool", {}).get("poetry", {}).get("dependencies", {}).get("python", "")
                # match = re.match(r"^>=(\d+\.\d+),<(\d+)\.(\d+)$", min_python_version)
                # if match:
                #    min_python_version = match.group(1)
                #    max_python_version_major = int(match.group(2))
                #    max_python_version_minor = int(match.group(3))
                #    if max_python_version_major == 4:
                #        max_python_version = "3.13"
                #    else:
                #        max_python_version = f"{max_python_version_major}.{max_python_version_minor-1}"

                break
    use_python = config.enabled("python", use_python)
    pyproject_path = config.value("pyproject_path", pyproject_path)
    prospector_path = config.value("prospector_path", prospector_path)

    use_pypi = config.enabled("pypi", use_python and "no-pypi" not in config.repo.get("type", []))
    use_docker = config.enabled(
        "docker",
        (Path("Dockerfile").exists() or Path("app/Dockerfile").exists() or Path("api/Dockerfile").exists())
        and "no-docker" not in config.repo.get("type", []),
    )

    stabilization_branches = mra.get_stabilization_branches(config.repo)

    print("Task environment:")
    print(f"  c2cciutils_version: {c2cciutils_version}")
    print(f"  Set c2cciutils version: {set_c2cciutils_version}")
    print(f"  Use Python: {use_python}")
    print(f"  pyproject_path: {pyproject_path}")
    print(f"  Prospector_path: {prospector_path}")
    print(f"  Use pypi: {use_pypi}")
    print(f"  Use Docker: {use_docker}")
    print(f"  Use Helm: {use_helm}")
    print(f"  On stabilization branches: {config.arguments.on_stabilization_branches}")
    print(f"  Has stabilization branches: {len(stabilization_branches) > 0}")
    print(f"  Stabilization branches: {stabilization_branches}")
    print(f"  GoPass: {gopass}")

    return _TaskEnv(
        GitHub(_TOKEN),
        c2cciutils_version,
        set_c2cciutils_version,
        use_python,
        # min_python_version,
        # max_python_version,
        pyproject_path,
        prospector_path,
        use_pypi,
        use_docker,
        use_helm,
        config.arguments.on_stabilization_branches or len(stabilization_branches) > 0,
        config.arguments.on_stabilization_branches and len(stabilization_branches) > 0,
        stabilization_branches,
        gopass,
        token,
        config,
    )


def _ghci_updates(task_env: _TaskEnv) -> None:
    if (
        task_env.use_helm
        and not Path(".github/ghci.yaml").exists()
        and not task_env.on_stabilization_branches
    ):
        with Path(".github/ghci.yaml").open("w", encoding="utf-8") as ghci:
            ghci.write(
                """# yaml-language-server: $schema=https://geoservices-int.camptocamp.com/github/schema.json

profile: helm
""",
            )


def _do() -> None:
    task_env = _get_env()
    print(f"Task environment: {task_env}")

    for name, task in (
        ("clean-update-workflow", _clean_update_workflow),
        (
            "update-dependency-auto-review-workflow",
            _update_pull_request_automation_workflow,
        ),
    ):
        if task_env.config.enabled(name, default=True):
            task(task_env)
    if task_env.on_stabilization_branches:
        for file_ in (
            Path(".github/workflows/delete-old-workflow-run.yaml"),
            Path(".github/workflows/delete-old-workflows-run.yaml"),
            Path(".github/renovate.json5"),
        ):
            if file_.exists():
                file_.unlink()
        for file_ in Path(".github/workflows").glob("audit*.yaml"):
            file_.unlink()
        for file_ in Path(".github/workflows").glob("rebuild*.yaml"):
            file_.unlink()

    else:
        for name, task in (
            # ("upgrade-ubuntu", _upgrade_ubuntu),
            ("create-labels", _create_labels),
            ("update-clean-workflow", _update_clean_workflow),
            ("tag-publish-config", _tag_publish_config),
            ("update-audit-workflow", _update_audit_workflow),
            (
                "update-delete-old-workflow-run-workflow",
                _update_delete_old_workflows_run_workflow,
            ),
            ("update-pyproject-toml", _update_pyproject_toml),
            ("update-prospector-config", _update_prospector_config),
            # ("update-python-version", _update_python_version),
            ("update-renovate-config", _update_renovate_config),
            ("update-config", _update_config),
            ("update-pre-commit-config", _update_pre_commit_config),
            ("remove-docker-compose-version", _remove_docker_compose_version),
            ("set-schema-config", _set_schema_config),
            ("update-main-workflow", _update_main_workflow),
            ("update-ghci", _ghci_updates),
            ("use-tag-publish", _use_tag_publish),
            ("update-dockerfile", _update_dockerfile),
        ):
            if task_env.config.enabled(name, default=True):
                task(task_env)


if __name__ == "__main__":
    os.environ["IGNORE_CONFIG_ERROR"] = "true"

    mra.main(
        _do,
        # pull_request_on_stabilization_branches
        # pull_request_title
        # pull_request_body
        # branch
        # pull_request_branch_prefix
        config={
            "branch": "ci-upgrade",
            "pull_request_branch_prefix": "ci-upgrade-",
            "pull_request_title": "CI updates",
            "pull_request_body": "This is done by the automated script named " + Path(__file__).name,
        },
        description="Update the repository for the CI evolutions",
    )
