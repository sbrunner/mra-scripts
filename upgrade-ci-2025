#!/usr/bin/env python3

# TODO:
# Warning: [tool.poetry.name] is deprecated. Use [project.name] instead.
# Warning: [tool.poetry.version] is set but 'version' is not in [project.dynamic]. If it is static use [project.version]. If it is dynamic, add 'version' to [project.dynamic].
# If you want to set the version dynamically via `poetry build --local-version` or you are using a plugin, which sets the version dynamically, you should define the version in [tool.poetry] and add 'version' to [project.dynamic].
# Warning: [tool.poetry.description] is deprecated. Use [project.description] instead.
# Warning: [tool.poetry.readme] is set but 'readme' is not in [project.dynamic]. If it is static use [project.readme]. If it is dynamic, add 'readme' to [project.dynamic].
# If you want to define multiple readmes, you should define them in [tool.poetry] and add 'readme' to [project.dynamic].
# Warning: [tool.poetry.license] is deprecated. Use [project.license] instead.
# Warning: [tool.poetry.authors] is deprecated. Use [project.authors] instead.
# Warning: [tool.poetry.keywords] is deprecated. Use [project.keywords] instead.
# Warning: [tool.poetry.classifiers] is set but 'classifiers' is not in [project.dynamic]. If it is static use [project.classifiers]. If it is dynamic, add 'classifiers' to [project.dynamic].
# ATTENTION: Per default Poetry determines classifiers for supported Python versions and license automatically. If you define classifiers in [project], you disable the automatic enrichment. In other words, you have to define all classifiers manually. If you want to use Poetry's automatic enrichment of classifiers, you should define them in [tool.poetry] and add 'classifiers' to [project.dynamic].
# Warning: [tool.poetry.homepage] is deprecated. Use [project.urls] instead.
# Warning: [tool.poetry.repository] is deprecated. Use [project.urls] instead.
# Warning: [tool.poetry.extras] is deprecated. Use [project.optional-dependencies] instead.
# Warning: Defining console scripts in [tool.poetry.scripts] is deprecated. Use [project.scripts] instead. ([tool.poetry.scripts] should only be used for scripts of type 'file').

import glob
import os
import re
import subprocess
from pathlib import Path
from typing import Any, AnyStr, NamedTuple, Optional, Union
import functools
import c2cciutils
import multi_repo_automation as mra
import ruamel.yaml.comments
import ruamel.yaml.scalarstring
import tomlkit.items
import yaml as py_yaml
from packaging import version

# if os.path.exists(".github/renovate.json5"):
# if mra.run(["grep", "text", ".github/renovate.json5"], exit_on_error=False).returncode != 0: # not found
# if mra.git_grep(r"\<text\>"]): # found
# if mra.run(["git", "ls-files", "**/*.txt"], stdout=subprocess.PIPE).stdout.strip() != b"": # found
# mra.edit("file")
# input()

_VERSIONS = {}
with open(Path(__file__).parent / "versions.yaml", encoding="utf-8") as f:
    _VERSIONS = py_yaml.load(f, Loader=py_yaml.SafeLoader)


class Config:
    _values: dict[str, Any] = {}
    _enabled: list[str] = []
    _disabled: list[str] = []

    def __init__(self) -> None:
        self.repo = mra.get_repo_config()
        self.arguments = mra.get_arguments()

        if os.path.exists(".github/ci-upgrade.yaml"):
            with open(".github/ci-upgrade.yaml", encoding="utf-8") as f:
                upgrade_config = py_yaml.load(f.read(), Loader=py_yaml.SafeLoader)
                self._values = upgrade_config.get("values", {})
                self._enabled = upgrade_config.get("enabled", [])
                self._disabled = upgrade_config.get("disabled", [])

    def value(self, name: str, default: Any = None) -> Any:
        return self._values.get(name, default)

    def enabled(self, name: str, default: bool) -> bool:
        if name in self._enabled:
            return True
        if name in self._disabled:
            return False
        return default


class TaskEnv(NamedTuple):
    c2cciutils_version: version.Version
    set_c2cciutils_version: bool
    use_python: bool
    # min_python_version: str
    # max_python_version: str
    use_pypi: bool
    use_docker: bool
    use_helm: bool
    has_stabilization_branches: bool
    on_stabilization_branches: bool
    stabilization_branches: list[str]
    gopass: bool
    token: str
    config: Config


def _order_keys(
    data: dict[str, Any], first_keys: list[str], last_keys: Optional[list[str]] = None
) -> ruamel.yaml.comments.CommentedMap:
    if last_keys is None:
        last_keys = []

    # use order: <first_keys>, <other>, <last_keys>
    new_data = []
    for key in first_keys:
        if key in data:
            new_data.append((key, data[key]))

    new_data += [e for e in data.items() if e[0] not in [*first_keys, *last_keys]]

    for key in last_keys:
        if key in data:
            new_data.append((key, data[key]))

    return ruamel.yaml.comments.CommentedMap(new_data)


def _order_sub_keys(
    data: Union[dict[str, dict[str, Any]], list[dict[str, AnyStr]]],
    first_keys: list[str],
    last_keys: Optional[list[str]] = None,
) -> None:
    items = data.items() if isinstance(data, dict) else enumerate(data)
    for key, value in items:
        # copy the last comment
        comment = None
        if hasattr(value, "ca"):
            last_value = list(value.values())[-1]
            if isinstance(last_value, dict) and hasattr(last_value, "ca"):
                last_last_key = list(last_value.keys())[-1]
                comment = last_value.ca.items.get(last_last_key)
                if comment is not None:
                    del last_value.ca.items[last_last_key]
            else:
                comment = value.ca.items.get(list(value.keys())[-1])
        data[key] = _order_keys(value, first_keys, last_keys)
        if comment is not None:
            last_key = list(data[key].keys())[-1]
            if isinstance(data[key][last_key], ruamel.yaml.comments.CommentedMap):
                last_last_key = list(data[key][last_key].keys())[-1]
                data[key][last_key].ca.items[last_last_key] = comment
            else:
                data[key].ca.items[last_key] = comment


def _canonicalize_workflow(workflow: mra.EditYAML) -> None:
    workflow.data = _order_keys(
        workflow.data, ["name", "on", "permissions", "env"], ["jobs"]
    )

    # Add space after simple key
    for key in ["name"]:
        workflow.data.ca.items[key] = [
            None,
            None,
            ruamel.yaml.CommentToken("\n\n", ruamel.yaml.error.CommentMark(0), None),
            None,
        ]

    # add space after complex keys
    for key in ["on", "permissions", "env", "jobs"]:
        workflow.data.ca.items[key] = [
            None,
            [ruamel.yaml.CommentToken("\n", ruamel.yaml.error.CommentMark(0), None)],
            None,
            None,
        ]

    for name, job in workflow["jobs"].items():
        job = _order_keys(
            job,
            ["name", "runs-on", "timeout-minutes", "if", "concurrency", "needs"],
            ["strategy", "env", "steps"],
        )
        workflow["jobs"][name] = job

        for key in reversed(
            ["name", "runs-on", "timeout-minutes", "if", "concurrency", "needs"]
        ):
            if key in job:
                job.ca.items[key] = [
                    None,
                    None,
                    ruamel.yaml.CommentToken(
                        "\n\n", ruamel.yaml.error.CommentMark(0), None
                    ),
                    None,
                ]
                break

        for key in reversed(["strategy", "env"]):
            if key in job:
                job.ca.items[key] = [
                    None,
                    None,
                    ruamel.yaml.CommentToken(
                        "\n\n", ruamel.yaml.error.CommentMark(0), None
                    ),
                    None,
                ]

        for job in workflow["jobs"].values():
            if "steps" in job:
                _order_sub_keys(
                    job["steps"], ["name"], ["uses", "with", "run", "env", "if"]
                )


def _create_labels(task_env: TaskEnv) -> None:
    mra.gh(
        "label",
        "create",
        "--force",
        "dependencies",
        "--color=0075ca",
        "--description=Update the dependencies",
    )
    if task_env.config.enabled("pullRequestWelcome", False):
        mra.gh(
            "label",
            "create",
            "--force",
            "pull request welcome",
            "--color=6622BB",
            "--description=A pull request is welcome to fix this issue",
        )


def _merge(default_config: Any, config: Any) -> Any:
    """
    Deep merge the dictionaries (on dictionaries only, not on arrays).

    Arguments:
        default_config: The default config that will be applied
        config: The base config, will be modified
    """
    if not isinstance(default_config, dict) or not isinstance(config, dict):
        return config

    for key in default_config.keys():
        if key not in config:
            config[key] = default_config[key]
        else:
            _merge(default_config[key], config[key])
    return config


def _get_repository() -> str:
    """
    Get the current GitHub repository like `organization/project`.
    """
    if "GITHUB_REPOSITORY" in os.environ:
        return os.environ["GITHUB_REPOSITORY"]

    remote_lines = (
        subprocess.check_output(["git", "remote", "--verbose"]).decode().split("\n")
    )
    remote_match = (
        re.match(r".*git@github.com:(.*).git .*", remote_lines[0])
        if len(remote_lines) >= 1
        else None
    )

    if remote_match:
        return remote_match.group(1)

    print("::warning::The GitHub repository isn't found, using 'camptocamp/project'")

    return "camptocamp/project"


def _get_master_branch(repo: list[str]) -> tuple[str, bool]:
    """Get the name of the master branch."""
    master_branch = "master"
    success = False
    try:
        default_branch_json = c2cciutils.graphql(
            "default_branch.graphql", {"name": repo[1], "owner": repo[0]}, default=False
        )
        success = default_branch_json is not False
        master_branch = (
            default_branch_json["repository"]["defaultBranchRef"]["name"]
            if success
            else "master"
        )
    except RuntimeError as runtime_error:
        print(runtime_error)
        print("::warning::Fallback to master")
    return master_branch, success


def _get_c2cciutils_1_8_config(config: dict[str, Any]) -> dict[str, Any]:
    """
    Get the configuration, with project and auto detections.
    """

    repository = _get_repository()
    repo = repository.split("/")
    master_branch, _ = _get_master_branch(repo)

    # _merge(
    #    {
    #        "version": {
    #            "tag_to_version_re": [
    #                {"from": r"([0-9]+.[0-9]+.[0-9]+)", "to": r"\1"},
    #            ],
    #            "branch_to_version_re": [
    #                {"from": r"([0-9]+.[0-9]+)", "to": r"\1"},
    #                {"from": master_branch, "to": master_branch},
    #            ],
    #        }
    #    },
    #    config,
    # )

    has_docker_files = bool(
        subprocess.run(
            ["git", "ls-files", "*/Dockerfile*", "Dockerfile*"],
            stdout=subprocess.PIPE,
            check=True,
        ).stdout
    )
    has_python_package = bool(
        subprocess.run(
            ["git", "ls-files", "setup.py", "*/setup.py"],
            stdout=subprocess.PIPE,
            check=True,
        ).stdout
    ) or bool(
        subprocess.run(
            ["git", "ls-files", "pyproject.toml", "*/pyproject.toml"],
            stdout=subprocess.PIPE,
            check=True,
        ).stdout
    )

    publish_config = _merge(c2cciutils.configuration.PUBLISH_DEFAULT, {})
    publish_config["pypi"]["packages"] = [{"path": "."}] if has_python_package else []
    publish_config["docker"]["images"] = (
        [{"name": _get_repository()}] if has_docker_files else []
    )
    publish_config["helm"]["folders"] = [
        os.path.dirname(f) for f in glob.glob("./**/Chart.yaml", recursive=True)
    ]

    default_config = {
        "publish": publish_config,
    }
    _merge(default_config, config)

    return config


def _tag_publish_config(task_env: TaskEnv) -> None:
    if os.path.exists(".github/publish.yaml"):
        return

    if not os.path.exists("ci/config.yaml"):
        filled_config = _get_c2cciutils_1_8_config({})
    else:
        with mra.EditYAML("ci/config.yaml") as config:
            filled_config = _get_c2cciutils_1_8_config(config)

    if "publish" not in filled_config:
        return

    if os.path.exists("ci/dpkg-versions.yaml"):
        mra.run(["git", "mv", "ci/dpkg-versions.yaml", ".github/"])

    with mra.EditYAML(".github/publish.yaml") as publish:
        publish.data = filled_config["publish"]
        if "helm" in publish and "folders" in publish["helm"]:
            publish["helm"]["packages"] = [
                {"folder": f} for f in publish["helm"]["folders"]
            ]
            del publish["helm"]["folders"]
        if "dispatch" not in publish:
            publish["dispatch"] = [{}]
        if "version_transform" in filled_config:
            publish["version_transform"] = filled_config["version_transform"]

        for package in publish.get("pypi", {}).get("packages", []):
            if package["path"] == ".":
                del package["path"]
        if publish.get("pypi", {}).get("versions", []) == ["version_tag"]:
            del publish["pypi"]["versions"]
        if publish.get("helm", {}).get("versions", []) == ["version_tag"]:
            del publish["helm"]["versions"]
        if "repository" in publish.get("docker", {}):
            del publish["docker"]["repository"]
        if "print_versions" in publish:
            del publish["print_versions"]

        if "pypi" in publish and not publish["pypi"].get("packages", []):
            del publish["pypi"]
        if "docker" in publish and not publish["docker"].get("images", []):
            del publish["docker"]
        if "docker" in publish and "dispatch" in publish["docker"]:
            del publish["docker"]["dispatch"]
        if "helm" in publish and not publish["helm"].get("packages", []):
            del publish["helm"]

        def migrate_versions(versions: list[str]) -> list[str]:
            new_versions = []
            for version in versions:
                if version == "version_tag":
                    new_versions.append("tag")
                if version == "version_branch":
                    new_versions.append("stabilization_branch")
                    new_versions.append("default_branch")
                if version == "feature_tag":
                    pass  # no more supported
                if version == "feature_branch":
                    new_versions.append("feature_branch")
                    new_versions.append("pull_request")
                else:
                    new_versions.append(version)
            return new_versions

        if "versions" in publish.get("docker", {}):
            publish["docker"]["versions_type"] = migrate_versions(
                publish["docker"]["versions"]
            )
            del publish["docker"]["versions"]
        if "versions" in publish.get("helm", {}):
            publish["helm"]["versions_type"] = migrate_versions(
                publish["helm"]["versions"]
            )
            del publish["helm"]["versions"]
        if "versions" in publish.get("pypi", {}):
            publish["pypi"]["versions_type"] = migrate_versions(
                publish["pypi"]["versions"]
            )
            del publish["pypi"]["versions"]

        if "branch_to_version_re" in publish.get("version", {}):
            if publish["version"]["branch_to_version_re"] == {
                {"from": r"([0-9]+.[0-9]+)", "to": r"\1"},
                {"from": "master", "to": "master"},
            }:
                del publish["version"]["branch_to_version_re"]
            else:
                publish["version"]["branch_to_version"] = publish["version"][
                    "branch_to_version_re"
                ]
                del publish["version"]["branch_to_version_re"]
        if "tag_to_version_re" in publish.get("version", {}):
            if publish["version"]["tag_to_version_re"] == {
                {"from": r"([0-9]+.[0-9]+.[0-9]+)", "to": r"\1"},
            }:
                del publish["version"]["tag_to_version_re"]
            else:
                publish["version"]["tag_to_version"] = publish["version"][
                    "tag_to_version_re"
                ]
                del publish["version"]["tag_to_version_re"]

        if "repository" in publish.get("docker", {}):
            for repository in publish["docker"]["repository"].values():
                if "server" in repository:
                    repository["host"] = repository["server"]
                    del repository["host"]
                if "versions" in repository:
                    repository["versions_type"] = migrate_versions(
                        repository["versions"]
                    )
                    del repository["versions"]

    rm_config = False
    if os.path.exists("ci/config.yaml"):
        with mra.EditYAML("ci/config.yaml") as config:
            if "publish" in config:
                del config["publish"]
            if "version_transform" in config:
                del config["version_transform"]

            rm_config = not config.data

    if rm_config:
        os.remove("ci/config.yaml")


def _set_schema_config(task_env: TaskEnv) -> None:
    for config_filename, schema_url in (
        (
            "ci/config.yaml",
            f"https://raw.githubusercontent.com/camptocamp/c2cciutils/{task_env.c2cciutils_version}/c2cciutils/schema.json",
        ),
        (
            ".github/publish.yaml",
            f"https://raw.githubusercontent.com/camptocamp/tag-publish/{_VERSIONS['tag-publish']}/tag_publish/schema.json",
        ),
        (
            ".github/ghci.yaml",
            "https://geoservices-int.camptocamp.com/github/schema.json",
        ),
        (
            "jsonschema-gentypes.yaml",
            f"https://raw.githubusercontent.com/sbrunner/jsonschema-gentypes/{_VERSIONS['sbrunner/jsonschema-gentypes']}/jsonschema_gentypes/schema.json",
        ),
    ):
        if os.path.exists(config_filename):
            with mra.Edit(config_filename) as config:
                data = config.data.split("\n")
                if data[0].startswith("# yaml-language-server: $schema="):
                    continue

                data = [
                    f"# yaml-language-server: $schema={schema_url}",
                    "",
                    *data,
                ]

                config.data = "\n".join(data)


def _upgrade_ubuntu(task_env: TaskEnv) -> None:
    del task_env

    for workflow_file in mra.run(
        ["git", "ls-files", ".github/workflows/*.yaml"], stdout=subprocess.PIPE
    ).stdout.split("\n"):
        if workflow_file:
            try:
                with mra.EditYAML(workflow_file) as yaml:
                    for job in yaml.get("jobs", {}).values():
                        if job.get("runs-on", "").startswith("ubuntu-"):
                            job["runs-on"] = "ubuntu-22.04"
            except Exception as e:
                print(f"Error in {workflow_file}: {e}")


def _update_workflow_venv(task_env: TaskEnv, yaml: mra.EditYAML) -> None:
    if task_env.on_stabilization_branches:
        return

    # Update for Python 3.12
    # pip install match
    pip_install_re = re.compile(r"\bpip install\b")
    for job in yaml["jobs"].values():
        setup_index = -1
        install_index = -1
        echo_index = -1
        for index, step in enumerate(job["steps"]):
            if "pip install " in step.get("run", "") and " --user " in step.get(
                "run", ""
            ):
                step["run"] = step["run"].replace(" --user ", " ")
            if install_index < 0 and pip_install_re.search(step.get("run", "")):
                install_index = index
            if setup_index < 0 and step.get("uses", "").startswith(
                "actions/setup-python@"
            ):
                setup_index = index
            if (
                echo_index < 0
                and step.get("run", "") == 'echo "${HOME}/.local/bin" >> ${GITHUB_PATH}'
            ):
                echo_index = index
        if install_index >= 0 and setup_index < 0:
            job["steps"].insert(
                install_index,
                {
                    "uses": "actions/setup-python@" + _VERSIONS["actions/setup-python"],
                    "with": {
                        "python-version": _VERSIONS["python"],
                    },
                },
            )
        if echo_index >= 0:
            del job["steps"][echo_index]


def _update_main_workflow(task_env: TaskEnv) -> None:
    if os.path.exists(".github/workflows/codeql.yaml"):
        os.remove(".github/workflows/codeql.yaml")
    if not os.path.exists(".github/workflows/main.yaml") and os.path.exists(
        ".github/workflows/ci.yaml"
    ):
        os.rename(".github/workflows/ci.yaml", ".github/workflows/main.yaml")
    if os.path.exists(".github/workflows/main.yaml"):
        with mra.EditYAML(".github/workflows/main.yaml") as yaml:
            _update_workflow_venv(task_env, yaml)

            permissions = yaml.setdefault("permissions", {})
            permissions["contents"] = "write"
            if task_env.use_docker:
                permissions["packages"] = "write"
            if task_env.use_pypi:
                permissions["id-token"] = "write"

            for job_name, job in yaml["jobs"].items():
                pre_commit_index = -1
                has_pre_commit_artifacts = False
                publish_index = -1
                tag_publish_index = -1
                has_publish_artifacts = False
                for index, step in enumerate(job["steps"]):
                    if step.get("run", "").startswith("pre-commit run"):
                        if step["run"] == "pre-commit run --all-files":
                            step["run"] = "pre-commit run --all-files --color=always"
                        pre_commit_index = index
                    if step.get("run", "").startswith("c2cciutils-publish"):
                        publish_index = index
                    if step.get("run", "").startswith("tag-publish"):
                        tag_publish_index = index
                    if (
                        step.get("uses", "").startswith("actions/upload-artifact@")
                        and step.get("with", {}).get("name", "")
                        == "Apply pre-commit fix.patch"
                    ):
                        has_pre_commit_artifacts = True
                    if (
                        step.get("uses", "").startswith("actions/upload-artifact@")
                        and step.get("with", {}).get("name", "")
                        == "Update dpkg versions list.patch"
                    ):
                        has_publish_artifacts = True
                    if (
                        step.get("uses", "").startswith("actions/checkout@")
                        and step.get("restore-keys", "")
                        == "pre-commit-${{ hashFiles('.pre-commit-config.yaml') }}"
                    ):
                        step["key"] = (
                            "pre-commit-${{ github.event_name == 'pull_request' && github.base_ref || github.ref_name }}-${{ hashFiles('.pre-commit-config.yaml') }}"
                        )
                        step["restore-keys"] = (
                            ruamel.yaml.scalarstring.LiteralScalarString(
                                "\n".join(
                                    [
                                        "pre-commit-${{ github.event_name == 'pull_request' && github.base_ref || github.ref_name }}-${{ hashFiles('.pre-commit-config.yaml') }}",
                                        "pre-commit-${{ github.event_name == 'pull_request' && github.base_ref || github.ref_name }}-",
                                        "pre-commit-",
                                    ]
                                )
                            )
                        )

                index_add = 0
                for index, filename, has_artifact, artifact_name in (
                    (
                        pre_commit_index,
                        "pre-commit",
                        has_pre_commit_artifacts,
                        "Apply pre-commit fix",
                    ),
                    (
                        publish_index,
                        "dpkg-versions",
                        has_publish_artifacts,
                        "Update dpkg versions list",
                    ),
                    (
                        tag_publish_index,
                        "dpkg-versions",
                        has_publish_artifacts,
                        "Update dpkg versions list",
                    ),
                ):
                    if index >= 0:
                        if not task_env.on_stabilization_branches:
                            if (
                                job["steps"][index + index_add]
                                .get("env", {})
                                .get("SKIP", "")
                                .strip(",")
                                == "poetry-lock"
                            ):
                                del job["steps"][index + index_add]["env"]["SKIP"]
                                if not job["steps"][index + index_add]["env"]:
                                    del job["steps"][index + index_add]["env"]
                        if len(job["steps"]) > index + index_add + 1 and job["steps"][
                            index + index_add + 1
                        ].get("run", "").startswith("git diff"):
                            job["steps"][index + index_add + 1]["run"] = (
                                f"git diff --exit-code --patch > /tmp/{filename}.patch; git diff --color; git reset --hard || true"
                            )
                            job["steps"][index + index_add + 1]["if"] = "failure()"
                        else:
                            job["steps"].insert(
                                index + index_add + 1,
                                {
                                    "run": f"git diff --exit-code --patch > /tmp/{filename}.patch || true",
                                    "if": "failure()",
                                },
                            )
                            index_add += 1
                        if not has_artifact and index >= 0:
                            job["steps"].insert(
                                index + index_add + 1,
                                {
                                    "uses": "actions/upload-artifact@v"
                                    + _VERSIONS["actions/upload-artifact"],
                                    "with": {
                                        "name": f"{artifact_name}.patch",
                                        "path": f"/tmp/{filename}.patch",  # nosec
                                        "retention-days": 1,
                                    },
                                    "if": "failure()",
                                },
                            )
                            index_add += 1

                publish_index = -1

                for index, step in enumerate(job["steps"]):
                    if not task_env.on_stabilization_branches:
                        if task_env.c2cciutils_version >= version.parse("1.6.0"):
                            if step.get("run", "") == "c2cciutils-checks":
                                step["name"] = "Print environment information"
                                step["run"] = "c2cciutils-env"
                                value = None
                                if "env" in step:
                                    if step["env"].ca.items:
                                        value = list(step["env"].ca.items.values())[-1][
                                            2
                                        ].value
                                    del step["env"]
                                step["env"] = {"GITHUB_EVENT": "${{ toJson(github) }}"}
                                job["steps"].ca.items[index] = [
                                    None,
                                    None,
                                    [
                                        ruamel.yaml.CommentToken(
                                            value or "\n\n",
                                            ruamel.yaml.error.CommentMark(0),
                                            None,
                                        )
                                    ],
                                    None,
                                ]
                        else:
                            if step.get("run", "") == "c2cciutils-checks":
                                if not task_env.gopass:
                                    env = step.setdefault("env", {})
                                    env["SNYK_TOKEN"] = (  # nosec
                                        "${{ secrets.SNYK_TOKEN }}"
                                    )

            # if len(yaml["jobs"]) > 1:
            #     candidate_jobs = set()
            #     needed_jobs = set()
            #     success_job = False
            #     for name, job in yaml["jobs"].items():
            #         if name == "success":
            #             success_job = True
            #         if "needs" in job:
            #             candidate_jobs.add(name)
            #             if isinstance(job["needs"], list):
            #                 needed_jobs += job["needs"]
            #             else:
            #                 needed_jobs.add(job["needs"])
            #     for needed_job in needed_jobs:
            #         if needed_job in candidate_jobs:
            #             candidate_jobs.remove(needed_job)
            #     if len(candidate_jobs) == 1 and not success_job:
            #         candidate_job = list(candidate_jobs)[0]
            #
            #         yaml["jobs"]["success"] = {
            #             "name": "Success",
            #             "runs-on": "ubuntu-22.04",
            #             "timeout-minutes": 5,
            #             "needs": yaml["jobs"][candidate_job]["needs"],
            #             "steps": [
            #                 {
            #                     "run": "touch SUCCESS",
            #                 },
            #                 {
            #                     "uses": "actions/upload-artifact@v4",
            #                     "with": {
            #                         "name": "Success",
            #                         "path": "SUCCESS",
            #                         "retention-days": 1,
            #                     },
            #                 },
            #             ],
            #         }
            #
            #         yaml["jobs"][candidate_job]["needs"] = "success"
            #         if "if" in yaml["jobs"][candidate_job]:
            #             yaml["jobs"]["success"][
            #                 "if"
            #             ] = f"always() && {yaml['jobs'][candidate_job]['if']}"
            #         else:
            #             yaml["jobs"]["success"]["if"] = "always()"
            #
            #         step = {
            #             "name": "Check if related check run failed",
            #             "uses": "actions/download-artifact@v4",
            #             "with": {
            #                 "name": "Success",
            #             },
            #         }
            #         if job_name == "publish":
            #             job["steps"].insert(0, step)
            #         else:
            #             job["steps"].append(step)

            if not task_env.on_stabilization_branches or yaml.is_modified():
                _canonicalize_workflow(yaml)


def _update_audit_workflow(task_env: TaskEnv) -> None:
    if os.path.exists(".github/workflows/audit.yaml"):
        os.remove(".github/workflows/audit.yaml")


def _update_clean_workflow(task_env: TaskEnv) -> None:
    if os.path.exists(".github/workflows/clean.yaml"):
        with mra.EditYAML(".github/workflows/clean.yaml") as yaml:
            _update_workflow_venv(task_env, yaml)


def _clean_update_workflow(task_env: TaskEnv) -> None:
    if os.path.exists(".whitesource"):
        os.remove(".whitesource")
    if os.path.exists(".pylintrc"):
        os.remove(".pylintrc")
    if os.path.exists(".github/changelog-config.yaml"):
        os.remove(".github/changelog-config.yaml")
    if os.path.exists(".github/workflows/changelog.yaml"):
        os.remove(".github/workflows/changelog.yaml")
    if os.path.exists(".github/run-changelog.mjs"):
        os.remove(".github/run-changelog.mjs")
    if os.path.exists(".github/workflows/pr-checks.yaml"):
        os.remove(".github/workflows/pr-checks.yaml")
    if os.path.exists(".github/workflows/test_url.yaml"):
        os.remove(".github/workflows/test_url.yaml")

    if not task_env.use_docker:
        if os.path.exists(".github/workflows/clean.yaml"):
            os.remove(".github/workflows/clean.yaml")
        return

    if not task_env.has_stabilization_branches:
        if os.path.exists(".github/workflows/backport.yaml"):
            os.remove(".github/workflows/backport.yaml")
        return

    # Upgrade deprecated workflows
    for workflow_filename in glob.glob(".github/workflows/*.yaml"):
        with mra.EditYAML(workflow_filename) as yaml:
            for job in yaml["jobs"].values():
                for step in job["steps"]:
                    for action, version in [
                        ("actions/cache", "v1"),
                        ("actions/cache", "v2"),
                        ("actions/upload-artifact", "v3"),
                        ("actions/download-artifact", "v3"),
                    ]:
                        if step.get("uses", "").startswith(f"{action}@{version}"):
                            step["uses"] = f"{action}@{_VERSIONS[action]}"
                            break


def _update_delete_old_workflows_run_workflow(task_env: TaskEnv) -> None:
    if os.path.exists(".github/workflows/delete-old-workflow-run.yaml"):
        os.remove(".github/workflows/delete-old-workflow-run.yaml")
    if os.path.exists(".github/workflows/delete-old-workflows-run.yaml"):
        os.remove(".github/workflows/delete-old-workflows-run.yaml")


def safe_or(elements: list[str], prefix: str = "") -> str:
    if len(elements) == 0:
        return ""
    if len(elements) == 1:
        return elements[0]
    return "(" + f"\n{prefix}|| ".join(elements) + ")"


def _and(elements: list[str], prefix: str = "") -> str:
    elements = [e for e in elements if e]
    if len(elements) == 0:
        return ""
    return f"\n{prefix}&& ".join(elements)


def _update_pull_request_automation_workflow(task_env: TaskEnv) -> None:
    for file_ in (
        ".github/workflows/dependabot-auto-merge.yaml",
        ".github/workflows/auto-review.yaml",
        ".github/workflows/auto-merge.yaml",
        ".github/workflows/dependency-update-review.yaml",
        ".github/workflows/dependency-auto-review.yaml",
    ):
        if os.path.exists(file_):
            if os.path.exists(".github/workflows/pull-request-automation.yaml"):
                os.remove(file_)
            else:
                mra.run(
                    [
                        "git",
                        "mv",
                        file_,
                        ".github/workflows/pull-request-automation.yaml",
                    ]
                )
    if not os.path.exists(".github/workflows/pull-request-automation.yaml"):
        with mra.Edit(".github/workflows/pull-request-automation.yaml") as text:
            text.data = "\n".join(
                [
                    "name: Auto reviews updates",
                    "",
                    "on:",
                    "  pull_request:",
                    "    types:",
                    "      - opened",
                    "      - reopened",
                    "",
                    "jobs:",
                    "  auto-merge:",
                    "    name: Auto reviews updates",
                    "    runs-on: ubuntu-22.04",
                    "    timeout-minutes: 5",
                    "",
                    "    steps:",
                    "      - uses: actions/github-script@v7",
                    "        with:",
                    "          script: |-",
                    "            github.rest.pulls.createReview({",
                    "              owner: context.repo.owner,",
                    "              repo: context.repo.repo,",
                    "              pull_number: context.payload.pull_request.number,",
                    "              event: 'APPROVE',",
                    "            })",
                    "    if: github.event.pull_request.user.login == 'renovate[bot]'",
                ]
            )
    with mra.EditYAML(".github/workflows/pull-request-automation.yaml") as yaml:
        task_env.config.value("dependencyAutoReviewUsers", ["renovate[bot]"])
        yaml["name"] = "Auto reviews pull requests from bots"
        yaml["on"] = {
            "pull_request": {"types": ["opened", "reopened"]},
        }
        yaml["name"] = "Auto reviews, merge and close pull requests"
        for job in yaml["jobs"].values():
            job["name"] = "Auto reviews pull requests from bots"
            if "if" in job:
                del job["if"]

            PRINT_EVENT = "Print event"
            PRINT_CONTEXT = "Print context"
            AUTO_REVIEW_GHCI_UPDATES = "Auto reviews GHCI updates"
            AUTO_REVIEW_RENOVATE_UPDATES = "Auto reviews Renovate updates"
            AUTO_REVIEW_AND_MERGE_DPKG_UPDATES = "Auto review and merge dpkg updates"
            AUTO_REVIEW_AND_MERGE_SNYK_AUTO_FIX = "Auto review and merge snyk auto fix"
            step_names = [
                PRINT_EVENT,
                PRINT_CONTEXT,
                AUTO_REVIEW_GHCI_UPDATES,
                AUTO_REVIEW_RENOVATE_UPDATES,
            ]

            old_step = {}
            for new_step_name in step_names:
                for step in job["steps"]:
                    if step.get("name") == new_step_name:
                        old_step[new_step_name] = step
                        break

            job["steps"] = [old_step.get(step, {"name": step}) for step in step_names]

            auto_review_and_merge_snyk_auto_fix_index = -1
            for index, step in enumerate(job["steps"]):
                if step["name"] == AUTO_REVIEW_AND_MERGE_SNYK_AUTO_FIX:
                    auto_review_and_merge_snyk_auto_fix_index = index
            if auto_review_and_merge_snyk_auto_fix_index >= 0:
                del job["steps"][auto_review_and_merge_snyk_auto_fix_index]

            auto_review_and_merge_dpkg_update_index = -1
            for index, step in enumerate(job["steps"]):
                if step["name"] == AUTO_REVIEW_AND_MERGE_DPKG_UPDATES:
                    auto_review_and_merge_dpkg_update_index = index
            if auto_review_and_merge_dpkg_update_index >= 0:
                del job["steps"][auto_review_and_merge_dpkg_update_index]

            for step in job["steps"]:
                if step["name"] == PRINT_EVENT:
                    step["run"] = 'echo "${GITHUB}" | jq'
                    step["env"] = {
                        "GITHUB": "${{ toJson(github) }}",
                    }
                if step["name"] == PRINT_CONTEXT:
                    if not step.get("uses", "").startswith("actions/github-script@"):
                        step["uses"] = "actions/github-script@v7"
                    step["with"] = {
                        "script": ruamel.yaml.scalarstring.LiteralScalarString(
                            "\n".join(["console.log(context);"])
                        )
                    }
                    if "if" in step:
                        del step["if"]
                    if "env" in step:
                        del step["env"]
                if step["name"] == AUTO_REVIEW_GHCI_UPDATES:
                    if not step.get("uses", "").startswith("actions/github-script@"):
                        step["uses"] = "actions/github-script@v7"
                    step["if"] = ruamel.yaml.scalarstring.LiteralScalarString(
                        _and(
                            [
                                "startsWith(github.head_ref, 'ghci/audit/')",
                                safe_or(
                                    [
                                        f"github.event.pull_request.user.login == 'geo-ghci-test[bot]'",
                                        f"github.event.pull_request.user.login == 'geo-ghci-int[bot]'",
                                        f"github.event.pull_request.user.login == 'geo-ghci[bot]'",
                                    ],
                                    "  ",
                                ),
                            ]
                        )
                    )
                    step["with"] = {
                        "script": ruamel.yaml.scalarstring.LiteralScalarString(
                            "\n".join(
                                [
                                    "github.rest.pulls.createReview({",
                                    "  owner: context.repo.owner,",
                                    "  repo: context.repo.repo,",
                                    "  pull_number: context.payload.pull_request.number,",
                                    "  event: 'APPROVE',",
                                    "})",
                                ]
                            )
                        )
                    }
                if step["name"] == AUTO_REVIEW_RENOVATE_UPDATES:
                    if not step.get("uses", "").startswith("actions/github-script@"):
                        step["uses"] = "actions/github-script@v7"
                    step["if"] = ruamel.yaml.scalarstring.LiteralScalarString(
                        f"github.event.pull_request.user.login == 'renovate[bot]'",
                    )
                    step["with"] = {
                        "script": ruamel.yaml.scalarstring.LiteralScalarString(
                            "\n".join(
                                [
                                    "github.rest.pulls.createReview({",
                                    "  owner: context.repo.owner,",
                                    "  repo: context.repo.repo,",
                                    "  pull_number: context.payload.pull_request.number,",
                                    "  event: 'APPROVE',",
                                    "})",
                                ]
                            )
                        )
                    }

        if not task_env.on_stabilization_branches or yaml.is_modified():
            _canonicalize_workflow(yaml)


class _PythonVersion:
    def __init__(self, version: str) -> None:
        version_split = version.split(".")
        self.major = int(version_split[0])
        self.minor = int(version_split[1])


def _update_pyproject_toml(task_env: TaskEnv) -> None:
    """
    Add or update the Poetry extensions to the pyproject.toml file.
    """

    poetry_version = version.parse("0.0.0")
    for requirements_file_name in ("requirements.txt", "ci/requirements.txt"):
        if os.path.exists(requirements_file_name):
            with mra.Edit(requirements_file_name) as requirements_txt:
                for line in requirements_txt.data.splitlines():
                    if line.startswith("poetry=="):
                        poetry_version = version.parse(line.split("==")[1])
                        break

    if poetry_version >= version.parse("1.3.0"):
        typed = (
            len(
                mra.run(
                    ["git", "ls-files", "py.typed"],
                    exit_on_error=False,
                    stdout=subprocess.PIPE,
                    encoding="utf-8",
                ).stdout.strip()
            )
            > 0
        )
        for pyproject_filename in (
            "pyproject.toml",
            "app/pyproject.toml",
            "api/pyproject.toml",
        ):
            if os.path.exists(pyproject_filename):
                with mra.EditTOML(pyproject_filename) as pyproject:
                    if "requires" in pyproject.get(
                        "build-system", {}
                    ) and "python" in pyproject.get("tool", {}).get("poetry", {}).get(
                        "dependencies", {}
                    ):
                        classifiers = (
                            pyproject.setdefault("tool", {})
                            .setdefault("poetry", {})
                            .setdefault("classifiers", [])
                        )
                        if typed and "Typing :: Typed" not in classifiers:
                            classifiers.append("Typing :: Typed")
                        pyproject["tool"]["poetry"]["classifiers"] = sorted(classifiers)

                        if "dev-dependencies" in pyproject["tool"]["poetry"]:
                            if "dependencies" in pyproject["tool"]["poetry"].setdefault(
                                "group", {}
                            ).setdefault("dev", {}):
                                pyproject["tool"]["poetry"]["group"]["dev"][
                                    "dependencies"
                                ].update(
                                    pyproject["tool"]["poetry"]["dev-dependencies"]
                                )
                            else:
                                pyproject["tool"]["poetry"]["group"]["dev"][
                                    "dependencies"
                                ] = pyproject["tool"]["poetry"]["dev-dependencies"]
                            del pyproject["tool"]["poetry"]["dev-dependencies"]

                        if "prospector" in pyproject["tool"]["poetry"].get(
                            "group", {}
                        ).get("dev", {}).get("dependencies", {}):
                            dev_dependencies = pyproject["tool"]["poetry"]["group"][
                                "dev"
                            ]["dependencies"]
                            if "prospector-profile-utils" not in dev_dependencies:
                                dev_dependencies["prospector-profile-utils"] = (
                                    f"{_VERSIONS['prospector-profile-utils']}"
                                )
                            if "prospector-profile-duplicated" not in dev_dependencies:
                                dev_dependencies["prospector-profile-duplicated"] = (
                                    f"{_VERSIONS['prospector-profile-duplicated']}"
                                )
                            extra = dev_dependencies["prospector"].setdefault(
                                "extras", []
                            )
                            if "with_ruff" not in extra:
                                extra.append("with_ruff")
                            if "with_pyroma" not in extra:
                                extra.append("with_pyroma")

                        version_splitter = re.compile("[<>=]+")
                        [
                            version_splitter.split(p)[0]
                            for p in pyproject["build-system"]["requires"]
                        ]
                        for requirements_file_name_candidate in (
                            "requirements.txt",
                            "ci/requirements.txt",
                        ):
                            if os.path.exists(requirements_file_name_candidate):
                                with mra.Edit(
                                    requirements_file_name_candidate
                                ) as requirements_txt:
                                    if "poetry" in requirements_txt.data:
                                        break
                        # for dependency, plugin, plugin_version in (
                        #     (True, "poetry-dynamic-versioning", _VERSIONS["poetry-dynamic-versioning"]),
                        #     (True, "poetry-plugin-tweak-dependencies-version", _VERSIONS["poetry-plugin-tweak-dependencies-version"]),
                        #     (True, "poetry-plugin-drop-python-upper-constraint", _VERSIONS["poetry-plugin-drop-python-upper-constraint"]),
                        #     (False, "poetry-plugin-export", _VERSIONS["poetry-plugin-export"]),
                        # ):
                        #     requirement = not dependency
                        #     if dependency and plugin not in build_system_requires_no_version:
                        #         pyproject.data["build-system"]["requires"].append(plugin)
                        #         requirement = True
                        #     if requirement and requirement_file_name:
                        #         with mra.Edit(requirements_file_name) as requirements_txt:
                        #                     if (
                        #                         f"{plugin}==" not in requirements_txt.data
                        #                         and f"{plugin}[" not in requirements_txt.data
                        #                     ):
                        #                         requirements_txt.data += f"{plugin}=={plugin_version}\n"

                        poetry_dynamic_versioning = pyproject.setdefault(
                            "tool", {}
                        ).setdefault("poetry-dynamic-versioning", {})
                        poetry_dynamic_versioning.setdefault("enable", True)
                        poetry_dynamic_versioning.setdefault("vcs", "git")
                        poetry_dynamic_versioning.setdefault(
                            "pattern", "^(?P<base>\\d+(\\.\\d+)*)"
                        )
                        if "style" in poetry_dynamic_versioning:
                            del poetry_dynamic_versioning["style"]
                        poetry_dynamic_versioning["format-jinja"] = (
                            tomlkit.items.String.from_raw(
                                "\n".join(
                                    [
                                        "",
                                        '{%- if env.get("VERSION_TYPE") == "version_branch" -%}',
                                        '{{serialize_pep440(bump_version(base, 1 if env.get("IS_MASTER") == "TRUE" else 2), dev=distance)}}',
                                        "{%- elif distance == 0 -%}",
                                        "{{serialize_pep440(base)}}",
                                        "{%- else -%}",
                                        "{{serialize_pep440(bump_version(base), dev=distance)}}",
                                        "{%- endif -%}",
                                        "",
                                    ]
                                ),
                                tomlkit.items.StringType.MLB,
                            )
                        )
                        poetry_plugin_tweak_dependencies_version = pyproject.setdefault(
                            "tool", {}
                        ).setdefault("poetry-plugin-tweak-dependencies-version", {})
                        poetry_plugin_tweak_dependencies_version.setdefault(
                            "default", "present"
                        )

                    pyproject.setdefault("tool", {}).setdefault("ruff", {})
                    pyproject["tool"]["ruff"].setdefault("target-version", "py310")
                    pyproject["tool"]["ruff"].setdefault("line-length", 110)
                    pyproject["tool"]["ruff"].setdefault("lint", {}).setdefault(
                        "pydocstyle", {}
                    ).setdefault("convention", "numpy")
                    for rm_tool in ("mypy", "black", "isort"):
                        if rm_tool in pyproject["tool"]:
                            del pyproject["tool"][rm_tool]

                    if pyproject.get("tool", {}).get(
                        "poetry-dynamic-versioning", {}
                    ).get("format-jinja", "").strip() == "\n".join(
                        [
                            '{%- if env.get("VERSION_TYPE") == "version_branch" -%}',
                            '{{serialize_pep440(bump_version(base, 1 if env.get("IS_MASTER") == "TRUE" else 2), dev=distance)}}',
                            "{%- elif distance == 0 -%}",
                            "{{serialize_pep440(base)}}",
                            "{%- else -%}",
                            "{{serialize_pep440(bump_version(base), dev=distance)}}",
                            "{%- endif -%}",
                        ]
                    ):
                        pyproject["tool"]["poetry-dynamic-versioning"][
                            "format-jinja"
                        ] = tomlkit.items.String.from_raw(
                            "\n".join(
                                [
                                    "",
                                    '{%- if env.get("VERSION_TYPE") == "default_branch" -%}',
                                    "{{serialize_pep440(bump_version(base, 1), dev=distance)}}",
                                    '{%- elif env.get("VERSION_TYPE") == "stabilization_branch" -%}',
                                    "{{serialize_pep440(bump_version(base, 2), dev=distance)}}",
                                    "{%- elif distance == 0 -%}",
                                    "{{serialize_pep440(base)}}",
                                    "{%- else -%}",
                                    "{{serialize_pep440(bump_version(base), dev=distance)}}",
                                    "{%- endif -%}",
                                    "",
                                ]
                            ),
                            tomlkit.items.StringType.MLB,
                        )


def _update_prospector_config(task_env: TaskEnv) -> None:
    use_c2cwsgiutils = False
    proc = mra.run(
        ["git", "grep", "c2cwsgiutils"],
        exit_on_error=False,
        stdout=subprocess.DEVNULL,
    )
    for line in proc.stdout.split("\n") if proc.stdout is not None else []:
        if ".py:" in line:
            if "/test_" not in line and "_test.py" not in line:
                use_c2cwsgiutils = True
                break
    has_bandit_file = False
    for bandit_filename in mra.run(
        ["git", "ls-files", ".bandit.yaml"], stdout=subprocess.PIPE
    ).stdout.splitlines():
        has_bandit_file = os.path.exists(bandit_filename)
        if has_bandit_file:
            os.remove(bandit_filename)
    for prospector_filename in mra.run(
        ["git", "ls-files", ".prospector.yaml"], stdout=subprocess.PIPE
    ).stdout.splitlines():
        with mra.EditYAML(prospector_filename) as prospector_config:
            if has_bandit_file and "bandit" in prospector_config:
                del prospector_config["bandit"]
            for inherit in (
                "utils:base",
                "utils:fix",
                *(["utils:c2cwsgiutils"] if use_c2cwsgiutils else []),
            ):
                if inherit not in prospector_config.get("inherits", []):
                    prospector_config["inherits"].append(inherit)

            # remove utils:unsafe from inherits
            for inherit in prospector_config.get("inherits", []):
                if inherit == "utils:unsafe":
                    prospector_config["inherits"].remove(inherit)

            for tag in ("strictness", "max-line-length", "doc-warnings"):
                if tag in prospector_config:
                    del prospector_config[tag]
            for tag in (
                "pylint",
                "pycodestyle",
                "pydocstyle",
                "bandit",
                "mypy",
                "mccabe",
            ):
                if "run" in prospector_config.get(tag, {}):
                    del prospector_config[tag]["run"]
                    if not prospector_config[tag]:
                        del prospector_config[tag]


# def _update_python_version(task_env: TaskEnv) -> None:
#    if task_env.min_python_version:
#        if os.exists("jsonschema-gentypes.yaml"):
#            with mra.Edit("jsonschema-gentypes.yaml") as jsonschema_gentypes:
#                jsonschema_gentypes['python_version'] = task_env.min_python_version


def _update_renovate_config(task_env: TaskEnv) -> None:
    if not os.path.exists(".github/renovate.json5"):
        return
    upgrade_required = False
    with mra.EditRenovateConfigV2() as renovate_config:
        if "regexManagers" in renovate_config:
            upgrade_required = True

    if upgrade_required:
        with mra.Edit(".github/renovate.json5") as renovate_config:
            renovate_config.data = renovate_config.data.replace(
                "regexManagers", "customManagers"
            )
        with mra.EditRenovateConfigV2() as renovate_config:
            for custom_manager in renovate_config["customManagers"]:
                custom_manager["customType"] = "regex"

    if task_env.c2cciutils_version >= version.parse("1.6.0"):
        if not os.path.exists(".github/renovate.json5"):
            with mra.Edit(".github/renovate.json5") as renovate_config:
                renovate_config.data = "{}"

    with mra.EditRenovateConfigV2() as renovate_config:
        # matchPackagePrefixes => matchPackageNames
        for package_rule in renovate_config.get("packageRules", []):
            if "matchPackagePrefixes" in package_rule:
                package_rule["matchPackageNames"] = [
                    f"/^{re.escape(prefix)}.*/"
                    for prefix in package_rule["matchPackagePrefixes"]
                ]
                del package_rule["matchPackagePrefixes"]

        for extend in renovate_config["extends"]:
            if isinstance(extend, mra.JSON5RowAttribute):
                if extend.value.startswith(
                    "github>camptocamp/gs-renovate-config-preset:preset.json5#"
                ):
                    extend.value = (
                        "github>camptocamp/gs-renovate-config-preset:preset.json5#"
                        + _VERSIONS["camptocamp/gs-renovate-config-preset"]
                    )

        extends = [
            (e, e if isinstance(e, str) else e.value)
            for e in renovate_config.get("extends", [])
        ]
        extends_to_remove = [
            (e, v)
            for e, v in extends
            if v.startswith("config:")
            or v
            in (
                "group:monorepos",
                "group:recommended",
                "replacements:all",
                "workarounds:all",
            )
        ]
        for extend, _ in extends_to_remove:
            renovate_config["extends"].remove(extend)
        extends = [
            v
            for _, v in extends
            if not v.startswith("config:")
            and v
            not in (
                "group:monorepos",
                "group:recommended",
                "replacements:all",
                "workarounds:all",
            )
        ]

        extends_base = [e.split("#")[0] for e in extends]
        for preset in (
            "base",
            "group",
            *(
                ["stabilization-branches"]
                if task_env.has_stabilization_branches
                else []
            ),
            "preset",
            "ci",
            "pre-commit",
            *(
                [
                    "python",
                    "security",
                ]
                if task_env.use_python
                else []
            ),
            *(
                [
                    "docker",
                ]
                if task_env.use_docker
                else []
            ),
            "own",
            "json-schema",
            "shellcheck",
        ):
            new_extend = (
                f"github>camptocamp/gs-renovate-config-preset:{preset}.json5#"
                + _VERSIONS["camptocamp/gs-renovate-config-preset"]
            )
            if new_extend.split("#")[0] not in extends_base:
                renovate_config["extends"].append(new_extend)

        # put profile base at first, group at second, and stabilization-branches as thirst.
        def cmp(extend1, extend2) -> int:
            if isinstance(extend1, mra.JSON5RowAttribute):
                extend1 = extend1.value
            if isinstance(extend2, mra.JSON5RowAttribute):
                extend2 = extend2.value
            for preset in ["base", "group", "stabilization-branches"]:
                if extend1.startswith(
                    f"github>camptocamp/gs-renovate-config-preset:{preset}"
                ):
                    return -1
                if extend2.startswith(
                    f"github>camptocamp/gs-renovate-config-preset:{preset}"
                ):
                    return 1
            return 0

        renovate_config["extends"] = mra.JSON5List(
            sorted(renovate_config["extends"], key=functools.cmp_to_key(cmp))
        )
        for property in (
            "timezone",
            "schedule",
            "labels",
            "separateMajorMinor",
            "separateMinorPatch",
            "prHourlyLimit",
            "prConcurrentLimit",
            "lockFileMaintenance",
            "semanticCommits",
            "osvVulnerabilityAlerts",
            "vulnerabilityAlerts",
            "dependencyDashboard",
        ):
            if property in renovate_config:
                del renovate_config[property]
        if "html" in renovate_config and (
            renovate_config["html"] == {"fileMatch": ["\\.html?$", "\\.html?.mako$"]}
            or renovate_config["html"] == {"fileMatch": ["\\.html?$"]}
            or renovate_config["html"] == {"fileMatch": ["\\.html?.mako$"]}
        ):
            del renovate_config["html"]

        renovate_config.remove_package_rule(
            {}, ["Group and auto merge the patch updates"]
        )
        renovate_config.remove_package_rule(
            {}, ["Group and auto merge the minor updates"]
        )

        # CI
        renovate_config.remove_package_rule({}, ["Group the dev dependency update"])
        renovate_config.remove_package_rule(
            {}, ["Auto merge the dev dependency update"]
        )
        renovate_config.remove_package_rule(
            {}, ["Group and auto merge the CI dependencies"]
        )

        # pre-commit
        if "pre-commit" in renovate_config:
            del renovate_config["pre-commit"]
        renovate_config.remove_regex_manager(
            {}, ["Do updates on pre-commit additional dependencies"]
        )

        # python
        renovate_config.remove_package_rule({}, ["Ungroup Python dependencies"])
        renovate_config.remove_regex_manager(
            {}, ["Python version in actions/setup-python action"]
        )
        renovate_config.remove_package_rule(
            {}, ["In file .python-version, use the <major>.<minor> version"]
        )
        renovate_config.remove_package_rule(
            {}, ["In file `.python-version`, use the `<major>.<minor>` version"]
        )

        # json-schema
        renovate_config.remove_regex_manager(
            {}, ["Do update on the schema present in the YAML files"]
        )

        # shellcheck
        renovate_config.remove_package_rule(
            {}, ["Support the 4 parts of shellcheck-py version with a v prefix"]
        )

        renovate_config.remove_package_rule({}, ["Update dpkg versions at any time"])
        renovate_config.remove_regex_manager(
            {}, ["Do update on the schema present in the ci/config.yaml"]
        )

        if (
            not task_env.has_stabilization_branches
            or task_env.stabilization_branches == ["master"]
        ):
            if "baseBranches" in renovate_config:
                del renovate_config["baseBranches"]
            renovate_config.remove_package_rule(
                {}, ["Accept only the patch on stabilization branches"]
            )
            renovate_config.remove_package_rule(
                {}, ["Accept only the patch on the stabilization branches"]
            )

        renovate_config.remove_package_rule(
            {}, ["In file .python-version, use the <major>.<minor> version"]
        )
        if os.path.exists(".python-version"):
            renovate_config.add_package_rule(
                {
                    "matchFileNames": [".python-version"],
                    "versioning": "regex:^(?<major>\\d+)\\.(?<minor>\\d+)$",
                },
                ["In file `.python-version`, use the `<major>.<minor>` version"],
            )

        renovate_config.remove_package_rule({}, ["Group Poetry packages"])
        if "packageRules" in renovate_config and not renovate_config["packageRules"]:
            del renovate_config["packageRules"]
        if (
            "customManagers" in renovate_config
            and not renovate_config["customManagers"]
        ):
            del renovate_config["customManagers"]


def _update_config(task_env: TaskEnv) -> None:
    if os.path.exists(
        "ci/config.yaml"
    ) and task_env.c2cciutils_version >= version.parse("1.6.0"):
        with mra.EditYAML("ci/config.yaml") as config:
            if "checks" in config:
                del config["checks"]
            to_delete = len(config.keys()) == 0
        if to_delete:
            os.remove("ci/config.yaml")


def _update_pre_commit_config(task_env: TaskEnv) -> None:
    if os.path.exists(".pre-commit-config.yaml"):
        with mra.EditPreCommitConfig() as pre_commit_config:
            if "ci" in pre_commit_config:
                del pre_commit_config["ci"]

            if os.path.exists(".github/renovate.json5"):
                pre_commit_config.add_repo(
                    "https://github.com/renovatebot/pre-commit-hooks",
                    _VERSIONS["renovatebot/pre-commit-hooks"],
                )
                pre_commit_config.add_hook(
                    "https://github.com/renovatebot/pre-commit-hooks",
                    {
                        "id": "renovate-config-validator",
                    },
                )

            pre_commit_config.add_repo(
                "https://github.com/sbrunner/jsonschema-validator",
                _VERSIONS["sbrunner/jsonschema-validator"],
            )
            pre_commit_config.add_hook(
                "https://github.com/sbrunner/jsonschema-validator",
                {"id": "jsonschema-validator"},
            )
            for repo in pre_commit_config["repos"]:
                if repo["repo"] == "https://github.com/sbrunner/jsonschema-validator":
                    files = repo["hooks"][0].get("files", "").strip()
                    if files.startswith(r"(?x)^("):
                        files = files[len(r"(?x)^(") :]
                    elif files.startswith(r"^"):
                        files = files[len(r"^") :]
                    if files.endswith(r")$"):
                        files = files[: -len(r")$")]
                    elif files.endswith(r"$"):
                        files = files[: -len(r"$")]
                    files_split = files.split("\n")
                    files_split = [f.strip() for f in files_split]
                    files_split = [f.lstrip("|") for f in files_split]
                    files_split = [f for f in files_split if f]

                    filenames = {
                        ".github/publish.yaml",
                        ".github/ghci.yaml",
                        "jsonschema_gentype.yaml",
                        "ci/config.yaml",
                    }
                    filenames_proc = mra.run(
                        ["git", "grep", r"# yaml-language-server: \$schema=https://"],
                        stdout=subprocess.PIPE,
                        exit_on_error=False,
                    )
                    if filenames_proc.stdout is not None:
                        for line in filenames_proc.stdout.split("\n"):
                            if line:
                                filename = line.split(":")[0]
                                if filename.endswith(".yaml"):
                                    filenames |= {filename}
                    for filename in filenames:
                        filename_re = re.escape(filename)
                        if os.path.exists(filename):
                            if filename_re not in files_split:
                                files_split.append(filename_re)
                        else:
                            if filename_re in files_split:
                                files_split.remove(filename_re)

                    repo["hooks"][0]["files"] = pre_commit_config.create_files_regex(
                        files_split
                    )

                    break

            # Do a spell check on the found schemas
            schemas = []
            for files_ in ("*.schema.json", "schema.json", "schema-*.json"):
                schemas += [
                    f
                    for f in mra.run(
                        ["git", "ls-files", files_], stdout=subprocess.PIPE
                    ).stdout.split("\n")
                    if f
                ]
                # Get all the schemas files
                schemas += [
                    f
                    for f in mra.run(
                        ["git", "ls-files", f"**/{files_}"], stdout=subprocess.PIPE
                    ).stdout.split("\n")
                    if f
                ]

            if schemas:
                pre_commit_config.add_repo(
                    "https://github.com/mheap/json-schema-spell-checker",
                    _VERSIONS["mheap/json-schema-spell-checker"],
                )
                pre_commit_config.add_hook(
                    "https://github.com/mheap/json-schema-spell-checker",
                    {
                        "id": "json-schema-spell-checker",
                        "files": pre_commit_config.create_files_regex(
                            [re.escape(f) for f in schemas]
                        ),
                        "args": [
                            "--fields=description,title",
                            "--spelling=.github/spell-ignore-words.txt",
                            "--ignore-numbers",
                            "--ignore-acronyms",
                            "--en-us",
                        ],
                    },
                )

            for repo in pre_commit_config["repos"]:
                if (
                    repo["repo"]
                    == "https://github.com/python-jsonschema/check-jsonschema"
                ):
                    for index, hook in enumerate(list(repo["hooks"])):
                        if hook["id"] == "check-renovate":
                            del repo["hooks"][index]
                            break
                if repo["repo"] == "https://github.com/sbrunner/hooks":
                    for index, hook in enumerate(list(repo["hooks"])):
                        if hook["id"] == "poetry-check":
                            del repo["hooks"][index]
                            break

            if task_env.use_python:
                rm_repos = (
                    "https://github.com/psf/black",
                    "https://github.com/PyCQA/isort",
                    "https://github.com/PyCQA/autoflake",
                    "https://github.com/asottile/pyupgrade",
                    "https://github.com/PyCQA/docformatter",
                )
                continue_ = True
                while continue_:
                    continue_ = False
                    for name, repo in enumerate(list(pre_commit_config["repos"])):
                        if repo["repo"] in rm_repos:
                            del pre_commit_config["repos"][name]
                            continue_ = True
                            break

                pre_commit_config.add_repo(
                    "https://github.com/astral-sh/ruff-pre-commit",
                    _VERSIONS["astral-sh/ruff-pre-commit"],
                )
                pre_commit_config.add_hook(
                    "https://github.com/astral-sh/ruff-pre-commit",
                    {"id": "ruff-format"},
                )
                pre_commit_config.add_repo(
                    "https://github.com/PyCQA/prospector", _VERSIONS["PyCQA/prospector"]
                )
                pre_commit_config.add_hook(
                    "https://github.com/PyCQA/prospector",
                    {
                        "id": "prospector",
                    },
                )
                if (
                    "prospector"
                    in pre_commit_config.repos_hooks[
                        "https://github.com/PyCQA/prospector"
                    ]["hooks"]
                ):
                    prospector_hooks = pre_commit_config.repos_hooks[
                        "https://github.com/PyCQA/prospector"
                    ]["hooks"]["prospector"]
                    prospector_hooks[0]["args"] = [
                        "--tool=ruff",
                        "--die-on-tool-error",
                        "--output-format=pylint",
                        "--profile=.prospector.yaml",
                        "--profile=utils:autofix",
                    ]
                    current_deps = [
                        deps.split("=")[0]
                        for deps in prospector_hooks[0].get(
                            "additional_dependencies", []
                        )
                    ]
                    for deps in [
                        "prospector-profile-duplicated=="
                        + _VERSIONS["prospector-profile-duplicated"],
                        "prospector-profile-utils=="
                        + _VERSIONS["prospector-profile-utils"],
                        "ruff==" + _VERSIONS["ruff"],
                    ]:
                        if deps.split("=")[0] not in current_deps:
                            pre_commit_config.add_commented_additional_dependencies(
                                prospector_hooks[0], [deps], "pypi"
                            )
                    if len(prospector_hooks) == 1:
                        pre_commit_config.add_hook(
                            "https://github.com/PyCQA/prospector",
                            {
                                "id": "prospector",
                                "args": [
                                    "--die-on-tool-error",
                                    "--output-format=pylint",
                                    "--profile=utils:tests",
                                    "--profile=utils:autofix",
                                ],
                            },
                            force=True,
                        )
                        pre_commit_config.add_commented_additional_dependencies(
                            prospector_hooks[1],
                            [
                                "prospector-profile-utils=="
                                + _VERSIONS["prospector-profile-utils"],
                                "ruff==" + _VERSIONS["ruff"],
                            ],
                            "pypi",
                        )

                pre_commit_config.add_repo(
                    "https://github.com/sbrunner/python-versions-hook",
                    _VERSIONS["sbrunner/python-versions-hook"],
                )
                pre_commit_config.add_hook(
                    "https://github.com/sbrunner/python-versions-hook",
                    {
                        "id": "python-versions",
                    },
                )
                pre_commit_config.add_repo(
                    "https://github.com/sbrunner/python-versions-hook",
                    _VERSIONS["sbrunner/python-versions-hook"],
                )
                pre_commit_config.add_hook(
                    "https://github.com/sbrunner/python-versions-hook",
                    {
                        "id": "python-versions",
                    },
                )


def _use_tag_publish(task_env: TaskEnv) -> None:
    if not os.path.exists(".github/workflows/main.yaml"):
        return

    add_tag_publish = False
    with mra.EditYAML(".github/workflows/main.yaml") as yaml:
        for job in yaml["jobs"].values():
            for step in job["steps"]:
                if step.get("run", "").startswith("tag-publish"):
                    add_tag_publish = True
                elif step.get("run", "").startswith("c2cciutils-publish"):
                    add_tag_publish = True
                    step["run"] = step["run"].replace(
                        "c2cciutils-publish", "tag-publish"
                    )
                    step.setdefault("env", {})["GITHUB_TOKEN"] = (  # nosec
                        "${{ secrets.GITHUB_TOKEN }}"
                    )

    if not add_tag_publish:
        return

    for candidate_requirements_filename in (
        ".github/requirements.txt",
        "ci/requirements.txt",
        "requirements.txt",
    ):
        if os.path.exists(candidate_requirements_filename):
            with mra.Edit(candidate_requirements_filename) as requirements_txt:
                if "c2cciutils" in requirements_txt.data:
                    if "tag-publish" not in requirements_txt.data:
                        requirements_txt.data += (
                            f"tag-publish=={_VERSIONS['tag-publish']}\n"
                        )
                    break


def _remove_docker_compose_version(task_env: TaskEnv) -> None:
    for docker_compose_filename in [
        *glob.glob("**/docker-compose.yaml"),
        *glob.glob("**/docker-compose.*.yaml"),
        *glob.glob("**/docker-compose-*.yaml"),
        *glob.glob("docker-compose.yaml"),
        *glob.glob("docker-compose.*.yaml"),
        *glob.glob("docker-compose-*.yaml"),
    ]:
        with mra.EditYAML(docker_compose_filename) as docker_compose:
            if "version" in docker_compose:
                del docker_compose["version"]


def _get_env() -> TaskEnv:
    config = Config()

    use_helm = config.enabled(
        "helm",
        os.path.exists("Chart.yaml") or os.path.exists("test/helmchart/Chart.yaml"),
    )

    gopass = config.enabled(
        "gopass",
        "no-gopass" not in config.repo.get("types", [])
        and (
            config.repo["name"].startswith("camptocamp/")
            or config.repo["name"].startswith("mapfish/")
        ),
    )
    # Get the string we used in the workflow to get the GitHub token to be used
    token = config.value(
        "github_token_secret",
        "${{ secrets.GOPASS_CI_GITHUB_TOKEN }}" if gopass else "${{ secrets.TOKEN }}",
    )

    # Get the version of c2cciutils
    c2cciutils_version = version.parse("1.6.0")
    set_c2cciutils_version = False
    requirements = Path("ci/requirements.txt")
    if requirements.exists():
        with mra.Edit(requirements) as requirements_txt:
            requirements = [
                r
                for r in requirements_txt.data.split("\n")
                if r.startswith("c2cciutils==") or r.startswith("c2cciutils[")
            ]
            if len(requirements) == 1:
                c2cciutils_version_string = requirements[0].split("==")[1]
                if c2cciutils_version_string.endswith(".*"):
                    c2cciutils_version_string = c2cciutils_version_string[:-2]
                c2cciutils_version = version.parse(c2cciutils_version_string)
                set_c2cciutils_version = True
    c2cciutils_version_config = config.value("c2cciutils_version")
    if c2cciutils_version_config:
        if c2cciutils_version_config == "master":
            c2cciutils_version = version.parse("1.6.0")
            set_c2cciutils_version = False
        else:
            c2cciutils_version = version.parse(c2cciutils_version_config)
            set_c2cciutils_version = True

    use_python = False
    # min_python_version = ''
    # max_python_version = ''
    for pyproject_filename in (
        "pyproject.toml",
        "app/pyproject.toml",
        "api/pyproject.toml",
    ):
        if os.path.exists(pyproject_filename):
            with mra.EditTOML(pyproject_filename) as pyproject:
                use_python = "project" in pyproject or "build-system" in pyproject
                # min_python_version = pyproject.get("tool", {}).get("poetry", {}).get("dependencies", {}).get("python", "")
                # match = re.match(r"^>=(\d+\.\d+),<(\d+)\.(\d+)$", min_python_version)
                # if match:
                #    min_python_version = match.group(1)
                #    max_python_version_major = int(match.group(2))
                #    max_python_version_minor = int(match.group(3))
                #    if max_python_version_major == 4:
                #        max_python_version = "3.13"
                #    else:
                #        max_python_version = f"{max_python_version_major}.{max_python_version_minor-1}"

                break
    use_python = config.enabled("python", use_python)

    use_pypi = config.enabled(
        "pypi", use_python and "no-pypi" not in config.repo.get("type", [])
    )
    use_docker = config.enabled(
        "docker",
        (
            os.path.exists("Dockerfile")
            or os.path.exists("app/Dockerfile")
            or os.path.exists("api/Dockerfile")
        )
        and "no-docker" not in config.repo.get("type", []),
    )

    stabilization_branches = mra.get_stabilization_branches(config.repo)

    return TaskEnv(
        c2cciutils_version,
        set_c2cciutils_version,
        use_python,
        # min_python_version,
        # max_python_version,
        use_pypi,
        use_docker,
        use_helm,
        config.arguments.on_stabilization_branches or len(stabilization_branches) > 0,
        config.arguments.on_stabilization_branches and len(stabilization_branches) > 0,
        stabilization_branches,
        gopass,
        token,
        config,
    )


def _ghci_updates(task_env: TaskEnv) -> None:
    if (
        task_env.use_helm
        and not os.path.exists(".github/ghci.yaml")
        and not task_env.on_stabilization_branches
    ):
        with open(".github/ghci.yaml", "w", encoding="utf-8") as ghci:
            ghci.write(
                """# yaml-language-server: $schema=https://geoservices-int.camptocamp.com/github/schema.json

profile: helm
"""
            )


def _do() -> None:
    task_env = _get_env()
    print(f"Task environment: {task_env}")

    for name, task in (
        ("clean-update-workflow", _clean_update_workflow),
        (
            "update-dependency-auto-review-workflow",
            _update_pull_request_automation_workflow,
        ),
    ):
        if task_env.config.enabled(name, True):
            task(task_env)
    if task_env.on_stabilization_branches:
        for file_ in (
            ".github/workflows/delete-old-workflow-run.yaml",
            ".github/workflows/delete-old-workflows-run.yaml",
            ".github/renovate.json5",
        ):
            if os.path.exists(file_):
                os.remove(file_)
        for file_ in glob.glob(".github/workflows/audit*.yaml"):
            os.remove(file_)
        for file_ in glob.glob(".github/workflows/rebuild*.yaml"):
            os.remove(file_)

    else:
        for name, task in (
            # ("upgrade-ubuntu", _upgrade_ubuntu),
            ("create-labels", _create_labels),
            ("update-clean-workflow", _update_clean_workflow),
            ("tag-publish-config", _tag_publish_config),
            ("update-audit-workflow", _update_audit_workflow),
            (
                "update-delete-old-workflow-run-workflow",
                _update_delete_old_workflows_run_workflow,
            ),
            ("update-pyproject-toml", _update_pyproject_toml),
            ("update-prospector-config", _update_prospector_config),
            # ("update-python-version", _update_python_version),
            ("update-renovate-config", _update_renovate_config),
            ("update-config", _update_config),
            ("update-pre-commit-config", _update_pre_commit_config),
            ("remove-docker-compose-version", _remove_docker_compose_version),
            ("set-schema-config", _set_schema_config),
            ("update-main-workflow", _update_main_workflow),
            ("update-ghci", _ghci_updates),
            ("use-tag-publish", _use_tag_publish),
        ):
            if task_env.config.enabled(name, True):
                task(task_env)


if __name__ == "__main__":
    # edit the file /home/sbrunner/workspace/docker-vim/.github/workflows/changelog.yaml
    # with mra.EditYAML("/home/sbrunner/workspace/docker-vim/.github/workflows/audit.yaml") as e:
    #    _canonicalize_workflow(e)
    # with mra.EditYAML("/home/sbrunner/workspace/docker-vim/.github/workflows/changelog.yaml") as e:
    #    _canonicalize_workflow(e)
    # exit(0)

    os.environ["IGNORE_CONFIG_ERROR"] = "true"

    mra.main(
        _do,
        # pull_request_on_stabilization_branches
        # pull_request_title
        # pull_request_body
        # branch
        # pull_request_branch_prefix
        config={
            "branch": "ci-upgrade",
            "pull_request_branch_prefix": "ci-upgrade-",
            "pull_request_title": "CI updates",
            "pull_request_body": "This is done by the automated script named "
            + os.path.basename(__file__),
        },
        description="Update the repository for the CI evolutions",
    )
