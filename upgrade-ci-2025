#!/usr/bin/env python3

# TODO:
# verify remove poetry-check in pre-commit
# verify remove renovate check  https://github.com/python-jsonschema/check-jsonschema

#    "Development Status :: 5 - Production/Stable",
#    "Environment :: Console",
#    "Operating System :: OS Independent",
#    "Programming Language :: Python",
#    "Intended Audience :: Developers",
#    "License :: OSI Approved :: MIT License",
#    "Typing :: Typed",

# Add missing
# dispatch:
#   - {}

import glob
import os
import re
import subprocess
from pathlib import Path
from typing import Any, AnyStr, NamedTuple, Optional, Union

import c2cciutils
import multi_repo_automation as mra
import ruamel.yaml.comments
import ruamel.yaml.scalarstring
import tomlkit.items
import yaml as py_yaml
from packaging import version

# if os.path.exists(".github/renovate.json5"):
# if mra.run(["grep", "text", ".github/renovate.json5"], exit_on_error=False).returncode != 0: # not found
# if mra.git_grep(r"\<text\>"]): # found
# if mra.run(["git", "ls-files", "**/*.txt"], stdout=subprocess.PIPE).stdout.strip() != b"": # found
# mra.edit("file")
# input()

_VERSIONS = {}
with open(Path(__file__).parent / "versions.yaml", encoding="utf-8") as f:
    _VERSIONS = py_yaml.load(f, Loader=py_yaml.SafeLoader)


class Config:
    _values: dict[str, Any] = {}
    _enabled: list[str] = []
    _disabled: list[str] = []

    def __init__(self) -> None:
        self.repo = mra.get_repo_config()
        self.arguments = mra.get_arguments()

        if os.path.exists(".github/ci-upgrade.yaml"):
            with open(".github/ci-upgrade.yaml", encoding="utf-8") as f:
                upgrade_config = py_yaml.load(f.read(), Loader=py_yaml.SafeLoader)
                self._values = upgrade_config.get("values", {})
                self._enabled = upgrade_config.get("enabled", [])
                self._disabled = upgrade_config.get("disabled", [])

    def value(self, name: str, default: Any = None) -> Any:
        return self._values.get(name, default)

    def enabled(self, name: str, default: bool) -> bool:
        if name in self._enabled:
            return True
        if name in self._disabled:
            return False
        return default


class TaskEnv(NamedTuple):
    c2cciutils_version: version.Version
    set_c2cciutils_version: bool
    use_python: bool
    # min_python_version: str
    # max_python_version: str
    use_pypi: bool
    use_docker: bool
    use_helm: bool
    has_stabilization_branches: bool
    on_stabilization_branches: bool
    stabilization_branches: list[str]
    gopass: bool
    token: str
    config: Config


def _order_keys(
    data: dict[str, Any], first_keys: list[str], last_keys: Optional[list[str]] = None
) -> ruamel.yaml.comments.CommentedMap:
    if last_keys is None:
        last_keys = []

    # use order: <first_keys>, <other>, <last_keys>
    new_data = []
    for key in first_keys:
        if key in data:
            new_data.append((key, data[key]))

    new_data += [e for e in data.items() if e[0] not in [*first_keys, *last_keys]]

    for key in last_keys:
        if key in data:
            new_data.append((key, data[key]))

    return ruamel.yaml.comments.CommentedMap(new_data)


def _order_sub_keys(
    data: Union[dict[str, dict[str, Any]], list[dict[str, AnyStr]]],
    first_keys: list[str],
    last_keys: Optional[list[str]] = None,
) -> None:
    items = data.items() if isinstance(data, dict) else enumerate(data)
    for key, value in items:
        # copy the last comment
        comment = None
        if hasattr(value, "ca"):
            last_value = list(value.values())[-1]
            if isinstance(last_value, dict) and hasattr(last_value, "ca"):
                last_last_key = list(last_value.keys())[-1]
                comment = last_value.ca.items.get(last_last_key)
                if comment is not None:
                    del last_value.ca.items[last_last_key]
            else:
                comment = value.ca.items.get(list(value.keys())[-1])
        data[key] = _order_keys(value, first_keys, last_keys)
        if comment is not None:
            last_key = list(data[key].keys())[-1]
            if isinstance(data[key][last_key], ruamel.yaml.comments.CommentedMap):
                last_last_key = list(data[key][last_key].keys())[-1]
                data[key][last_key].ca.items[last_last_key] = comment
            else:
                data[key].ca.items[last_key] = comment


def _canonicalize_workflow(workflow: mra.EditYAML) -> None:
    workflow.data = _order_keys(
        workflow.data, ["name", "on", "permissions", "env"], ["jobs"]
    )

    # Add space after simple key
    for key in ["name"]:
        workflow.data.ca.items[key] = [
            None,
            None,
            ruamel.yaml.CommentToken("\n\n", ruamel.yaml.error.CommentMark(0), None),
            None,
        ]

    # add space after complex keys
    for key in ["on", "permissions", "env", "jobs"]:
        workflow.data.ca.items[key] = [
            None,
            [ruamel.yaml.CommentToken("\n", ruamel.yaml.error.CommentMark(0), None)],
            None,
            None,
        ]

    for name, job in workflow["jobs"].items():
        job = _order_keys(
            job,
            ["name", "runs-on", "timeout-minutes", "if", "concurrency", "needs"],
            ["strategy", "env", "steps"],
        )
        workflow["jobs"][name] = job

        for key in reversed(
            ["name", "runs-on", "timeout-minutes", "if", "concurrency", "needs"]
        ):
            if key in job:
                job.ca.items[key] = [
                    None,
                    None,
                    ruamel.yaml.CommentToken(
                        "\n\n", ruamel.yaml.error.CommentMark(0), None
                    ),
                    None,
                ]
                break

        for key in reversed(["strategy", "env"]):
            if key in job:
                job.ca.items[key] = [
                    None,
                    None,
                    ruamel.yaml.CommentToken(
                        "\n\n", ruamel.yaml.error.CommentMark(0), None
                    ),
                    None,
                ]

        for job in workflow["jobs"].values():
            if "steps" in job:
                _order_sub_keys(
                    job["steps"], ["name"], ["uses", "with", "run", "env", "if"]
                )


def _create_labels(task_env: TaskEnv) -> None:
    mra.gh(
        "label",
        "create",
        "--force",
        "dependencies",
        "--color=0075ca",
        "--description=Update the dependencies",
    )
    if task_env.config.enabled("pullRequestWelcome", False):
        mra.gh(
            "label",
            "create",
            "--force",
            "pull request welcome",
            "--color=6622BB",
            "--description=A pull request is welcome to fix this issue",
        )


def _merge(default_config: Any, config: Any) -> Any:
    """
    Deep merge the dictionaries (on dictionaries only, not on arrays).

    Arguments:
        default_config: The default config that will be applied
        config: The base config, will be modified
    """
    if not isinstance(default_config, dict) or not isinstance(config, dict):
        return config

    for key in default_config.keys():
        if key not in config:
            config[key] = default_config[key]
        else:
            _merge(default_config[key], config[key])
    return config


def _get_repository() -> str:
    """
    Get the current GitHub repository like `organization/project`.
    """
    if "GITHUB_REPOSITORY" in os.environ:
        return os.environ["GITHUB_REPOSITORY"]

    remote_lines = (
        subprocess.check_output(["git", "remote", "--verbose"]).decode().split("\n")
    )
    remote_match = (
        re.match(r".*git@github.com:(.*).git .*", remote_lines[0])
        if len(remote_lines) >= 1
        else None
    )

    if remote_match:
        return remote_match.group(1)

    print("::warning::The GitHub repository isn't found, using 'camptocamp/project'")

    return "camptocamp/project"


def _get_master_branch(repo: list[str]) -> tuple[str, bool]:
    """Get the name of the master branch."""
    master_branch = "master"
    success = False
    try:
        default_branch_json = c2cciutils.graphql(
            "default_branch.graphql", {"name": repo[1], "owner": repo[0]}, default=False
        )
        success = default_branch_json is not False
        master_branch = (
            default_branch_json["repository"]["defaultBranchRef"]["name"]
            if success
            else "master"
        )
    except RuntimeError as runtime_error:
        print(runtime_error)
        print("::warning::Fallback to master")
    return master_branch, success


def _get_c2cciutils_1_8_config(config: dict[str, Any]) -> dict[str, Any]:
    """
    Get the configuration, with project and auto detections.
    """

    repository = _get_repository()
    repo = repository.split("/")
    master_branch, _ = _get_master_branch(repo)

    # _merge(
    #    {
    #        "version": {
    #            "tag_to_version_re": [
    #                {"from": r"([0-9]+.[0-9]+.[0-9]+)", "to": r"\1"},
    #            ],
    #            "branch_to_version_re": [
    #                {"from": r"([0-9]+.[0-9]+)", "to": r"\1"},
    #                {"from": master_branch, "to": master_branch},
    #            ],
    #        }
    #    },
    #    config,
    # )

    has_docker_files = bool(
        subprocess.run(
            ["git", "ls-files", "*/Dockerfile*", "Dockerfile*"],
            stdout=subprocess.PIPE,
            check=True,
        ).stdout
    )
    has_python_package = bool(
        subprocess.run(
            ["git", "ls-files", "setup.py", "*/setup.py"],
            stdout=subprocess.PIPE,
            check=True,
        ).stdout
    ) or bool(
        subprocess.run(
            ["git", "ls-files", "pyproject.toml", "*/pyproject.toml"],
            stdout=subprocess.PIPE,
            check=True,
        ).stdout
    )

    publish_config = _merge(c2cciutils.configuration.PUBLISH_DEFAULT, {})
    publish_config["pypi"]["packages"] = [{"path": "."}] if has_python_package else []
    publish_config["docker"]["images"] = (
        [{"name": _get_repository()}] if has_docker_files else []
    )
    publish_config["helm"]["folders"] = [
        os.path.dirname(f) for f in glob.glob("./**/Chart.yaml", recursive=True)
    ]

    default_config = {
        "publish": publish_config,
    }
    _merge(default_config, config)

    return config


def _tag_publish_config(task_env: TaskEnv) -> None:
    if os.path.exists(".github/publish.yaml"):
        return

    if not os.path.exists("ci/config.yaml"):
        filled_config = _get_c2cciutils_1_8_config({})
    else:
        with mra.EditYAML("ci/config.yaml") as config:
            filled_config = _get_c2cciutils_1_8_config(config)

    if "publish" not in filled_config:
        return

    if os.path.exists("ci/dpkg-versions.yaml"):
        mra.run(["git", "mv", "ci/dpkg-versions.yaml", ".github/"])

    with mra.EditYAML(".github/publish.yaml") as publish:
        publish.data = filled_config["publish"]
        if "helm" in publish and "folders" in publish["helm"]:
            publish["helm"]["packages"] = [
                {"folder": f} for f in publish["helm"]["folders"]
            ]
            del publish["helm"]["folders"]
        if "dispatch" not in publish:
            publish["dispatch"] = [{}]
        if "version_transform" in filled_config:
            publish["version_transform"] = filled_config["version_transform"]

        for package in publish.get("pypi", {}).get("packages", []):
            if package["path"] == ".":
                del package["path"]
        if publish.get("pypi", {}).get("versions", []) == ["version_tag"]:
            del publish["pypi"]["versions"]
        if publish.get("helm", {}).get("versions", []) == ["version_tag"]:
            del publish["helm"]["versions"]
        if "repository" in publish.get("docker", {}):
            del publish["docker"]["repository"]

        if "pypi" in publish and not publish["pypi"].get("packages", []):
            del publish["pypi"]
        if "docker" in publish and not publish["docker"].get("images", []):
            del publish["docker"]
        if "helm" in publish and not publish["helm"].get("packages", []):
            del publish["helm"]

        def migrate_versions(versions: list[str]) -> list[str]:
            new_versions = []
            for version in versions:
                if version == "version_tag":
                    new_versions.append("tag")
                if version == "version_branch":
                    new_versions.append("stabilization_branch")
                    new_versions.append("default_branch")
                if version == "feature_tag":
                    pass  # no more supported
                if version == "feature_branch":
                    new_versions.append("feature_branch")
                    new_versions.append("pull_request")
                else:
                    new_versions.append(version)
            return new_versions

        if "versions" in publish.get("docker", {}):
            publish["docker"]["versions_type"] = migrate_versions(
                publish["docker"]["versions"]
            )
            del publish["docker"]["versions"]
        if "versions" in publish.get("helm", {}):
            publish["helm"]["versions_type"] = migrate_versions(
                publish["helm"]["versions"]
            )
            del publish["helm"]["versions"]
        if "versions" in publish.get("pypi", {}):
            publish["pypi"]["versions_type"] = migrate_versions(
                publish["pypi"]["versions"]
            )
            del publish["pypi"]["versions"]

        if "branch_to_version_re" in publish.get("version", {}):
            if publish["version"]["branch_to_version_re"] == {
                {"from": r"([0-9]+.[0-9]+)", "to": r"\1"},
                {"from": "master", "to": "master"},
            }:
                del publish["version"]["branch_to_version_re"]
            else:
                publish["version"]["branch_to_version"] = publish["version"][
                    "branch_to_version_re"
                ]
                del publish["version"]["branch_to_version_re"]
        if "tag_to_version_re" in publish.get("version", {}):
            if publish["version"]["tag_to_version_re"] == {
                {"from": r"([0-9]+.[0-9]+.[0-9]+)", "to": r"\1"},
            }:
                del publish["version"]["tag_to_version_re"]
            else:
                publish["version"]["tag_to_version"] = publish["version"][
                    "tag_to_version_re"
                ]
                del publish["version"]["tag_to_version_re"]

        if "repository" in publish.get("docker", {}):
            for repository in publish["docker"]["repository"].values():
                if "server" in repository:
                    repository["host"] = repository["server"]
                    del repository["host"]
                if "versions" in repository:
                    repository["versions_type"] = migrate_versions(
                        repository["versions"]
                    )
                    del repository["versions"]

    rm_config = False
    if os.path.exists("ci/config.yaml"):
        with mra.EditYAML("ci/config.yaml") as config:
            if "publish" in config:
                del config["publish"]
            if "version_transform" in config:
                del config["version_transform"]

            rm_config = not config.data

    if rm_config:
        os.remove("ci/config.yaml")


def _set_schema_config(task_env: TaskEnv) -> None:
    for config_filename, schema_url in (
        (
            "ci/config.yaml",
            f"https://raw.githubusercontent.com/camptocamp/c2cciutils/{task_env.c2cciutils_version}/c2cciutils/schema.json",
        ),
        (
            ".github/publish.yaml",
            f"https://raw.githubusercontent.com/camptocamp/tag-publish/{_VERSIONS['tag-publish']}/tag_publish/schema.json",
        ),
        (
            ".github/ghci.yaml",
            "https://geoservices-int.camptocamp.com/github/schema.json",
        ),
        (
            "jsonschema-gentypes.yaml",
            f"https://raw.githubusercontent.com/sbrunner/jsonschema-gentypes/{_VERSIONS['sbrunner/jsonschema-gentypes']}/jsonschema_gentypes/schema.json",
        ),
    ):
        if os.path.exists(config_filename):
            with mra.Edit(config_filename) as config:
                data = config.data.split("\n")
                if data[0].startswith("# yaml-language-server: $schema="):
                    continue

                data = [
                    f"# yaml-language-server: $schema={schema_url}",
                    "",
                    *data,
                ]

                config.data = "\n".join(data)


def _upgrade_ubuntu(task_env: TaskEnv) -> None:
    del task_env

    for workflow_file in mra.run(
        ["git", "ls-files", ".github/workflows/*.yaml"], stdout=subprocess.PIPE
    ).stdout.split("\n"):
        if workflow_file:
            try:
                with mra.EditYAML(workflow_file) as yaml:
                    for job in yaml.get("jobs", {}).values():
                        if job.get("runs-on", "").startswith("ubuntu-"):
                            job["runs-on"] = "ubuntu-22.04"
            except Exception as e:
                print(f"Error in {workflow_file}: {e}")


def _update_workflow_venv(task_env: TaskEnv, yaml: mra.EditYAML) -> None:
    # Update for Python 3.12
    # pip install match
    pip_install_re = re.compile(r"\bpip install\b")
    for job in yaml["jobs"].values():
        setup_index = -1
        install_index = -1
        echo_index = -1
        for index, step in enumerate(job["steps"]):
            if "pip install " in step.get("run", "") and " --user " in step.get(
                "run", ""
            ):
                step["run"] = step["run"].replace(" --user ", " ")
            if install_index < 0 and pip_install_re.search(step.get("run", "")):
                install_index = index
            if setup_index < 0 and step.get("uses", "").startswith(
                "actions/setup-python@"
            ):
                setup_index = index
            if (
                echo_index < 0
                and step.get("run", "") == 'echo "${HOME}/.local/bin" >> ${GITHUB_PATH}'
            ):
                echo_index = index
        if install_index >= 0 and setup_index < 0:
            job["steps"].insert(
                install_index,
                {
                    "uses": "actions/setup-python@v5",
                    "with": {
                        "python-version": _VERSIONS["python"],
                    },
                },
            )
        if echo_index >= 0:
            del job["steps"][echo_index]


def _update_main_workflow(task_env: TaskEnv) -> None:
    if os.path.exists(".github/workflows/codeql.yaml"):
        os.remove(".github/workflows/codeql.yaml")
    if not os.path.exists(".github/workflows/main.yaml") and os.path.exists(
        ".github/workflows/ci.yaml"
    ):
        os.rename(".github/workflows/ci.yaml", ".github/workflows/main.yaml")
    if os.path.exists(".github/workflows/main.yaml"):
        with mra.EditYAML(".github/workflows/main.yaml") as yaml:
            _update_workflow_venv(task_env, yaml)

            permissions = yaml.setdefault("permissions", {})
            permissions["contents"] = "write"
            if task_env.use_docker:
                permissions["packages"] = "write"
            if task_env.use_pypi:
                permissions["id-token"] = "write"

            for job_name, job in yaml["jobs"].items():
                pre_commit_index = -1
                has_pre_commit_artifacts = False
                publish_index = -1
                tag_publish_index = -1
                has_publish_artifacts = False
                for index, step in enumerate(job["steps"]):
                    if step.get("run", "").startswith("pre-commit run"):
                        if step["run"] == "pre-commit run --all-files":
                            step["run"] = "pre-commit run --all-files --color=always"
                        pre_commit_index = index
                    if step.get("run", "").startswith("c2cciutils-publish"):
                        publish_index = index
                    if step.get("run", "").startswith("tag-publish"):
                        tag_publish_index = index
                    if (
                        step.get("uses", "").startswith("actions/upload-artifact@")
                        and step.get("with", {}).get("name", "")
                        == "Apply pre-commit fix.patch"
                    ):
                        has_pre_commit_artifacts = True
                    if (
                        step.get("uses", "").startswith("actions/upload-artifact@")
                        and step.get("with", {}).get("name", "")
                        == "Update dpkg versions list.patch"
                    ):
                        has_publish_artifacts = True

                index_add = 0
                for index, filename, has_artifact, artifact_name in (
                    (
                        pre_commit_index,
                        "pre-commit",
                        has_pre_commit_artifacts,
                        "Apply pre-commit fix",
                    ),
                    (
                        publish_index,
                        "dpkg-versions",
                        has_publish_artifacts,
                        "Update dpkg versions list",
                    ),
                    (
                        tag_publish_index,
                        "dpkg-versions",
                        has_publish_artifacts,
                        "Update dpkg versions list",
                    ),
                ):
                    if index >= 0:
                        if not task_env.on_stabilization_branches:
                            if (
                                job["steps"][index + index_add]
                                .get("env", {})
                                .get("SKIP", "")
                                .strip(",")
                                == "poetry-lock"
                            ):
                                del job["steps"][index + index_add]["env"]["SKIP"]
                                if not job["steps"][index + index_add]["env"]:
                                    del job["steps"][index + index_add]["env"]
                        if len(job["steps"]) > index + index_add + 1 and job["steps"][
                            index + index_add + 1
                        ].get("run", "").startswith("git diff"):
                            job["steps"][index + index_add + 1][
                                "run"
                            ] = f"git diff --exit-code --patch > /tmp/{filename}.patch; git diff --color; git reset --hard || true"
                            job["steps"][index + index_add + 1]["if"] = "failure()"
                        else:
                            job["steps"].insert(
                                index + index_add + 1,
                                {
                                    "run": f"git diff --exit-code --patch > /tmp/{filename}.patch || true",
                                    "if": "failure()",
                                },
                            )
                            index_add += 1
                        if not has_artifact and index >= 0:
                            job["steps"].insert(
                                index + index_add + 1,
                                {
                                    "uses": "actions/upload-artifact@v4",
                                    "with": {
                                        "name": f"{artifact_name}.patch",
                                        "path": f"/tmp/{filename}.patch",
                                        "retention-days": 1,
                                    },
                                    "if": "failure()",
                                },
                            )
                            index_add += 1

                publish_index = -1

                for index, step in enumerate(job["steps"]):
                    if not task_env.on_stabilization_branches:
                        if task_env.c2cciutils_version >= version.parse("1.6.0"):
                            if step.get("run", "") == "c2cciutils-checks":
                                step["name"] = "Print environment information"
                                step["run"] = "c2cciutils-env"
                                value = None
                                if "env" in step:
                                    if step["env"].ca.items:
                                        value = list(step["env"].ca.items.values())[-1][
                                            2
                                        ].value
                                    del step["env"]
                                step["env"] = {"GITHUB_EVENT": "${{ toJson(github) }}"}
                                job["steps"].ca.items[index] = [
                                    None,
                                    None,
                                    [
                                        ruamel.yaml.CommentToken(
                                            value or "\n\n",
                                            ruamel.yaml.error.CommentMark(0),
                                            None,
                                        )
                                    ],
                                    None,
                                ]
                        else:
                            if step.get("run", "") == "c2cciutils-checks":
                                if not task_env.gopass:
                                    env = step.setdefault("env", {})
                                    env["SNYK_TOKEN"] = (  # nosec
                                        "${{ secrets.SNYK_TOKEN }}"
                                    )

            if len(yaml["jobs"]) > 1:
                candidate_jobs = set()
                needed_jobs = set()
                success_job = False
                for name, job in yaml["jobs"].items():
                    if name == "success":
                        success_job = True
                    if "needs" in job:
                        candidate_jobs.add(name)
                        if isinstance(job["needs"], list):
                            needed_jobs += job["needs"]
                        else:
                            needed_jobs.add(job["needs"])
                for needed_job in needed_jobs:
                    if needed_job in candidate_jobs:
                        candidate_jobs.remove(needed_job)
                if len(candidate_jobs) == 1 and not success_job:
                    candidate_job = list(candidate_jobs)[0]

                    yaml["jobs"]["success"] = {
                        "name": "Success",
                        "runs-on": "ubuntu-22.04",
                        "timeout-minutes": 5,
                        "needs": yaml["jobs"][candidate_job]["needs"],
                        "steps": [
                            {
                                "run": "touch SUCCESS",
                            },
                            {
                                "uses": "actions/upload-artifact@v4",
                                "with": {
                                    "name": "Success",
                                    "path": "SUCCESS",
                                    "retention-days": 1,
                                },
                            },
                        ],
                    }

                    yaml["jobs"][candidate_job]["needs"] = "success"
                    if "if" in yaml["jobs"][candidate_job]:
                        yaml["jobs"]["success"][
                            "if"
                        ] = f"always() && {yaml['jobs'][candidate_job]['if']}"
                    else:
                        yaml["jobs"]["success"]["if"] = "always()"

                    step = {
                        "name": "Check if related check run failed",
                        "uses": "actions/download-artifact@v4",
                        "with": {
                            "name": "Success",
                        },
                    }
                    if job_name == "publish":
                        job["steps"].insert(0, step)
                    else:
                        job["steps"].append(step)

            if not task_env.on_stabilization_branches or yaml.is_modified():
                _canonicalize_workflow(yaml)


def _update_audit_workflow(task_env: TaskEnv) -> None:
    if os.path.exists(".github/workflows/audit.yaml"):
        os.remove(".github/workflows/audit.yaml")


def _update_changelog_workflow(task_env: TaskEnv) -> None:
    if os.path.exists(".github/changelog-config.yaml"):
        os.remove(".github/changelog-config.yaml")
    if os.path.exists(".github/workflows/changelog.yaml"):
        os.remove(".github/workflows/changelog.yaml")
    if os.path.exists(".github/run-changelog.mjs"):
        os.remove(".github/run-changelog.mjs")


def _update_clean_workflow(task_env: TaskEnv) -> None:
    if not task_env.use_docker:
        if os.path.exists(".github/workflows/clean.yaml"):
            os.remove(".github/workflows/clean.yaml")
        return
    if os.path.exists(".github/workflows/clean.yaml"):
        with mra.EditYAML(".github/workflows/clean.yaml") as yaml:
            _update_workflow_venv(task_env, yaml)


def _update_delete_old_workflows_run_workflow(task_env: TaskEnv) -> None:
    if os.path.exists(".github/workflows/delete-old-workflow-run.yaml"):
        os.remove(".github/workflows/delete-old-workflow-run.yaml")
    if os.path.exists(".github/workflows/delete-old-workflows-run.yaml"):
        os.remove(".github/workflows/delete-old-workflows-run.yaml")


def safe_or(elements: list[str], prefix: str = "") -> str:
    if len(elements) == 0:
        return ""
    if len(elements) == 1:
        return elements[0]
    return "(" + f"\n{prefix}|| ".join(elements) + ")"


def _and(elements: list[str], prefix: str = "") -> str:
    elements = [e for e in elements if e]
    if len(elements) == 0:
        return ""
    return f"\n{prefix}&& ".join(elements)


def _update_pull_request_automation_workflow(task_env: TaskEnv) -> None:
    for file_ in (
        ".github/workflows/dependabot-auto-merge.yaml",
        ".github/workflows/auto-review.yaml",
        ".github/workflows/auto-merge.yaml",
        ".github/workflows/dependency-update-review.yaml",
        ".github/workflows/dependency-auto-review.yaml",
    ):
        if os.path.exists(file_):
            if os.path.exists(".github/workflows/pull-request-automation.yaml"):
                os.remove(file_)
            else:
                mra.run(
                    [
                        "git",
                        "mv",
                        file_,
                        ".github/workflows/pull-request-automation.yaml",
                    ]
                )
    if not os.path.exists(".github/workflows/pull-request-automation.yaml"):
        with mra.Edit(".github/workflows/pull-request-automation.yaml") as text:
            text.data = "\n".join(
                [
                    "name: Auto reviews updates",
                    "",
                    "on:",
                    "  pull_request:",
                    "    types:",
                    "      - opened",
                    "      - reopened",
                    "",
                    "jobs:",
                    "  auto-merge:",
                    "    name: Auto reviews updates",
                    "    runs-on: ubuntu-22.04",
                    "    timeout-minutes: 5",
                    "",
                    "    steps:",
                    "      - uses: actions/github-script@v7",
                    "        with:",
                    "          script: |-",
                    "            github.rest.pulls.createReview({",
                    "              owner: context.repo.owner,",
                    "              repo: context.repo.repo,",
                    "              pull_number: context.payload.pull_request.number,",
                    "              event: 'APPROVE',",
                    "            })",
                    "    if: github.event.pull_request.user.login == 'renovate[bot]'",
                ]
            )
    with mra.EditYAML(".github/workflows/pull-request-automation.yaml") as yaml:
        task_env.config.value("dependencyAutoReviewUsers", ["renovate[bot]"])
        yaml["name"] = "Auto reviews pull requests from bots"
        yaml["on"] = {
            "pull_request": {"types": ["opened", "reopened"]},
        }
        yaml["name"] = "Auto reviews, merge and close pull requests"
        for job in yaml["jobs"].values():
            job["name"] = "Auto reviews pull requests from bots"
            if "if" in job:
                del job["if"]

            PRINT_EVENT = "Print event"
            PRINT_CONTEXT = "Print context"
            AUTO_REVIEW_GHCI_UPDATES = "Auto reviews GHCI updates"
            AUTO_REVIEW_RENOVATE_UPDATES = "Auto reviews Renovate updates"
            AUTO_REVIEW_AND_MERGE_DPKG_UPDATES = "Auto review and merge dpkg updates"
            AUTO_REVIEW_AND_MERGE_SNYK_AUTO_FIX = "Auto review and merge snyk auto fix"
            step_names = [
                PRINT_EVENT,
                PRINT_CONTEXT,
                AUTO_REVIEW_GHCI_UPDATES,
                AUTO_REVIEW_RENOVATE_UPDATES,
            ]

            old_step = {}
            for new_step_name in step_names:
                for step in job["steps"]:
                    if step.get("name") == new_step_name:
                        old_step[new_step_name] = step
                        break

            job["steps"] = [old_step.get(step, {"name": step}) for step in step_names]

            auto_review_and_merge_snyk_auto_fix_index = -1
            for index, step in enumerate(job["steps"]):
                if step["name"] == AUTO_REVIEW_AND_MERGE_SNYK_AUTO_FIX:
                    auto_review_and_merge_snyk_auto_fix_index = index
            if auto_review_and_merge_snyk_auto_fix_index >= 0:
                del job["steps"][auto_review_and_merge_snyk_auto_fix_index]

            auto_review_and_merge_dpkg_update_index = -1
            for index, step in enumerate(job["steps"]):
                if step["name"] == AUTO_REVIEW_AND_MERGE_DPKG_UPDATES:
                    auto_review_and_merge_dpkg_update_index = index
            if auto_review_and_merge_dpkg_update_index >= 0:
                del job["steps"][auto_review_and_merge_dpkg_update_index]

            for step in job["steps"]:
                if step["name"] == PRINT_EVENT:
                    step["run"] = 'echo "${GITHUB}" | jq'
                    step["env"] = {
                        "GITHUB": "${{ toJson(github) }}",
                    }
                if step["name"] == PRINT_CONTEXT:
                    if not step.get("uses", "").startswith("actions/github-script@"):
                        step["uses"] = "actions/github-script@v7"
                    step["with"] = {
                        "script": ruamel.yaml.scalarstring.LiteralScalarString(
                            "\n".join(["console.log(context);"])
                        )
                    }
                    if "if" in step:
                        del step["if"]
                    if "env" in step:
                        del step["env"]
                if step["name"] == AUTO_REVIEW_GHCI_UPDATES:
                    if not step.get("uses", "").startswith("actions/github-script@"):
                        step["uses"] = "actions/github-script@v7"
                    step["if"] = ruamel.yaml.scalarstring.LiteralScalarString(
                        _and(
                            [
                                "startsWith(github.head_ref, 'ghci/audit/')",
                                safe_or(
                                    [
                                        f"github.event.pull_request.user.login == 'geo-ghci-test[bot]'",
                                        f"github.event.pull_request.user.login == 'geo-ghci-int[bot]'",
                                        f"github.event.pull_request.user.login == 'geo-ghci[bot]'",
                                    ],
                                    "  ",
                                ),
                            ]
                        )
                    )
                    step["with"] = {
                        "script": ruamel.yaml.scalarstring.LiteralScalarString(
                            "\n".join(
                                [
                                    "github.rest.pulls.createReview({",
                                    "  owner: context.repo.owner,",
                                    "  repo: context.repo.repo,",
                                    "  pull_number: context.payload.pull_request.number,",
                                    "  event: 'APPROVE',",
                                    "})",
                                ]
                            )
                        )
                    }
                if step["name"] == AUTO_REVIEW_RENOVATE_UPDATES:
                    if not step.get("uses", "").startswith("actions/github-script@"):
                        step["uses"] = "actions/github-script@v7"
                    step["if"] = ruamel.yaml.scalarstring.LiteralScalarString(
                        f"github.event.pull_request.user.login == 'renovate[bot]'",
                    )
                    step["with"] = {
                        "script": ruamel.yaml.scalarstring.LiteralScalarString(
                            "\n".join(
                                [
                                    "github.rest.pulls.createReview({",
                                    "  owner: context.repo.owner,",
                                    "  repo: context.repo.repo,",
                                    "  pull_number: context.payload.pull_request.number,",
                                    "  event: 'APPROVE',",
                                    "})",
                                ]
                            )
                        )
                    }

        if not task_env.on_stabilization_branches or yaml.is_modified():
            _canonicalize_workflow(yaml)


def _update_pull_request_checks_workflow(task_env: TaskEnv) -> None:
    if os.path.exists(".github/workflows/pr-checks.yaml"):
        os.remove(".github/workflows/pr-checks.yaml")
    if os.path.exists(".github/workflows/test_url.yaml"):
        os.remove(".github/workflows/test_url.yaml")


def _update_backport_workflow(task_env: TaskEnv) -> None:
    if not task_env.has_stabilization_branches:
        if os.path.exists(".github/workflows/backport.yaml"):
            os.remove(".github/workflows/backport.yaml")
        return


class _PythonVersion:
    def __init__(self, version: str) -> None:
        version_split = version.split(".")
        self.major = int(version_split[0])
        self.minor = int(version_split[1])


def _update_pyproject_toml(task_env: TaskEnv) -> None:
    """
    Add or update the Poetry extensions to the pyproject.toml file.
    """

    poetry_version = version.parse("0.0.0")
    for requirements_file_name in ("requirements.txt", "ci/requirements.txt"):
        if os.path.exists(requirements_file_name):
            with mra.Edit(requirements_file_name) as requirements_txt:
                for line in requirements_txt.data.splitlines():
                    if line.startswith("poetry=="):
                        poetry_version = version.parse(line.split("==")[1])
                        break

    if poetry_version >= version.parse("1.3.0"):
        typed = (
            len(
                mra.run(
                    ["git", "ls-files", "py.typed"],
                    exit_on_error=False,
                    stdout=subprocess.PIPE,
                    encoding="utf-8",
                ).stdout.strip()
            )
            > 0
        )
        for pyproject_filename in (
            "pyproject.toml",
            "app/pyproject.toml",
            "api/pyproject.toml",
        ):
            if os.path.exists(pyproject_filename):
                with mra.EditTOML(pyproject_filename) as pyproject:
                    if "requires" in pyproject.get(
                        "build-system", {}
                    ) and "python" in pyproject.get("tool", {}).get("poetry", {}).get(
                        "dependencies", {}
                    ):
                        classifiers = (
                            pyproject.setdefault("tool", {})
                            .setdefault("poetry", {})
                            .setdefault("classifiers", [])
                        )
                        if typed and "Typing :: Typed" not in classifiers:
                            classifiers.append("Typing :: Typed")
                        # if task_env.min_python_version and task_env.max_python_version:
                        #    min_python_version = _PythonVersion(task_env.min_python_version)
                        #    max_python_version = _PythonVersion(task_env.max_python_version)
                        #    classifiers = [c for c in classifiers if not c.startswith("Programming Language :: Python")]
                        #    classifiers.append("Programming Language :: Python")
                        #    classifiers.append("Programming Language :: Python :: 3")
                        #    for minor in range(min_python_version.minor, max_python_version.minor + 1):
                        #        classifiers.append(f"Programming Language :: Python :: {min_python_version.major}.{minor}")
                        pyproject["tool"]["poetry"]["classifiers"] = sorted(classifiers)

                        version_splitter = re.compile("[<>=]+")
                        [
                            version_splitter.split(p)[0]
                            for p in pyproject["build-system"]["requires"]
                        ]
                        for requirements_file_name_candidate in (
                            "requirements.txt",
                            "ci/requirements.txt",
                        ):
                            if os.path.exists(requirements_file_name_candidate):
                                with mra.Edit(
                                    requirements_file_name_candidate
                                ) as requirements_txt:
                                    if "poetry" in requirements_txt.data:
                                        break
                        # for dependency, plugin, plugin_version in (
                        #     (True, "poetry-dynamic-versioning", _VERSIONS["poetry-dynamic-versioning"]),
                        #     (True, "poetry-plugin-tweak-dependencies-version", _VERSIONS["poetry-plugin-tweak-dependencies-version"]),
                        #     (True, "poetry-plugin-drop-python-upper-constraint", _VERSIONS["poetry-plugin-drop-python-upper-constraint"]),
                        #     (False, "poetry-plugin-export", _VERSIONS["poetry-plugin-export"]),
                        # ):
                        #     requirement = not dependency
                        #     if dependency and plugin not in build_system_requires_no_version:
                        #         pyproject.data["build-system"]["requires"].append(plugin)
                        #         requirement = True
                        #     if requirement and requirement_file_name:
                        #         with mra.Edit(requirements_file_name) as requirements_txt:
                        #                     if (
                        #                         f"{plugin}==" not in requirements_txt.data
                        #                         and f"{plugin}[" not in requirements_txt.data
                        #                     ):
                        #                         requirements_txt.data += f"{plugin}=={plugin_version}\n"

                        poetry_dynamic_versioning = pyproject.setdefault(
                            "tool", {}
                        ).setdefault("poetry-dynamic-versioning", {})
                        poetry_dynamic_versioning.setdefault("enable", True)
                        poetry_dynamic_versioning.setdefault("vcs", "git")
                        poetry_dynamic_versioning.setdefault(
                            "pattern", "^(?P<base>\\d+(\\.\\d+)*)"
                        )
                        if "style" in poetry_dynamic_versioning:
                            del poetry_dynamic_versioning["style"]
                        poetry_dynamic_versioning["format-jinja"] = (
                            tomlkit.items.String.from_raw(
                                "\n".join(
                                    [
                                        "",
                                        '{%- if env.get("VERSION_TYPE") == "version_branch" -%}',
                                        '{{serialize_pep440(bump_version(base, 1 if env.get("IS_MASTER") == "TRUE" else 2), dev=distance)}}',
                                        "{%- elif distance == 0 -%}",
                                        "{{serialize_pep440(base)}}",
                                        "{%- else -%}",
                                        "{{serialize_pep440(bump_version(base), dev=distance)}}",
                                        "{%- endif -%}",
                                        "",
                                    ]
                                ),
                                tomlkit.items.StringType.MLB,
                            )
                        )
                        poetry_plugin_tweak_dependencies_version = pyproject.setdefault(
                            "tool", {}
                        ).setdefault("poetry-plugin-tweak-dependencies-version", {})
                        poetry_plugin_tweak_dependencies_version.setdefault(
                            "default", "present"
                        )

                        pyproject.setdefault("tool", {}).setdefault(
                            "ruff", {}
                        ).setdefault("line-length", 110)
                        pyproject.setdefault("tool", {}).setdefault(
                            "ruff", {}
                        ).setdefault("target-version", "py310")
                        pyproject["tool"]["ruff"].setdefault("lint", {}).setdefault(
                            "pydocstyle", {}
                        ).setdefault("convention", "numpy")
                        for rm_tool in ("mypy", "black", "isort"):
                            if rm_tool in pyproject["tool"]:
                                del pyproject["tool"][rm_tool]

                    if pyproject.get("tool", {}).get(
                        "poetry-dynamic-versioning", {}
                    ).get("format-jinja", {}).strip() == "\n".join(
                        [
                            '{%- if env.get("VERSION_TYPE") == "version_branch" -%}',
                            '{{serialize_pep440(bump_version(base, 1 if env.get("IS_MASTER") == "TRUE" else 2), dev=distance)}}',
                            "{%- elif distance == 0 -%}",
                            "{{serialize_pep440(base)}}",
                            "{%- else -%}",
                            "{{serialize_pep440(bump_version(base), dev=distance)}}",
                            "{%- endif -%}",
                        ]
                    ):
                        pyproject["tool"]["poetry-dynamic-versioning"][
                            "format-jinja"
                        ] = tomlkit.items.String.from_raw(
                            "\n".join(
                                [
                                    "",
                                    '{%- if env.get("VERSION_TYPE") == "default_branch" -%}',
                                    "{{serialize_pep440(bump_version(base, 1), dev=distance)}}",
                                    '{%- elif env.get("VERSION_TYPE") == "stabilization_branch" -%}',
                                    "{{serialize_pep440(bump_version(base, 2), dev=distance)}}",
                                    "{%- elif distance == 0 -%}",
                                    "{{serialize_pep440(base)}}",
                                    "{%- else -%}",
                                    "{{serialize_pep440(bump_version(base), dev=distance)}}",
                                    "{%- endif -%}",
                                    "",
                                ]
                            ),
                            tomlkit.items.StringType.MLB,
                        )


def _update_prospector_config(task_env: TaskEnv) -> None:
    if os.path.exists("..whitesource"):
        os.remove("..whitesource")
    use_c2cwsiutils = (
        mra.run(
            ["git", "grep", "c2cwsgiutils"],
            exit_on_error=False,
            stdout=subprocess.DEVNULL,
        ).returncode
        == 0
    )
    for bandit_filename in mra.run(
        ["git", "ls-files", ".bandit.yaml"], stdout=subprocess.PIPE
    ).stdout.splitlines():
        if os.path.exists(bandit_filename):
            os.remove(bandit_filename)
    for prospector_filename in mra.run(
        ["git", "ls-files", ".prospector.yaml"], stdout=subprocess.PIPE
    ).stdout.splitlines():
        with mra.EditYAML(prospector_filename) as prospector_config:
            if "bandit" in prospector_config:
                del prospector_config["bandit"]
            if "utils:base" in prospector_config.get("inherits", []):
                for inherit in (
                    "utils:fix",
                    "utils:unsafe",
                    *(["utils:c2cwsgiutils"] if use_c2cwsiutils else []),
                ):
                    if inherit not in prospector_config.get("inherits", []):
                        prospector_config["inherits"].append(inherit)

            # if task_env.min_python_version:
            #    prospector_config.setdefault("mypy", {}).setdefault("options", {}).setdefault("python_version", task_env.min_python_version)


# def _update_python_version(task_env: TaskEnv) -> None:
#    if task_env.min_python_version:
#        if os.exists("jsonschema-gentypes.yaml"):
#            with mra.Edit("jsonschema-gentypes.yaml") as jsonschema_gentypes:
#                jsonschema_gentypes['python_version'] = task_env.min_python_version


def _update_renovate_config(task_env: TaskEnv) -> None:
    if not os.path.exists(".github/renovate.json5"):
        return
    upgrade_required = False
    with mra.EditRenovateConfigV2() as renovate_config:
        if "regexManagers" in renovate_config:
            upgrade_required = True

    if upgrade_required:
        with mra.Edit(".github/renovate.json5") as renovate_config:
            renovate_config.data = renovate_config.data.replace(
                "regexManagers", "customManagers"
            )
        with mra.EditRenovateConfigV2() as renovate_config:
            for custom_manager in renovate_config["customManagers"]:
                custom_manager["customType"] = "regex"

    if task_env.c2cciutils_version >= version.parse("1.6.0"):
        if not os.path.exists(".github/renovate.json5"):
            with mra.Edit(".github/renovate.json5") as renovate_config:
                renovate_config.data = "{}"

    with mra.EditRenovateConfigV2() as renovate_config:
        # matchPackagePrefixes => matchPackageNames
        for package_rule in renovate_config["packageRules"]:
            if "matchPackagePrefixes" in package_rule:
                package_rule["matchPackageNames"] = [
                    f"/^{re.escape(prefix)}.*/"
                    for prefix in package_rule["matchPackagePrefixes"]
                ]
                del package_rule["matchPackagePrefixes"]

        extends = [
            e if isinstance(e, str) else e.value
            for e in renovate_config.get("extends", [])
        ]
        extends = [
            e
            for e in extends
            if not e.startswith("config:")
            and e
            not in (
                "group:monorepos",
                "group:recommended",
                "replacements:all",
                "workarounds:all",
            )
        ]
        extends_base = [e.split("@")[0] for e in extends]
        for new_extend in (
            "github>camptocamp/gs-renovate-config-preset:base.json5#"
            + _VERSIONS["camptocamp/gs-renovate-config-preset"],
            "github>camptocamp/gs-renovate-config-preset:ci.json5#"
            + _VERSIONS["camptocamp/gs-renovate-config-preset"],
            "github>camptocamp/gs-renovate-config-preset:pre-commit.json5#"
            + _VERSIONS["camptocamp/gs-renovate-config-preset"],
            "github>camptocamp/gs-renovate-config-preset:python.json5#"
            + _VERSIONS["camptocamp/gs-renovate-config-preset"],
            "github>camptocamp/gs-renovate-config-preset:json-schema.json5#"
            + _VERSIONS["camptocamp/gs-renovate-config-preset"],
            "github>camptocamp/gs-renovate-config-preset:shellcheck.json5#"
            + _VERSIONS["camptocamp/gs-renovate-config-preset"],
        ):
            if new_extend.split("@")[0] not in extends_base:
                renovate_config["extends"].append(new_extend)

        for property in (
            "timezone",
            "schedule",
            "labels",
            "separateMajorMinor",
            "separateMinorPatch",
            "prHourlyLimit",
            "prConcurrentLimit",
            "lockFileMaintenance",
        ):
            if property in renovate_config:
                del renovate_config[property]
        if "html" in renovate_config and (
            renovate_config["html"] == {"fileMatch": ["\\.html?$", "\\.html?.mako$"]}
            or renovate_config["html"] == {"fileMatch": ["\\.html?$"]}
            or renovate_config["html"] == {"fileMatch": ["\\.html?.mako$"]}
        ):
            del renovate_config["html"]

        renovate_config.remove_package_rule(
            {}, ["Group and auto merge the patch updates"]
        )
        renovate_config.remove_package_rule(
            {}, ["Group and auto merge the minor updates"]
        )

        # CI
        renovate_config.remove_package_rule({}, ["Group the dev dependency update"])
        renovate_config.remove_package_rule(
            {}, ["Auto merge the dev dependency update"]
        )
        renovate_config.remove_package_rule(
            {}, ["Group and auto merge the CI dependencies"]
        )

        # pre-commit
        if "pre-commit" in renovate_config:
            del renovate_config["pre-commit"]
        renovate_config.remove_regex_manager(
            {}, ["Do updates on pre-commit additional dependencies"]
        )

        # python
        renovate_config.remove_package_rule({}, ["Ungroup Python dependencies"])
        renovate_config.remove_regex_manager(
            {}, ["Python version in actions/setup-python action"]
        )
        renovate_config.remove_package_rule(
            {}, ["In file .python-version, use the <major>.<minor> version"]
        )
        renovate_config.remove_package_rule(
            {}, ["In file `.python-version`, use the `<major>.<minor>` version"]
        )

        # json-schema
        renovate_config.remove_regex_manager(
            {}, ["Do update on the schema present in the YAML files"]
        )

        # shellcheck
        renovate_config.remove_package_rule(
            {}, ["Support the 4 parts of shellcheck-py version with a v prefix"]
        )

        renovate_config.remove_package_rule({}, ["Update dpkg versions at any time"])

        if (
            not task_env.has_stabilization_branches
            or task_env.stabilization_branches == ["master"]
        ):
            if "baseBranches" in renovate_config:
                del renovate_config["baseBranches"]
            renovate_config.remove_package_rule(
                {}, ["Accept only the patch on stabilization branches"]
            )
            renovate_config.remove_package_rule(
                {}, ["Accept only the patch on the stabilization branches"]
            )

        renovate_config.remove_package_rule(
            {}, ["In file .python-version, use the <major>.<minor> version"]
        )
        if os.path.exists(".python-version"):
            renovate_config.add_package_rule(
                {
                    "matchFileNames": [".python-version"],
                    "versioning": "regex:^(?<major>\\d+)\\.(?<minor>\\d+)$",
                },
                ["In file `.python-version`, use the `<major>.<minor>` version"],
            )

        renovate_config.remove_package_rule({}, ["Group Poetry packages"])
        if not renovate_config["packageRules"]:
            del renovate_config["packageRules"]
        if not renovate_config["customManagers"]:
            del renovate_config["customManagers"]


def _update_config(task_env: TaskEnv) -> None:
    if os.path.exists(
        "ci/config.yaml"
    ) and task_env.c2cciutils_version >= version.parse("1.6.0"):
        with mra.EditYAML("ci/config.yaml") as config:
            if "checks" in config:
                del config["checks"]
            to_delete = len(config.keys()) == 0
        if to_delete:
            os.remove("ci/config.yaml")
    if not os.path.exists("ci/config.yaml"):
        with mra.EditPreCommitConfig() as pre_commit_config:
            for index, repo in enumerate(list(pre_commit_config["repos"])):
                print(repo["repo"])
                if repo["repo"] == "https://github.com/sbrunner/jsonschema-validator":
                    print(8888)
                    if len(repo.get("hooks", [])) >= 1 and repo["hooks"][0].get(
                        "files", ""
                    ).strip() == "\n".join(["(?x)^(", r"    ci/config\.yaml", ")$"]):
                        del pre_commit_config["repos"][index]

    if task_env.use_docker:
        if not os.path.exists("ci/dpkg-versions.yaml"):
            with open("ci/dpkg-versions.yaml", "w", encoding="utf-8") as dpkg_versions:
                dpkg_versions.write("{}")


def _update_pre_commit_config(task_env: TaskEnv) -> None:
    if os.path.exists(".pre-commit-config.yaml"):
        with mra.EditPreCommitConfig() as pre_commit_config:
            if "ci" in pre_commit_config:
                del pre_commit_config["ci"]

            pre_commit_config.add_repo(
                "https://github.com/renovatebot/pre-commit-hooks",
                _VERSIONS["renovatebot/pre-commit-hooks"],
            )
            pre_commit_config.add_hook(
                "https://github.com/renovatebot/pre-commit-hooks",
                {
                    "id": "renovate-config-validator",
                },
            )

            # Do a spell check on the found schemas
            schemas = []
            for files_ in ("*.schema.json", "schema.json", "schema-*.json"):
                schemas += [
                    f
                    for f in mra.run(
                        ["git", "ls-files", files_], stdout=subprocess.PIPE
                    ).stdout.split("\n")
                    if f
                ]
                # Get all the schemas files
                schemas += [
                    f
                    for f in mra.run(
                        ["git", "ls-files", f"**/{files_}"], stdout=subprocess.PIPE
                    ).stdout.split("\n")
                    if f
                ]

            if schemas:
                pre_commit_config.add_repo(
                    "https://github.com/mheap/json-schema-spell-checker",
                    _VERSIONS["mheap/json-schema-spell-checker"],
                )
                pre_commit_config.add_hook(
                    "https://github.com/mheap/json-schema-spell-checker",
                    {
                        "id": "json-schema-spell-checker",
                        "files": pre_commit_config.create_files_regex(
                            [re.escape(f) for f in schemas]
                        ),
                        "args": [
                            "--fields=description,title",
                            "--spelling=.github/spell-ignore-words.txt",
                            "--ignore-numbers",
                            "--ignore-acronyms",
                            "--en-us",
                        ],
                    },
                )

            for repo in pre_commit_config["repos"]:
                if (
                    repo["repo"]
                    == "https://github.com/python-jsonschema/check-jsonschema"
                ):
                    for index, hook in enumerate(list(repo["hooks"])):
                        if hook["id"] == "check-renovate":
                            del repo["hooks"][index]
                            break

            if task_env.use_python:
                rm_repos = (
                    "https://github.com/psf/black",
                    "https://github.com/PyCQA/isort",
                    "https://github.com/PyCQA/autoflake",
                    "https://github.com/asottile/pyupgrade",
                )
                continue_ = True
                while continue_:
                    continue_ = False
                    for name, repo in enumerate(list(pre_commit_config["repos"])):
                        if repo["repo"] in rm_repos:
                            del pre_commit_config["repos"][name]
                            continue_ = True
                            break

                pre_commit_config.add_repo(
                    "https://github.com/astral-sh/ruff-pre-commit",
                    _VERSIONS["astral-sh/ruff-pre-commit"],
                )
                pre_commit_config.add_hook(
                    "https://github.com/astral-sh/ruff-pre-commit",
                    {"id": "ruff-format"},
                )
                pre_commit_config.add_repo(
                    "https://github.com/PyCQA/prospector", _VERSIONS["PyCQA/prospector"]
                )
                pre_commit_config.add_hook(
                    "https://github.com/PyCQA/prospector",
                    {
                        "id": "prospector",
                    },
                )
                prospector_hook = pre_commit_config.repos_hooks[
                    "https://github.com/PyCQA/prospector"
                ]["hooks"]["prospector"]
                prospector_hook["args"] = [
                    "--tool=ruff",
                    "--die-on-tool-error",
                    "--output-format=pylint",
                ]
                if (
                    "prospector"
                    in pre_commit_config.repos_hooks[
                        "https://github.com/PyCQA/prospector"
                    ]["hooks"]
                ):
                    current_deps = [
                        deps.split("=")[0]
                        for deps in prospector_hook.get("additional_dependencies", [])
                    ]
                    for deps in [
                        "prospector-profile-duplicated=="
                        + _VERSIONS["prospector-profile-duplicated"],
                        "prospector-profile-utils=="
                        + _VERSIONS["prospector-profile-utils"],
                        "ruff==" + _VERSIONS["ruff"],
                    ]:
                        if deps.split("=")[0] not in current_deps:
                            pre_commit_config.add_commented_additional_dependencies(
                                prospector_hook, [deps], "pypi"
                            )
                    pre_commit_config.repos_hooks[
                        "https://github.com/PyCQA/prospector"
                    ]["hooks"]["prospector"] = prospector_hook
                pre_commit_config.add_repo(
                    "https://github.com/sbrunner/python-versions-hook",
                    _VERSIONS["sbrunner/python-versions-hook"],
                )
                pre_commit_config.add_hook(
                    "https://github.com/sbrunner/python-versions-hook",
                    {
                        "id": "python-versions",
                    },
                )
                sbrunner_repo_hooks = pre_commit_config.repos_hooks[
                    "https://github.com/sbrunner/hooks"
                ]["hooks"]
                for name, hook in list(sbrunner_repo_hooks.items()):
                    if hook["id"] == "poetry-check":
                        del sbrunner_repo_hooks[name]

                jsonschema_repo_hooks = pre_commit_config.repos_hooks[
                    "https://github.com/python-jsonschema/check-jsonschema"
                ]["hooks"]
                for name, hook in list(jsonschema_repo_hooks.items()):
                    if hook["id"] == "check-renovate":
                        del jsonschema_repo_hooks[name]


def _use_tag_publish(task_env: TaskEnv) -> None:
    if not os.path.exists(".github/workflows/main.yaml"):
        return

    add_tag_publish = False
    with mra.EditYAML(".github/workflows/main.yaml") as yaml:
        for job in yaml["jobs"].values():
            for step in job["steps"]:
                if step.get("run", "").startswith("tag-publish"):
                    add_tag_publish = True
                elif step.get("run", "").startswith("c2cciutils-publish"):
                    add_tag_publish = True
                    step["run"] = step["run"].replace(
                        "c2cciutils-publish", "tag-publish"
                    )
                    step.setdefault("env", {})[
                        "GITHUB_TOKEN"
                    ] = "${{ secrets.GITHUB_TOKEN }}"  # nosec

    if not add_tag_publish:
        return

    for candidate_requirements_filename in (
        ".github/requirements.txt",
        "ci/requirements.txt",
        "requirements.txt",
    ):
        if os.path.exists(candidate_requirements_filename):
            with mra.Edit(candidate_requirements_filename) as requirements_txt:
                if "c2cciutils" in requirements_txt.data:
                    if "tag-publish" not in requirements_txt.data:
                        requirements_txt.data += (
                            f"tag-publish=={_VERSIONS['tag-publish']}\n"
                        )
                    break


def _remove_docker_compose_version(task_env: TaskEnv) -> None:
    for docker_compose_filename in [
        *glob.glob("**/docker-compose.yaml"),
        *glob.glob("**/docker-compose.*.yaml"),
        *glob.glob("**/docker-compose-*.yaml"),
        *glob.glob("docker-compose.yaml"),
        *glob.glob("docker-compose.*.yaml"),
        *glob.glob("docker-compose-*.yaml"),
    ]:
        with mra.EditYAML(docker_compose_filename) as docker_compose:
            if "version" in docker_compose:
                del docker_compose["version"]


def _get_env() -> TaskEnv:
    config = Config()

    use_helm = config.enabled(
        "helm",
        os.path.exists("Chart.yaml") or os.path.exists("test/helmchart/Chart.yaml"),
    )

    gopass = config.enabled(
        "gopass",
        "no-gopass" not in config.repo.get("types", [])
        and (
            config.repo["name"].startswith("camptocamp/")
            or config.repo["name"].startswith("mapfish/")
        ),
    )
    # Get the string we used in the workflow to get the GitHub token to be used
    token = config.value(
        "github_token_secret",
        "${{ secrets.GOPASS_CI_GITHUB_TOKEN }}" if gopass else "${{ secrets.TOKEN }}",
    )

    # Get the version of c2cciutils
    c2cciutils_version = version.parse("1.6.0")
    set_c2cciutils_version = False
    if os.path.exists("ci/requirements.txt"):
        with mra.Edit("ci/requirements.txt") as requirements_txt:
            requirements = [
                r
                for r in requirements_txt.data.split("\n")
                if r.startswith("c2cciutils==") or r.startswith("c2cciutils[")
            ]
            if len(requirements) == 1:
                c2cciutils_version_string = requirements[0].split("==")[1]
                if c2cciutils_version_string.endswith(".*"):
                    c2cciutils_version_string = c2cciutils_version_string[:-2]
                c2cciutils_version = version.parse(c2cciutils_version_string)
                set_c2cciutils_version = True
    c2cciutils_version_config = config.value("c2cciutils_version")
    if c2cciutils_version_config:
        if c2cciutils_version_config == "master":
            c2cciutils_version = version.parse("1.6.0")
            set_c2cciutils_version = False
        else:
            c2cciutils_version = version.parse(c2cciutils_version_config)
            set_c2cciutils_version = True

    use_python = False
    # min_python_version = ''
    # max_python_version = ''
    for pyproject_filename in (
        "pyproject.toml",
        "app/pyproject.toml",
        "api/pyproject.toml",
    ):
        if os.path.exists(pyproject_filename):
            with mra.EditTOML(pyproject_filename) as pyproject:
                use_python = "project" in pyproject or "build-system" in pyproject
                # min_python_version = pyproject.get("tool", {}).get("poetry", {}).get("dependencies", {}).get("python", "")
                # match = re.match(r"^>=(\d+\.\d+),<(\d+)\.(\d+)$", min_python_version)
                # if match:
                #    min_python_version = match.group(1)
                #    max_python_version_major = int(match.group(2))
                #    max_python_version_minor = int(match.group(3))
                #    if max_python_version_major == 4:
                #        max_python_version = "3.13"
                #    else:
                #        max_python_version = f"{max_python_version_major}.{max_python_version_minor-1}"

                break
    use_python = config.enabled("python", use_python)

    use_pypi = config.enabled(
        "pypi", use_python and "no-pypi" not in config.repo.get("type", [])
    )
    use_docker = config.enabled(
        "docker",
        (
            os.path.exists("Dockerfile")
            or os.path.exists("app/Dockerfile")
            or os.path.exists("api/Dockerfile")
        )
        and "no-docker" not in config.repo.get("type", []),
    )

    stabilization_branches = mra.get_stabilization_branches(config.repo)

    return TaskEnv(
        c2cciutils_version,
        set_c2cciutils_version,
        use_python,
        # min_python_version,
        # max_python_version,
        use_pypi,
        use_docker,
        use_helm,
        config.arguments.on_stabilization_branches or len(stabilization_branches) > 0,
        config.arguments.on_stabilization_branches and len(stabilization_branches) > 0,
        stabilization_branches,
        gopass,
        token,
        config,
    )


def _ghci_updates(task_env: TaskEnv) -> None:
    if (
        task_env.use_helm
        and not os.path.exists(".github/ghci.yaml")
        and not task_env.on_stabilization_branches
    ):
        with open(".github/ghci.yaml", "w", encoding="utf-8") as ghci:
            ghci.write(
                """# yaml-language-server: $schema=https://geoservices-int.camptocamp.com/github/schema.json

profile: helm
"""
            )


def _do() -> None:
    task_env = _get_env()
    print(f"Task environment: {task_env}")

    for name, task in (
        ("create-labels", _create_labels),
        ("tag-publish-config", _tag_publish_config),
        ("set-schema-config", _set_schema_config),
        ("update-changelog-workflow", _update_changelog_workflow),
        ("update-clean-workflow", _update_clean_workflow),
        (
            "update-dependency-auto-review-workflow",
            _update_pull_request_automation_workflow,
        ),
        ("update-pull-request-checks-workflow", _update_pull_request_checks_workflow),
        ("update-backport-workflow", _update_backport_workflow),
        ("update-main-workflow", _update_main_workflow),
        ("update-ghci", _ghci_updates),
    ):
        if task_env.config.enabled(name, True):
            task(task_env)
    if task_env.on_stabilization_branches:
        for file_ in (
            ".github/workflows/delete-old-workflow-run.yaml",
            ".github/workflows/delete-old-workflows-run.yaml",
            ".github/renovate.json5",
        ):
            if os.path.exists(file_):
                os.remove(file_)
        for file_ in glob.glob(".github/workflows/audit*.yaml"):
            os.remove(file_)
        for file_ in glob.glob(".github/workflows/rebuild*.yaml"):
            os.remove(file_)

        if not os.path.exists("ci/config.yaml"):
            with open("ci/config.yaml", "w", encoding="utf-8") as config:
                config.write("{}")

        with mra.EditYAML("ci/config.yaml") as config:
            if config.get("checks") is not False:
                # config.setdefault("checks", {})["codespell"] = False
                if (
                    task_env.c2cciutils_version.major == 1
                    and task_env.c2cciutils_version.minor <= 3
                ):
                    config.setdefault("checks", {})["required_workflows"] = False
    else:
        for name, task in (
            # ("upgrade-ubuntu", _upgrade_ubuntu),
            ("update-audit-workflow", _update_audit_workflow),
            (
                "update-delete-old-workflow-run-workflow",
                _update_delete_old_workflows_run_workflow,
            ),
            ("update-pyproject-toml", _update_pyproject_toml),
            ("update-prospector-config", _update_prospector_config),
            # ("update-python-version", _update_python_version),
            ("update-renovate-config", _update_renovate_config),
            ("update-config", _update_config),
            ("update-pre-commit-config", _update_pre_commit_config),
            ("remove-docker-compose-version", _remove_docker_compose_version),
            ("use-tag-publish", _use_tag_publish),
        ):
            if task_env.config.enabled(name, True):
                task(task_env)


if __name__ == "__main__":
    # edit the file /home/sbrunner/workspace/docker-vim/.github/workflows/changelog.yaml
    # with mra.EditYAML("/home/sbrunner/workspace/docker-vim/.github/workflows/audit.yaml") as e:
    #    _canonicalize_workflow(e)
    # with mra.EditYAML("/home/sbrunner/workspace/docker-vim/.github/workflows/changelog.yaml") as e:
    #    _canonicalize_workflow(e)
    # exit(0)

    os.environ["IGNORE_CONFIG_ERROR"] = "true"

    mra.main(
        _do,
        # pull_request_on_stabilization_branches
        # pull_request_title
        # pull_request_body
        # branch
        # pull_request_branch_prefix
        config={
            "branch": "ci-upgrade",
            "pull_request_branch_prefix": "ci-upgrade-",
            "pull_request_title": "CI updates",
            "pull_request_body": "This is done by the automated script named "
            + os.path.basename(__file__),
        },
        description="Update the repository for the CI evolutions",
    )
